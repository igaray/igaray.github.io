<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>PKB</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="My personal knowledge base">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item affix "><a href="Home.html">Home</a></li><li class="chapter-item affix "><li class="part-title active">Computer Science and Engineering</li><li class="chapter-item "><a href="programming/index.html">Programming</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="programming/algorithms/index.html">Algorithms</a></li><li class="chapter-item "><a href="programming/ai/index.html">AI</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="programming/ai/timeline.html">AI Timeline</a></li><li class="chapter-item "><a href="programming/ai/bdi.html">BDI Model</a></li><li class="chapter-item "><a href="programming/ai/richard_sutton.html">Richard Sutton</a></li></ol></li><li class="chapter-item "><a href="programming/compilers/index.html">Compilers</a></li><li class="chapter-item "><a href="programming/distributed_systems/index.html">Distributed Systems</a></li><li class="chapter-item "><a href="programming/excellency/index.html">Excellency</a></li><li class="chapter-item "><a href="programming/tools/index.html">Tools</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="programming/tools/code_searching.html">Code Searching</a></li><li class="chapter-item "><a href="programming/tools/cli.html">CLI</a></li><li class="chapter-item "><a href="programming/tools/docker.html">Docker</a></li><li class="chapter-item "><a href="programming/tools/elasticsearch.html">ElasticSearch</a></li><li class="chapter-item "><a href="programming/tools/git.html">Git</a></li><li class="chapter-item "><a href="programming/tools/latex.html">Latex</a></li><li class="chapter-item "><a href="programming/tools/rsync.html">RSync</a></li><li class="chapter-item "><a href="programming/tools/suckless.html">&quot;Suckless&quot;</a></li><li class="chapter-item "><a href="programming/tools/utils.html">System Utilities</a></li><li class="chapter-item "><a href="programming/tools/vim.html">Vim</a></li></ol></li><li class="chapter-item "><a href="programming/misc/index.html">Misc</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="programming/misc/systems_performance.html">Systems Performance</a></li><li class="chapter-item "><a href="programming/misc/sql_explain.html">SQL Explain</a></li><li class="chapter-item "><a href="programming/misc/climate_modeling.html">Climate Modeling</a></li><li class="chapter-item "><a href="programming/misc/magic.html">Magic</a></li><li class="chapter-item "><a href="programming/misc/quotes.html">Quotes</a></li><li class="chapter-item "><a href="programming/misc/unix_philosophy.html">The Philosophy of Unix</a></li><li class="chapter-item "><a href="programming/misc/zen_programmer.html">The Zen Programmer</a></li><li class="chapter-item "><a href="programming/misc/zen_python.html">The Zen of Python</a></li></ol></li></ol></li><li class="chapter-item "><li class="part-title active">Other Stuff</li><li class="chapter-item "><a href="euskera/index.html">Euskera</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="euskera/habe.html">HABE</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="euskera/habe_a1.html">HABE A1</a></li><li class="chapter-item "><a href="euskera/habe_a2.html">HABE A2</a></li><li class="chapter-item "><a href="euskera/habe_b1.html">HABE B1</a></li><li class="chapter-item "><a href="euskera/habe_b2.html">HABE B2</a></li><li class="chapter-item "><a href="euskera/habe_c1.html">HABE C1</a></li><li class="chapter-item "><a href="euskera/habe_c2.html">HABE C2</a></li></ol></li><li class="chapter-item "><a href="euskera/studying_languages_linguistics.html">Studying Languages &amp; Linguistics</a></li><li class="chapter-item "><a href="euskera/euskarazko_hiztegi_txikia.html">Euskarazko Hiztegi Txikia</a></li><li class="chapter-item "><a href="euskera/nire_apunteak.html">Nire Apunteak</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="euskera/lexiko.html">Lexiko</a></li><li class="chapter-item "><a href="euskera/izen_sintagma.html">Izen Sintagma</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="euskera/nombres.html">Nombres</a></li><li class="chapter-item "><a href="euskera/pronombres.html">Pronombres</a></li><li class="chapter-item "><a href="euskera/pronombres_personales.html">Pronombres personales</a></li><li class="chapter-item "><a href="euskera/pronombres_personales_intensivos.html">Pronombres personales intensivos</a></li><li class="chapter-item "><a href="euskera/pronombres_demostrativos.html">Pronombres demostrativos</a></li><li class="chapter-item "><a href="euskera/pronombres_demostrativos_intensivos.html">Pronombres demostrativos intensivos</a></li><li class="chapter-item "><a href="euskera/pronombres_indeterminados.html">Pronombres indeterminados</a></li><li class="chapter-item "><a href="euskera/adjektiboak.html">Adjektiboak</a></li></ol></li><li class="chapter-item "><a href="euskera/kasuak.html">Kasuak</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="euskera/kasu_nor.html">Kasu: Nor</a></li><li class="chapter-item "><a href="euskera/kasu_partitiboa.html">Kasu: Partitiboa</a></li><li class="chapter-item "><a href="euskera/kasu_non.html">Kasu: Non</a></li><li class="chapter-item "><a href="euskera/kasu_nork.html">Kasu: Nork</a></li><li class="chapter-item "><a href="euskera/kasu_nori.html">Kasu: Nori</a></li><li class="chapter-item "><a href="euskera/kasu_noren.html">Kasu: Noren</a></li><li class="chapter-item "><a href="euskera/kasu_norentzat.html">Kasu: Norentzat</a></li><li class="chapter-item "><a href="euskera/kasu_norekin.html">Kasu: Norekin</a></li><li class="chapter-item "><a href="euskera/kasu_norengatik.html">Kasu: Norengatik</a></li><li class="chapter-item "><a href="euskera/kasu_norengan.html">Kasu: Norengan</a></li><li class="chapter-item "><a href="euskera/kasu_norengandik.html">Kasu: Norengandik</a></li><li class="chapter-item "><a href="euskera/kasu_norengana.html">Kasu: Norengana</a></li><li class="chapter-item "><a href="euskera/kasu_norenganaino.html">Kasu: Norenganaino</a></li><li class="chapter-item "><a href="euskera/kasu_norenganantz.html">Kasu: Norenganantz</a></li><li class="chapter-item "><a href="euskera/kasu_nora.html">Kasu: Nora</a></li><li class="chapter-item "><a href="euskera/kasu_noraino.html">Kasu: Noraino</a></li><li class="chapter-item "><a href="euskera/kasu_norantz.html">Kasu: Norantz</a></li><li class="chapter-item "><a href="euskera/kasu_norako.html">Kasu: Norako</a></li><li class="chapter-item "><a href="euskera/kasu_nondik.html">Kasu: Nondik</a></li><li class="chapter-item "><a href="euskera/kasu_nongo.html">Kasu: Nongo</a></li><li class="chapter-item "><a href="euskera/kasu_nortzat.html">Kasu: Nortzat</a></li><li class="chapter-item "><a href="euskera/kasu_zerez_zertaz.html">Kasu: Zerez/Zertaz</a></li><li class="chapter-item "><a href="euskera/kasu_zerezko.html">Kasu: Zerezko</a></li></ol></li><li class="chapter-item "><a href="euskera/aditzak.html">Aditzak</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="euskera/aditz_laguntzaileak.html">Aditz Laguntzaileak</a></li><li class="chapter-item "><a href="euskera/aditz_bereziak.html">Aditz Bereziak</a></li><li class="chapter-item "><a href="euskera/aditz_trinkoak.html">Aditz Trinkoak</a></li><li class="chapter-item "><a href="euskera/nominalizazioa.html">Nominalizazioa</a></li><li class="chapter-item "><a href="euskera/baldintzak.html">Baldintzak (Condicionales)</a></li></ol></li></ol></li></ol></li><li class="chapter-item "><a href="mind/index.html">Mind</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="mind/buddhism/index.html">Buddhism</a></li></ol></li><li class="chapter-item "><a href="body/index.html">Body</a></li><li class="chapter-item "><a href="society/index.html">Society</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="society/sustainable_economics.html">Sustainable Economics</a></li><li class="chapter-item "><a href="society/umberto_eco_ur_fascism.html">Ur Fascism</a></li></ol></li><li class="chapter-item "><a href="music/index.html">Music</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="music/lyrics/index.html">Lyrics</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="music/lyrics/berri_txarrak/index.html">Berri Txarrak</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="music/lyrics/berri_txarrak/1999_ikasten/index.html">1999 Ikasten</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2001_eskuak_ekubilak/index.html">2001 Eskuak-Ekubilak</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2003_libre/index.html">2003 Libre</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2003_jaoi_musika_hil/index.html">2005 Jaoi.Musika.Hil</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2009_payola/index.html">2009 Payola</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2011_haria/index.html">2011 Haria</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2014_denbora_da_poligrafo_bakarra/index.html">2014 Denbora da poligrafo bakarra</a></li><li class="chapter-item "><a href="music/lyrics/berri_txarrak/2017_infrasoinuak/index.html">2017 Infrasoinuak</a></li></ol></li><li class="chapter-item "><a href="music/lyrics/deftones/index.html">Deftones</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="music/lyrics/deftones/1995_adrenaline/index.html">1995 Adrenaline</a></li><li class="chapter-item "><a href="music/lyrics/deftones/1997_around_the_fur/index.html">1997 Around the Fur</a></li><li class="chapter-item "><a href="music/lyrics/deftones/2000_white_pony/index.html">2000 White Pony</a></li><li class="chapter-item "><a href="music/lyrics/deftones/2003_deftones/index.html">2003 Deftones</a></li><li class="chapter-item "><a href="music/lyrics/deftones/2006_saturday_night_wrist/index.html">2006 Saturday Night Wrist</a></li><li class="chapter-item "><a href="music/lyrics/deftones/2010_diamond_eyes/index.html">2010 Diamond Eyes</a></li><li class="chapter-item "><a href="music/lyrics/deftones/2012_koi_no_yokan/index.html">2012 Koi No Yokan</a></li><li class="chapter-item "><a href="music/lyrics/deftones/2016_gore/index.html">2016 Gore</a></li></ol></li><li class="chapter-item "><a href="music/lyrics/tool/index.html">Tool</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="music/lyrics/tool/1993_undertow/index.html">1993 Undertow</a></li><li class="chapter-item "><a href="music/lyrics/tool/1996_aenima/index.html">1996 Aenima</a></li><li class="chapter-item "><a href="music/lyrics/tool/2001_lateralus/index.html">2001 Lateralus</a></li><li class="chapter-item "><a href="music/lyrics/tool/2006_10000_days/index.html">2006 10000 Days</a></li><li class="chapter-item "><a href="music/lyrics/tool/2019_fear_inoculum/index.html">2019 Fear Inoculum</a></li></ol></li></ol></li></ol></li><li class="chapter-item "><a href="misc/index.html">Misc</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="misc/cooking/index.html">Cooking</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="misc/cooking/arroz_con_hongos.html">Arroz con Hongos</a></li><li class="chapter-item "><a href="misc/cooking/croquetas_de_acelga_o_espinaca.html">Croquetas de Acelga/Espinaca</a></li><li class="chapter-item "><a href="misc/cooking/mayonesa.html">Mayonesa</a></li><li class="chapter-item "><a href="misc/cooking/sopa_de_arvejas.html">Sopa de Arvejas</a></li></ol></li><li class="chapter-item "><a href="misc/library.html">My library</a></li><li class="chapter-item "><a href="misc/technical_and_scientific_writing.html">Technical and Scientific Writing</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">PKB</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#home" id="home">Home</a></h1>
<p>My name is Iñaki Garay. I'm a programmer from Argentina. This is where I put some of my stuff.</p>
<h1><a class="header" href="#programming" id="programming">Programming</a></h1>
<h1><a class="header" href="#algorithms" id="algorithms">Algorithms</a></h1>
<h2><a class="header" href="#books" id="books">Books</a></h2>
<h3><a class="header" href="#brassard---fundamentals-of-algorithmics" id="brassard---fundamentals-of-algorithmics">Brassard - Fundamentals Of Algorithmics</a></h3>
<p>Chapters</p>
<ul>
<li>1 Preliminaries</li>
<li>2 Elementary Algorithmics</li>
<li>3 Asymptotic Notation</li>
<li>4 Analysis Of Algorithms</li>
<li>5 Some Data Structures</li>
<li>6 Greedy Algorithms</li>
<li>7 Divide and Conquer</li>
<li>8 Dynamic Programming</li>
<li>9 Exploring Graphs</li>
<li>10 Probabilistic Algorithms</li>
<li>11 Parallel Algorithms</li>
<li>12 Computational Complexity</li>
<li>13 Heuristic And Approximate Algorithms</li>
</ul>
<h3><a class="header" href="#cormen---introduction-to-algorithms" id="cormen---introduction-to-algorithms">Cormen - Introduction To Algorithms</a></h3>
<p>Chapters</p>
<ul>
<li>1.0 the role of algorithms in computing
<ul>
<li>1.1 algorithms</li>
<li>1.2 algorithms as a technology</li>
</ul>
</li>
<li>2.0 getting started
<ul>
<li>2.1 insertion sort</li>
<li>2.2 analyzing algorithms</li>
<li>2.3 designing algorithms</li>
</ul>
</li>
<li>3.0 growth of functions
<ul>
<li>3.1 asymptotic functions</li>
<li>3.2 standard notations and common functions</li>
</ul>
</li>
<li>4.0 recurrences
<ul>
<li>4.1 the substitution method</li>
<li>4.2 the recursion-tree method</li>
<li>4.3 the master method</li>
<li>4.4 proof of the master theorem</li>
</ul>
</li>
<li>5.0 probalistic analysis and randomized algorithms
<ul>
<li>5.1 the hiring problem</li>
<li>5.2 indicator random variables</li>
<li>5.3 randomized algorithms</li>
<li>5.4 probabilistic analysis and further uses of indicator random variables</li>
</ul>
</li>
<li>6.0 heapsort
<ul>
<li>6.1 heaps</li>
<li>6.2 maintaining the heap property</li>
<li>6.3 building a heap</li>
<li>6.4 the heapsort algorithm</li>
<li>6.5 priority queues</li>
</ul>
</li>
<li>7.0 quicksort
<ul>
<li>7.1 description of quicksort</li>
<li>7.2 performance of quicksort</li>
<li>7.3 a randomized version of quicksort</li>
<li>7.4 analysis of quicksort</li>
</ul>
</li>
<li>8.0 sorting in linear time
<ul>
<li>8.1 lower bounds for sorting</li>
<li>8.2 counting sort</li>
<li>8.3 radix sort</li>
<li>8.4 bucket sort</li>
</ul>
</li>
<li>9.0 medians and order statistics
<ul>
<li>9.1 minimum and maximum</li>
<li>9.2 selection in expected linear time</li>
<li>9.3 selection in worst-case linear time</li>
</ul>
</li>
<li>10.0 elementary data structures
<ul>
<li>10.1 stacks and queues</li>
<li>10.2 linked lists</li>
<li>10.3 implementing pointers and objects</li>
<li>10.4 representing rooted trees</li>
</ul>
</li>
<li>11.0 hash tables
<ul>
<li>11.1 direct-address tables</li>
<li>11.2 hash tables</li>
<li>11.3 hash functions</li>
<li>11.4 open addressing</li>
<li>11.5 perfect hashing</li>
</ul>
</li>
<li>12.0 binary search trees
<ul>
<li>12.1 what is a binary search tree?</li>
<li>12.2 querying a binary search tree</li>
<li>12.3 insertion and deletion</li>
<li>12.4 randomly built binary search trees</li>
</ul>
</li>
<li>13.0 red-black trees
<ul>
<li>13.1 properties of red-black trees</li>
<li>13.2 rotations</li>
<li>13.3 insertion</li>
<li>13.4 deletion</li>
</ul>
</li>
<li>14.0 augmenting data structures
<ul>
<li>14.1 dynamic order statistics</li>
<li>14.2 how to augment a data structure</li>
<li>14.3 interval trees</li>
</ul>
</li>
<li>15.0 dynamic programming
<ul>
<li>15.1 assembly-line scheduling</li>
<li>15.2 matrix-chain multiplication</li>
<li>15.3 elements of dynamic programming</li>
<li>15.4 longest common subsequence</li>
<li>15.5 optimal binary search trees</li>
</ul>
</li>
<li>16.0 ggreedy algorithms
<ul>
<li>16.1 an activity-selection problem</li>
<li>16.2 elements of the greedy strategy</li>
<li>16.3 huffman codes</li>
<li>16.4 theoretical foundations for greedy algorithms</li>
<li>16.5 a task-scheduling algorithm</li>
</ul>
</li>
<li>17.0 amortized analysis
<ul>
<li>17.2 the accounting method</li>
<li>17.3 the potential method</li>
<li>17.4 dynamic tables</li>
</ul>
</li>
<li>18.0 b-trees
<ul>
<li>18.1 definition of b-trees</li>
<li>18.2 basic operations on b-trees</li>
<li>18.3 deleting keys from a b-tree</li>
</ul>
</li>
<li>19.0 binomial heaps
<ul>
<li>19.1 binomial trees and binomial heaps</li>
<li>19.2 operations on binomial heaps</li>
</ul>
</li>
<li>20.0 fibonacci heaps
<ul>
<li>20.1 structure of fibonacci heaps</li>
<li>20.2 mergeable-heap operations</li>
<li>20.3 decreasing a key and deleting a node</li>
<li>20.4 bounding the maximum degree</li>
</ul>
</li>
<li>21.0 data structures for disjoint sets
<ul>
<li>21.1 disjoint-set opertions</li>
<li>21.2 linked-list representation of disjoint sets</li>
<li>21.3 disjoint-set forests</li>
<li>21.4 analysis of union by rank with path compression</li>
</ul>
</li>
<li>22.0 elementary graph algorithms
<ul>
<li>22.1 representation of graphs</li>
<li>22.2 breadth-first search</li>
<li>22.3 depth-first search</li>
<li>22.4 topological sort</li>
<li>22.5 strongly connected components</li>
</ul>
</li>
<li>23.0 minimum spanning trees
<ul>
<li>23.1 growing a minimum spanning tree</li>
<li>23.2 the algorithms of kruskal and prim</li>
</ul>
</li>
<li>24.0 single-source shortest paths
<ul>
<li>24.1 the bellman-ford algorithm</li>
<li>24.2 single-source shortest paths in directed acyclic graphs</li>
<li>24.3 dijkstra's algorithm</li>
<li>24.4 difference constraints and shortest paths</li>
<li>24.5 proofs of shortest-paths properties</li>
</ul>
</li>
<li>25.0 all-pairs shortest paths
<ul>
<li>25.1 shortest paths and matrix multiplication</li>
<li>25.2 the floyd-warshall algorithm</li>
<li>25.3 johnson's algorithm for sparse graphs</li>
</ul>
</li>
<li>26.0 maximum flow
<ul>
<li>26.1 flow networks</li>
<li>26.2 the ford-fulkerson method</li>
<li>26.3 maximum bipartite graph</li>
<li>26.4 push-relabel algorithms</li>
<li>26.5 the relabel-to-front algorithm</li>
</ul>
</li>
<li>27.0 sorting algorithms
<ul>
<li>27.1 comparison networks</li>
<li>27.2 the zero-one principle</li>
<li>27.3 a bitonic sorting network</li>
<li>27.4 a merging network</li>
<li>27.5 a sorting network</li>
</ul>
</li>
<li>28.0 matrix operations
<ul>
<li>28.1 properties of matrices</li>
<li>28.2 strassen's algorithm for matrix multiplication</li>
<li>28.3 solving systems of linear equations</li>
<li>28.4 inverting matrices</li>
<li>28.5 symmetric possitive-definite matrices and least-squares approximation</li>
</ul>
</li>
<li>29.0 linear programming
<ul>
<li>29.1 standard and slack forms</li>
<li>29.2 formulating problems as linear programs</li>
<li>29.3 the simplex algorithm</li>
<li>29.4 duality</li>
<li>29.5 the initial basic feasible solution</li>
</ul>
</li>
<li>30.0 polynomials and the FFT
<ul>
<li>30.1 representation of polynomials</li>
<li>30.2 the dft and the fft</li>
<li>30.3 efficient fft implementations</li>
</ul>
</li>
<li>31.0 number-theoretic algorithms
<ul>
<li>31.1 elementary number-theoretic notions</li>
<li>31.2 greatest common divisor</li>
<li>31.3 modular arithmetic</li>
<li>31.4 soving modular linear equations</li>
<li>31.5 the chinese remainder problem</li>
<li>31.6 powers of an element</li>
<li>31.7 the rsa public-key cryptosystem</li>
<li>31.8 primality testing</li>
<li>31.9 integer factorization</li>
</ul>
</li>
<li>32.0 string matching
<ul>
<li>32.1 the naive string-matching algorithm</li>
<li>32.2 the rabin-karp algorithm</li>
<li>32.3 string matching with finite automata</li>
<li>32.4 the knuth-morris-pratt algorithm</li>
</ul>
</li>
<li>33.0 computational geometry
<ul>
<li>33.1 line-segment properties</li>
<li>33.2 determining whether any pair of segments intersect</li>
<li>33.3 finding the convex hull</li>
<li>33.4 finding the closest pair of points</li>
</ul>
</li>
<li>34.0 np-completeness
<ul>
<li>34.1 polynomial time</li>
<li>34.2 polynomial time verification</li>
<li>34.3 np-completeness and reducibility</li>
<li>34.4 np-completeness proofs</li>
<li>34.5 np-completeness problems</li>
</ul>
</li>
<li>35.0 approximation algorithms
<ul>
<li>35.1 the vertex-cover problem</li>
<li>35.2 the traveling salesman problem</li>
<li>35.3 the set-covering problem</li>
<li>35.4 randomization and linear programming</li>
<li>35.5 the subset-sum problem</li>
</ul>
</li>
<li>A summations
<ul>
<li>A1 summation formulas and properties</li>
<li>A2 bounding summations</li>
</ul>
</li>
<li>B sets, etc
<ul>
<li>B1 sets</li>
<li>B2 relations</li>
<li>B3 functions</li>
<li>B4 graphs</li>
<li>B5 trees</li>
</ul>
</li>
<li>C counting and probability
<ul>
<li>C1 counting</li>
<li>C2 probability</li>
<li>C3 discrete random variables</li>
<li>C4 the geometric and binomial distributions</li>
<li>C5 the tails of the binomial distribution</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#sedgewick---algorithms" id="sedgewick---algorithms">Sedgewick - Algorithms</a></h3>
<p>Chapters</p>
<ul>
<li>1.1 Basic Programming Model</li>
<li>1.2 Data Abstraction</li>
<li>1.3 Bags, Queues And Stacks</li>
<li>1.4 Analysis Of Algorithms</li>
<li>1.5 Case Study Union-find Algorithm</li>
<li>2.1 Elementary Sorts</li>
<li>2.2 Mergesort</li>
<li>2.3 Quicksort</li>
<li>2.4 Priority Queues</li>
<li>2.5 Applications</li>
<li>3.1 Symbol Tables</li>
<li>3.2 Binary Search Trees</li>
<li>3.3 Balanced Search Trees</li>
<li>3.4 Hash Tables</li>
<li>3.5 Applications</li>
<li>4.1 Undirected Graphs</li>
<li>4.2 Directed Graphs</li>
<li>4.3 Minimum Spanning Trees</li>
<li>4.4 Shortest Paths</li>
<li>5.1 String Sorts</li>
<li>5.2 Tries</li>
<li>5.3 Substring Search</li>
<li>5.4 Regular Expressions</li>
<li>5.5 Data Compression</li>
<li>6 Context</li>
</ul>
<h3><a class="header" href="#sedgewick---algorithms-in-c" id="sedgewick---algorithms-in-c">Sedgewick - Algorithms in C</a></h3>
<p>Chapters</p>
<ul>
<li>Fundamentals
<ul>
<li>1 introduction</li>
<li>2 principles of algorithm analysis</li>
</ul>
</li>
<li>Data structures
<ul>
<li>3 elementary data structures</li>
<li>4 trees and recursion</li>
<li>5 elementary abstract data types</li>
</ul>
</li>
<li>Sorting
<ul>
<li>6 elementary sorting methods</li>
<li>7 quicksort</li>
<li>8 mergesort</li>
<li>9 priority queues and heapsort</li>
<li>10 radix sorting</li>
<li>11 special-purpose sorts</li>
</ul>
</li>
<li>Searching
<ul>
<li>12 symbol tables and bsts</li>
<li>13 balances trees</li>
<li>14 hashing</li>
<li>15 radix searching</li>
<li>16 external searching</li>
</ul>
</li>
<li>Graph algorithms
<ul>
<li>17 graph properties and types</li>
<li>18 graph search</li>
<li>19 digraphs and dags</li>
<li>20 minimum spanning trees</li>
<li>21 shortest paths</li>
<li>22 network flows</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#van-wyk---data-structures-and-c-programs" id="van-wyk---data-structures-and-c-programs">Van Wyk - Data Structures And C Programs</a></h3>
<p>Chapters</p>
<ul>
<li>Fundamental Ideas
<ul>
<li>1 Introduction</li>
<li>2 The Complexity Of Algorithms</li>
<li>3 Pointers And Dynamic Storage</li>
<li>4 Stacks And Queues</li>
<li>5 Linked Lists</li>
<li>6 Memory Organization</li>
</ul>
</li>
<li>Efficient Algorithms
<ul>
<li>7 Searching</li>
<li>8 Hashing</li>
<li>9 Sorted Lists</li>
<li>10 Priority Queues</li>
<li>11 Sorting</li>
<li>12 Applying Data Structures</li>
</ul>
</li>
<li>Advanced Topics
<ul>
<li>Acyclic Graphs</li>
<li>Graphs</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#korsh--garrett---data-structures-algorithms-and-program-style-using-c" id="korsh--garrett---data-structures-algorithms-and-program-style-using-c">Korsh &amp; Garrett - Data Structures, Algorithms and Program Style Using C</a></h3>
<p>Chapters</p>
<ul>
<li>Fundamentals
<ul>
<li>1 Programming structure</li>
<li>2 Records, Arrays, and Pointers</li>
<li>3 Lists</li>
<li>4 Introduction to Recursion, Stacks, Queues</li>
<li>5 Packaging Data Abstractions</li>
<li>6 More Complex Lists</li>
<li>7 Trees</li>
</ul>
</li>
<li>Applications
<ul>
<li>8 Introduction to Searching and Sorting</li>
<li>9 More Searching: Insertion and Deletion</li>
<li>10 Files</li>
<li>11 Topological Sorting: An Archetypal Solution</li>
<li>12 Huffman Coding and Optimal and Nearly Optimal Binary Search Trees</li>
<li>13 Some Pointers on Storage Management</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#weiss---data-structs--algorithm-analysis-in-c" id="weiss---data-structs--algorithm-analysis-in-c">Weiss - Data Structs &amp; Algorithm Analysis In C++</a></h3>
<p>Chapters</p>
<ul>
<li>
<h2><a class="header" href="#1-introduction" id="1-introduction">1 Introduction</a></h2>
</li>
<li>2 Algorithm Analysis</li>
<li>3 Lists, Stacks and Queues</li>
<li>4 Trees</li>
<li>5 Hashing</li>
<li>6 Priority Queues (Heaps)</li>
<li>7 Sorting</li>
<li>8 The Disjoint Set Class</li>
<li>9 Graph Algorithms</li>
<li>10 Algorithm Design Techniques</li>
<li>11 Amortized Analysis</li>
<li>12 Advanced Data Structures and Implementation</li>
</ul>
<h3><a class="header" href="#skiena---algorithm-design-manual" id="skiena---algorithm-design-manual">Skiena - Algorithm Design Manual</a></h3>
<p>Chapters</p>
<ul>
<li>1.0 Introduction To Algorithm Design
<ul>
<li>1.1 Robot Tour Optimization</li>
<li>1.2 Selecting The Right Jobs</li>
<li>1.3 Reasoning About Correctness</li>
<li>1.4 Modeling The Problem</li>
<li>1.5 About The War Stories</li>
<li>1.6 War Story: Psychic Modeling</li>
<li>1.7 Exercises</li>
</ul>
</li>
<li>2.0 Algorithm Analysis
<ul>
<li>2.1 The Ram Model Of Computation</li>
<li>2.2 The Big Oh Notation</li>
<li>2.3 Growth Rates And Dominance Relations</li>
<li>2.4 Working With The Big Oh</li>
<li>2.5 Reasoning About Efficiency</li>
<li>2.6 Logarithms And Their Applications</li>
<li>2.7 Properties Of Logarithms</li>
<li>2.8 War Story: Mystery Of The Pyramids</li>
<li>2.9 Advanced Analysis</li>
</ul>
</li>
<li>3.0 Data Structures
<ul>
<li>3.1 Contiguous Vs Linked-list Structures</li>
<li>3.2 Stacks And Queues</li>
<li>3.3 Dictionaries</li>
<li>3.4 Binary Search Trees</li>
<li>3.5 Priority Queues</li>
<li>3.6 War Story: Stripping Triangulations</li>
<li>3.7 Hashing And Strings</li>
<li>3.8 Specialized Data Structures</li>
<li>3.9 War Story: String 'em Up</li>
<li>3.10 Exercises</li>
</ul>
</li>
<li>4.0 Sorting And Searching
<ul>
<li>4.1 Applications Of Sorting</li>
<li>4.2 Pragmatics Of Sorting</li>
<li>4.3 Heapsort: Fast Sorting Via Data Structures</li>
<li>4.4 War Story: Give Me A Ticket On The Airplane</li>
<li>4.5 Mergesort: Sorting By Divide-and-conquer</li>
<li>4.6 Quicksort: Sorting By Randomization</li>
<li>4.7 Distribution Sort: Sorting Via Bucketing</li>
<li>4.8 War Story: Skiena For The Defense</li>
<li>4.9 Binary Search And Related Algorithms</li>
<li>4.10 Divide-and-conquer</li>
<li>4.11 Exercises</li>
</ul>
</li>
<li>5.0 Graph Traversal
<ul>
<li>5.1 Flavors Of Graphs</li>
<li>5.2 Data Structures For Graphs</li>
<li>5.3 War Story: I Was A Victim Of Moore's Law</li>
<li>5.4 War Story: Getting The Graph</li>
<li>5.5 Traversing The Graph</li>
<li>5.6 Breadth-first Search</li>
<li>5.7 Applications Of Breadth-first Search</li>
<li>5.8 Depth-first Search</li>
<li>5.9 Applications Of Depth-first Search</li>
<li>5.10 Depth-first Search On Directed Graphs</li>
<li>5.11 Exercises</li>
</ul>
</li>
<li>6.0 Weighted Graph Algorithms
<ul>
<li>6.1 Minimum Spanning Trees</li>
<li>6.2 War Story: Nothing But Nets</li>
<li>6.3 Shortest Paths</li>
<li>6.4 War Story: Dialing For Documents</li>
<li>6.5 Network Flows And Bipartite Matching</li>
<li>6.6 Design Graphs, Not Algorithms</li>
<li>6.7 Exercises</li>
</ul>
</li>
<li>7.0 Combinatorial Search And Heuristic Methods
<ul>
<li>7.1 Backtracking</li>
<li>7.2 Search Pruning</li>
<li>7.3 Sudoku</li>
<li>7.4 War Story: Covering Chessboards</li>
<li>7.5 Heuristic Search Methods</li>
<li>7.6 War Story: Only It Is Not A Radio</li>
<li>7.7 War Story: Annealing Arrays</li>
<li>7.8 Other Heuristic Search Methods</li>
<li>7.9 Parallel Algorithms</li>
<li>7.10 War Story: Going Nowhere Fast</li>
<li>7.11 Exercises</li>
</ul>
</li>
<li>8.0 Dynamic Programming
<ul>
<li>8.1 Caching Vs Computation</li>
<li>8.2 Approximate String Matching</li>
<li>8.3 Longest Increasing Sequence</li>
<li>8.4 War Story: Evolution Of The Lobster</li>
<li>8.5 The Partition Problem</li>
<li>8.6 Parsing Context-free Grammars</li>
<li>8.7 Limitations Of Dynamic Programming: Tsp</li>
<li>8.8 War Story: What's Past Is Prolog</li>
<li>8.9 War Story: Text Compression For Bar Codes</li>
<li>8.10 Exercises</li>
</ul>
</li>
<li>9.0 Intractable Problems And Approximation Algorithms
<ul>
<li>9.1 Problems And Reductions</li>
<li>9.2 Reductions For Algorithms</li>
<li>9.3 Elementary Hardness Reductions</li>
<li>9.4 Satisfiability</li>
<li>9.5 Creative Reductions</li>
<li>9.6 The Art Of Proving Hardness</li>
<li>9.7 War Story: Hard Against The Clock</li>
<li>9.8 War Story: And The I Failed</li>
<li>9.9 P Vs Np</li>
<li>9.10 Dealing With Np-complete Problems</li>
<li>9.11 Exercises</li>
</ul>
</li>
<li>10.0 How To Design Algorithms
<ul>
<li>11.0 A Catalog Of Algorithmic Problems</li>
<li>12.0 Data Structures</li>
<li>12.1 Dictionaries</li>
<li>12.2 Priority Queues</li>
<li>12.3 Suffix Trees And Arrays</li>
<li>12.4 Graph Data Structures</li>
<li>12.5 Set Data Structures</li>
<li>12.6 Kd-trees</li>
</ul>
</li>
<li>13.0 Numerical Problems
<ul>
<li>13.1 Solving Linear Equations</li>
<li>13.2 Bandwidth Reduction</li>
<li>13.3 Matrix Multiplication</li>
<li>13.4 Determinants And Permanents</li>
<li>13.5 Constrained And Unconstrained Optimization</li>
<li>13.6 Linear Programming</li>
<li>13.7 Random Numer Generation</li>
<li>13.8 Factoring And Primality Testing</li>
<li>13.9 Arbitrary-precision Arithmetic</li>
<li>13.10 Knapsack Problem</li>
<li>13.11 Discrete Fourier Transform</li>
</ul>
</li>
<li>14.0 Combinatorial Problems
<ul>
<li>14.1 Sorting</li>
<li>14.2 Searching</li>
<li>14.3 Median And Selection</li>
<li>14.4 Generating Permutations</li>
<li>14.5 Generating Subsets</li>
<li>14.6 Geneasting Partitions</li>
<li>14.7 Generating Graphs</li>
<li>14.8 Calendarical Calculations</li>
<li>14.9 Job Scheduling</li>
<li>14.10 Satisfiability</li>
</ul>
</li>
<li>15.0 Graph Problems: Polynomial Time
<ul>
<li>15.1 Connected Components</li>
<li>15.2 Topological Sorting</li>
<li>15.3 Minimum Spanning Tree</li>
<li>15.4 Shortest Path</li>
<li>15.5 Transitive Closure And Reduction</li>
<li>15.6 Matching</li>
<li>15.7 Eulerian Cycle/chinese Postman</li>
<li>15.8 Edge And Vertex Connectivity</li>
<li>15.9 Network Flow</li>
<li>15.10 Drawing Graphs Nicely</li>
<li>15.11 Drawing Trees</li>
<li>15.12 Planarity Detection And Embedding</li>
</ul>
</li>
<li>16.0 Graph Problems: Hard Problems
<ul>
<li>16.1 Clique</li>
<li>16.2 Independent Set</li>
<li>16.3 Vertex Cover</li>
<li>16.4 Traveling Salesman Problem</li>
<li>16.5 Hamiltonian Cycle</li>
<li>16.6 Graph Partition</li>
<li>16.7 Vertex Coloring</li>
<li>16.8 Edge Coloring</li>
<li>16.9 Graph Isomorphism</li>
<li>16.10 Steiner Tree</li>
<li>16.11 Feedback Edge/vertex Set</li>
</ul>
</li>
<li>17.0 Computational Geometry
<ul>
<li>17.1 Robust Geometric Primitives</li>
<li>17.2 Convex Hull</li>
<li>17.3 Triangulation</li>
<li>17.4 Voronoi Diagrams</li>
<li>17.5 Nearest Neighbor Search</li>
<li>17.6 Range Search</li>
<li>17.7 Point Location</li>
<li>17.8 Intersection Detection</li>
<li>17.9 Bin Packing</li>
<li>17.10 Medial-axis Transform</li>
<li>17.11 Polygon Partitioning</li>
<li>17.12 Simplifying Polygons</li>
<li>17.13 Shape Similarity</li>
<li>17.14 Motion Planning</li>
<li>17.15 Maintaining Line Arrangements</li>
<li>17.16 Minkowski Sum</li>
</ul>
</li>
<li>18.0 Set And String Problems
<ul>
<li>18.1 Set Cover</li>
<li>18.2 Set Packing</li>
<li>18.3 String Matching</li>
<li>18.4 Approximate String Matching</li>
<li>18.5 Text Compression</li>
<li>18.6 Cryptography</li>
<li>18.7 Finite State Machine Minimization</li>
<li>18.8 Longest Common Substring/subsequence</li>
<li>18.9 Shortest Common Superstring</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#knuth---the-art-of-computer-programming-volume-1" id="knuth---the-art-of-computer-programming-volume-1">Knuth - The Art of Computer Programming Volume 1</a></h3>
<h3><a class="header" href="#knuth---the-art-of-computer-programming-volume-2" id="knuth---the-art-of-computer-programming-volume-2">Knuth - The Art of Computer Programming Volume 2</a></h3>
<h3><a class="header" href="#knuth---the-art-of-computer-programming-volume-3" id="knuth---the-art-of-computer-programming-volume-3">Knuth - The Art of Computer Programming Volume 3</a></h3>
<h3><a class="header" href="#knuth---the-art-of-computer-programming-volume-4" id="knuth---the-art-of-computer-programming-volume-4">Knuth - The Art of Computer Programming Volume 4</a></h3>
<h3><a class="header" href="#kleinberg-tardos-algorithm-design" id="kleinberg-tardos-algorithm-design">Kleinberg Tardos Algorithm Design</a></h3>
<p>Chapters</p>
<ul>
<li>1 Introduction: Some Representative Problems</li>
<li>2 Basics Of Algorithm Analysis</li>
<li>3 Graphs</li>
<li>4 Greedy Algorithms</li>
<li>5 Divide And Conquer</li>
<li>6 Dynamic Programming</li>
<li>7 Network Flow</li>
<li>8 Np And Computational Intractability</li>
<li>9 Pspace: A Class Of Problems Beyond Np</li>
<li>10 Extending The Limits Of Tractability</li>
<li>11 Approximation Algorithms</li>
<li>12 Local Search</li>
<li>13 Randomized Algorithms</li>
</ul>
<h3><a class="header" href="#papadimitriou---algorithms" id="papadimitriou---algorithms">Papadimitriou - Algorithms</a></h3>
<p>Chapters</p>
<ul>
<li>0 Prologue</li>
<li>1 Algorithms With Numbers</li>
<li>2 Divide-and-conquer Algoritms</li>
<li>3 Decomposition Of Graphs</li>
<li>4 Paths In Graphs</li>
<li>5 Greedy Algorithms</li>
<li>6 Dynamic Programming</li>
<li>7 Linear Programming And Reductions</li>
<li>8 Np-complete Problems</li>
<li>9 Coping With Np-completeness</li>
<li>10 Quantum Algorithms</li>
</ul>
<h3><a class="header" href="#peter-brass---advanced-data-structures" id="peter-brass---advanced-data-structures">Peter Brass - Advanced Data Structures</a></h3>
<p>Chapters</p>
<ul>
<li>Elementary Structures</li>
<li>Search Trees</li>
<li>Balanced Search Trees</li>
<li>Tree Structures For Sets Of Intervals</li>
<li>Heaps</li>
<li>Union-find And Related Structures</li>
<li>Data Structure Transformations</li>
<li>Data Structures For Strings</li>
<li>Hash Tables</li>
<li>Appendix</li>
</ul>
<h3><a class="header" href="#flajolet---analytic-combinatorics" id="flajolet---analytic-combinatorics">Flajolet - Analytic Combinatorics</a></h3>
<p>Chapters</p>
<ul>
<li>Preface</li>
<li>An Invitation To Analytic Combinatorics</li>
<li>Part A. Symbolic Methods:</li>
<li>
<ol>
<li>Combinatorial Structures And Ordinary Generating Functions</li>
</ol>
</li>
<li>
<ol start="2">
<li>Labelled Structures And Exponential Generating Functions</li>
</ol>
</li>
<li>
<ol start="3">
<li>Combinatorial Parameters And Multivariate Generating Functions</li>
</ol>
</li>
<li>Part B. Complex Asymptotics:</li>
<li>
<ol start="4">
<li>Complex Analysis, Rational And Meromorphic Asymptotics</li>
</ol>
</li>
<li>
<ol start="5">
<li>Applications Of Rational And Meromorphic Asymptotics</li>
</ol>
</li>
<li>
<ol start="6">
<li>Singularity Analysis Of Generating Functions</li>
</ol>
</li>
<li>
<ol start="7">
<li>Applications Of Singularity Analysis</li>
</ol>
</li>
<li>
<ol start="8">
<li>Saddle-point Asymptotics</li>
</ol>
</li>
<li>Part C. Random Structures:</li>
<li>
<ol start="9">
<li>Multivariate Asymptotics And Limit Laws</li>
</ol>
</li>
<li>Part D. Appendices: Appendix A. Auxiliary Elementary Notions</li>
<li>Appendix B. Basic Complex Analysis</li>
<li>Appendix C. Concepts Of Probability Theory</li>
</ul>
<h3><a class="header" href="#deberg---computational-geometry" id="deberg---computational-geometry">Deberg - Computational Geometry</a></h3>
<h3><a class="header" href="#laszlo---computational-geometry-in-c" id="laszlo---computational-geometry-in-c">Laszlo - Computational Geometry In C++</a></h3>
<h2><a class="header" href="#courses" id="courses">Courses</a></h2>
<h3><a class="header" href="#mathematical-thinking" id="mathematical-thinking">Mathematical Thinking</a></h3>
<h3><a class="header" href="#mitcw-introduction-to-algorithmas" id="mitcw-introduction-to-algorithmas">MITCW Introduction To Algorithmas</a></h3>
<h3><a class="header" href="#algorithm-design-and-analysis-1" id="algorithm-design-and-analysis-1">Algorithm Design And Analysis 1</a></h3>
<h3><a class="header" href="#algorithm-design-and-analysis-2" id="algorithm-design-and-analysis-2">Algorithm Design And Analysis 2</a></h3>
<h3><a class="header" href="#sedgewick-algorithms-1" id="sedgewick-algorithms-1">Sedgewick Algorithms 1</a></h3>
<h3><a class="header" href="#sedgewick-algorithms-2" id="sedgewick-algorithms-2">Sedgewick Algorithms 2</a></h3>
<h3><a class="header" href="#skiena" id="skiena">Skiena</a></h3>
<h3><a class="header" href="#algorithmic-toolbox" id="algorithmic-toolbox">Algorithmic Toolbox</a></h3>
<h3><a class="header" href="#data-structures" id="data-structures">Data Structures</a></h3>
<h3><a class="header" href="#algorithms-on-graphs" id="algorithms-on-graphs">Algorithms On Graphs</a></h3>
<h3><a class="header" href="#algorithms-on-strings" id="algorithms-on-strings">Algorithms On Strings</a></h3>
<h3><a class="header" href="#algorithmic-thinking-1" id="algorithmic-thinking-1">Algorithmic Thinking 1</a></h3>
<h3><a class="header" href="#algorithmic-thinking-2" id="algorithmic-thinking-2">Algorithmic Thinking 2</a></h3>
<h3><a class="header" href="#advanced-data-structures" id="advanced-data-structures">Advanced Data Structures</a></h3>
<h3><a class="header" href="#mastering-the-software-engineering-interview" id="mastering-the-software-engineering-interview">Mastering The Software Engineering Interview</a></h3>
<h3><a class="header" href="#sedgewick-analytics-combinatorics-1" id="sedgewick-analytics-combinatorics-1">Sedgewick Analytics Combinatorics 1</a></h3>
<h3><a class="header" href="#sedgewick-analytics-combinatorics-2" id="sedgewick-analytics-combinatorics-2">Sedgewick Analytics Combinatorics 2</a></h3>
<h3><a class="header" href="#discrete-optimization" id="discrete-optimization">Discrete Optimization</a></h3>
<h3><a class="header" href="#intro-to-parallel-programming" id="intro-to-parallel-programming">Intro To Parallel Programming</a></h3>
<h3><a class="header" href="#performance-engineering-of-software" id="performance-engineering-of-software">Performance Engineering Of Software</a></h3>
<h3><a class="header" href="#the-hardware-software-interface" id="the-hardware-software-interface">The Hardware-Software Interface</a></h3>
<h3><a class="header" href="#ecimag-computational-geometry-introduction" id="ecimag-computational-geometry-introduction">ECIMAG Computational Geometry Introduction</a></h3>
<h2><a class="header" href="#topics" id="topics">Topics</a></h2>
<pre><code>| Data Structure | Advantages                                                                                    | Disadvantages                                                           |
|----------------+-----------------------------------------------------------------------------------------------+-------------------------------------------------------------------------|
| Array          | Quick insertion, fast access if index is known.                                               | Slow search, slow deletion, fixed size.                                 |
| Ordered Array  | Quicker search than unsorted array.                                                           | Slow insertion and deletion, fixed size.                                |
| Stack          | LIFO access.                                                                                  | Slow access to other items.                                             |
| Queue          | FIFO access.                                                                                  | Slow access to other items.                                             |
| Linked List    | Quick insertion, quick deletion.                                                              | Slow search.                                                            |
| Binary Tree    | Quick search, insertion, deletion (if tree remains balanced).                                 | Deletion algorithm complex.                                             |
| Red-black Tree | Quick search, insertion, deletion, tree always balanced.                                      | Complex.                                                                |
| 2-3-4 Tree     | Quick search, insertion, deletion, tree always balanced, similar trees good for disk storage. | Complex.                                                                |
| Hash Table     | Very fast access if key is known, fast insertion.                                             | Slow deletion, access slow if key is unknown, inefficient memory usage. |
| Heap           | Fast insertion, deletion, access to largest item.                                             | Slow access to other items.                                             |
</code></pre>
<h3><a class="header" href="#linear-data-structures" id="linear-data-structures">Linear Data Structures</a></h3>
<h4><a class="header" href="#arrays" id="arrays">Arrays</a></h4>
<h4><a class="header" href="#linked-lists" id="linked-lists">Linked Lists</a></h4>
<h5><a class="header" href="#singly-linked" id="singly-linked">Singly Linked</a></h5>
<h5><a class="header" href="#doubly-linked" id="doubly-linked">Doubly Linked</a></h5>
<h5><a class="header" href="#direct--indirect-positioning" id="direct--indirect-positioning">Direct &amp; Indirect Positioning</a></h5>
<h5><a class="header" href="#with--without-header" id="with--without-header">With &amp; Without Header</a></h5>
<h3><a class="header" href="#trees" id="trees">Trees</a></h3>
<h4><a class="header" href="#binary-trees" id="binary-trees">Binary Trees</a></h4>
<h4><a class="header" href="#general-trees" id="general-trees">General Trees</a></h4>
<h4><a class="header" href="#balanced-trees" id="balanced-trees">Balanced Trees</a></h4>
<h5><a class="header" href="#balanced-binary-trees" id="balanced-binary-trees">Balanced Binary Trees</a></h5>
<h5><a class="header" href="#avl-trees" id="avl-trees">Avl Trees</a></h5>
<h5><a class="header" href="#red-black-trees" id="red-black-trees">Red-black Trees</a></h5>
<h4><a class="header" href="#b-trees" id="b-trees">B Trees</a></h4>
<h4><a class="header" href="#b-trees-1" id="b-trees-1">B+ Trees</a></h4>
<h4><a class="header" href="#tries" id="tries">Tries</a></h4>
<h3><a class="header" href="#heaps" id="heaps">Heaps</a></h3>
<h3><a class="header" href="#hash-tables" id="hash-tables">Hash Tables</a></h3>
<h3><a class="header" href="#sets" id="sets">Sets</a></h3>
<h4><a class="header" href="#disjoint-sets" id="disjoint-sets">Disjoint Sets</a></h4>
<h3><a class="header" href="#graphs" id="graphs">Graphs</a></h3>
<h4><a class="header" href="#adjacency-list" id="adjacency-list">Adjacency List</a></h4>
<h4><a class="header" href="#adjacency-matrix" id="adjacency-matrix">Adjacency Matrix</a></h4>
<h3><a class="header" href="#sorting" id="sorting">Sorting</a></h3>
<pre><code>| Algorithm       | Small Oh       | Big Oh     |
|-----------------+----------------+------------|
| BubbleSort      |                |            |
| InsertionSort   | Theta(n^2)     | O(n^2)     |
| SelectionSort   | Theta(n^2)     | O(n^2)     |
| QuickSort       | Theta(n log n) | O(n^2)     |
| MergeSort       | Theta(n log n) | O(n log n) |
| HeapSort        | Theta(n log n) | O(n log n) |
| PidgeonHoleSort | Theta(n)       | O(n)       |
</code></pre>
<h4><a class="header" href="#bubble-sort" id="bubble-sort">Bubble Sort</a></h4>
<h4><a class="header" href="#insertion-sort" id="insertion-sort">Insertion Sort</a></h4>
<p>Pseudocode</p>
<pre><code>procedure insert( T[1..n] )
    for i = 2 to n do
        x = T[i]
        j = i - 1
        while j &gt; 0 and x &lt; T[j] do
            T[j + 1] = T[j]
            j = j - 1
        T[j + 1] = x
</code></pre>
<p>Java</p>
<pre><code>void insertionSort(int[] arr) {
    int i, j, newValue;
    for (i = 1; i &lt; arr.length; i++) {
        newValue = arr[i];
        j = i;
        while (j &gt; 0 &amp;&amp; arr[j - 1] &gt; newValue) {
            arr[j] = arr[j - 1];
            j--;
        }
        arr[j] = newValue;
    }
}
</code></pre>
<p>C++</p>
<pre><code>void insertionSort(int arr[], int length) {
    int i, j, tmp;
    for (i = 1; i &lt; length; i++) {
        j = i;
        while (j &gt; 0 &amp;&amp; arr[j - 1] &gt; arr[j]) {
            tmp = arr[j];
            arr[j] = arr[j - 1];
            arr[j - 1] = tmp;
            j--;
        }
    }
}
</code></pre>
<p>Insertion sort provides several advantages:</p>
<ul>
<li>Simple implementation</li>
<li>Efficient for (quite) small data sets</li>
<li>Adaptive for data sets that are already substantially sorted: the time complexity is O(n + d), where d is the number of inversions</li>
<li>More efficient in practice than most other simple quadratic (i.e., O(n2)) algorithms such as selection sort or bubble sort; the best case (nearly sorted input) is O(n)</li>
<li>Stable; does not change the relative order of elements with equal keys</li>
<li>In-place; only requires a constant amount O(1) of additional memory space</li>
<li>Online; can sort a list as it receives it</li>
</ul>
<p>Let U and V be two arrays of n elements, such that U is already sorted in
ascending order, V is already sorted in descending order.</p>
<p>Both InsertionSort and SelectionSort take more time on U than V.</p>
<p>Array V represents the worst possible case for both insertion sort and selection
sort.</p>
<p>The time required by the selection sort is not very sensitive to the original
order of the array to be sorted.</p>
<p>The test &quot;if T[j] &lt; minx&quot; is executed the same number of times in case.</p>
<p>The variation in execution time is only due to the number of times the
assignments in the then clause of the test are executed.</p>
<p>The time requires by selection is cuadratic, regardless of the initial order of
the elements.</p>
<p>If we compare the times taked by the insertion sort algorithm on U and V,
because the condition controlling the while loop is always false at the outset,
insert(U) is very fast, taking linear time.</p>
<p>On the other hand, insert(V) taked quadratic time because the while loop is
executed i-1 times for each value of i.</p>
<p>The variation in time between these two instances is considerable, and increases
with the number of elements to be sorted.</p>
<p>https://en.wikipedia.org/wiki/Insertion_sort
http://www.algolist.net/Algorithms/Sorting/Insertion_sort
http://www.leepoint.net/notes-java/data/arrays/arrays.html
http://docs.oracle.com/javase/6/docs/api/java/util/Scanner.html</p>
<h4><a class="header" href="#selection-sort" id="selection-sort">Selection Sort</a></h4>
<h4><a class="header" href="#pidgeon-hole-sort" id="pidgeon-hole-sort">Pidgeon Hole Sort</a></h4>
<p>Suppose that the elements to be sorted are integers known to lie between 1 and 10000.</p>
<pre><code>procedure pidgeonhole(T[1..n])
    { Sorts integers between 1 and 10000 }
    array U[1..10000]
    for k-1 to 10000 do
        U[k] = 0
    for i-1 to 10000 do
        k = T[i]
        U[k] = U[k] + 1
    i = 0
    for k-1 to 10000 do
        while U[k] != 0 do
            i = i+1
            T[i] = k
            U[k] = U[k] - 1
</code></pre>
<p>The first loop clears the pigeon-holes, the second puts each element of T into
the appropriate place, and the third pulls them out again in ascending order.
This algorithm and its variants take a time in n.
The hidden multiplicative constant depends on the bound on the value of elements
to be sorted, here 10000.</p>
<h4><a class="header" href="#shell-sort" id="shell-sort">Shell Sort</a></h4>
<h4><a class="header" href="#quick-sort" id="quick-sort">Quick Sort</a></h4>
<h4><a class="header" href="#merge-sort" id="merge-sort">Merge Sort</a></h4>
<ol>
<li>Divide the array A[1..n] into two subarrays A[1..m] and A[m+1..n], where m = floor(n / 2)</li>
<li>Recursively mergesort the subarrays A[1..m] and A[m+1..n]</li>
<li>Merge the newly sorted subarrays A[1..m] and A[m+1..n]</li>
</ol>
<p>The first is completely trivial, we only need to compute the middle index.
All the real work is done in the final step: the two sorted subarrays A[1..m]
and A[m+1..n] can be merged using a simple linear-time algorithm.</p>
<pre><code>MergeSort( A[1..n] )
    if (n &gt; 1)
        m &lt;- floor(n / 1)
        MergeSort( A[1..m] )
        MergeSort( A[m+1..n] )
        Merge( A[1..n], m )

Merge( A[1..n], m )
    i &lt;- 1
    j &lt;- m+1
    for k &lt;- 1 to n
        if j &gt; n
</code></pre>
<h4><a class="header" href="#radix-sort" id="radix-sort">Radix Sort</a></h4>
<h4><a class="header" href="#sorting-networks" id="sorting-networks">Sorting Networks</a></h4>
<h3><a class="header" href="#searching" id="searching">Searching</a></h3>
<h4><a class="header" href="#arrays-1" id="arrays-1">Arrays</a></h4>
<p>Unordered arrays offer faster insertion but slow searching and deletion.
Ordered arrays offer faster search by using binary search.</p>
<h4><a class="header" href="#binary-search" id="binary-search">Binary Search</a></h4>
<pre><code>int find(double searchkey) {
    int lowerbound = 0;
    int upperbound = array.size(); // array is a global vector&lt;double&gt;
    int curin; // current index

    while (true) {
        curin = (lowerbound + upperbound) / 2;
        if (array[curin] == searchkey) {
            return searchkey;
        }
        else {
            if (lowerbound &gt; upperbound) {
                return array.size(); // can't find it
            }
            else {
                if (array[curin] &lt; searchkey) {
                    lowerbound = curin + 1; // it's in the upper half
                }
                else {
                    upperbound = curin - 1; // it's in the lower half
                }
            }
        }
    }
}
</code></pre>
<h4><a class="header" href="#spatial-search" id="spatial-search">Spatial Search</a></h4>
<h3><a class="header" href="#greedy-algorithms" id="greedy-algorithms">Greedy Algorithms</a></h3>
<h3><a class="header" href="#divide-and-conquer-algorithms" id="divide-and-conquer-algorithms">Divide And Conquer Algorithms</a></h3>
<h3><a class="header" href="#dynamic-algorithms" id="dynamic-algorithms">Dynamic Algorithms</a></h3>
<h3><a class="header" href="#string-algorithms" id="string-algorithms">String Algorithms</a></h3>
<h3><a class="header" href="#matrix-algorithms" id="matrix-algorithms">Matrix Algorithms</a></h3>
<h3><a class="header" href="#randomized-algorithms" id="randomized-algorithms">Randomized Algorithms</a></h3>
<h3><a class="header" href="#computational-geometry-algorithms" id="computational-geometry-algorithms">Computational Geometry Algorithms</a></h3>
<h3><a class="header" href="#numerical-algorithms" id="numerical-algorithms">Numerical Algorithms</a></h3>
<h4><a class="header" href="#euclids-algorithm-greatest-common-divisor" id="euclids-algorithm-greatest-common-divisor">Euclid's Algorithm: Greatest Common Divisor</a></h4>
<p>Let m and n be two positive integers.
The greatest common divisor of m and n, denoted gcd(m, n) is the largest integer
that divides both m and n exactly.
When gcd(m, n) = 1 we say that m and n are coprime.</p>
<pre><code>function gcd(m, n)
    i = min(m, n) + 1
    repeat
        i = i -1
    until i divides both m and n exactly
    return i
</code></pre>
<p>The time taken by this algorithm is in the order of the difference between the
smaller of the two arguments and their greatest cmmon divisor.
When m and n are of similar size and coprime, it therefore takes a time in the
order of n.
Notice that this is the value of the operand and not its size.</p>
<p>A classic algorithm for calculating gcd(m, n) consists of first factorizing
m and n, and then taking the product of the prime factors common to m and n,
each primer factor being raised to the lower of its power s in the two
arguments.
Even though this algorithm is better than the one given previously, it requires
factorizing m and n, something which crurrently cannot be done efficiently when
m and n are large.</p>
<p>There exists a much better algorithm known as Euclid's algorithm.</p>
<pre><code>function euclid(m, n)
    while m &gt; 0 do
        t = m
        m = n mod m
        n = t
    return n
</code></pre>
<h4><a class="header" href="#fibonacci-sequence" id="fibonacci-sequence">Fibonacci Sequence</a></h4>
<h3><a class="header" href="#bit-manipulation-algorthms" id="bit-manipulation-algorthms">Bit Manipulation Algorthms</a></h3>
<h2><a class="header" href="#an-algorithm-for-algorithmic-technical-interview-questions" id="an-algorithm-for-algorithmic-technical-interview-questions">An algorithm for algorithmic technical interview questions</a></h2>
<p>After solving dozens of practice questions, I started to notice a strategy
emerge for how I solve technical interview questions. This framework isn’t
guaranteed to get you the job; however, the perspective will hopefully help in
your practice regimen.</p>
<p>The algorithm is roughly as follows:</p>
<p>1 Repeat the problem statement a few times in your head.</p>
<p>2 Jot down key pieces of information: input domain (numbers, strings, etc),
whether or not the inputs are sorted, the type of data structure we’re dealing
with (binary search tree or not, singly or doubly linked list, a single or
multi-dimensional array), a suggested traversal method (breadth-first or
depth-first), or a desired implementation style (recursive or iterative).</p>
<p>3 Actively think about edge cases (i.e., inputs that could break your solution)
to clarify with the interviewer and run through when testing the solution you
decide to code.</p>
<p>4 Acknowledge the brute-force solution (that usually smacks you in the face).</p>
<p>5 Analyze the (usually quadratic, factorial, or exponential) time and (typically
constant) space complexity of that brute-force approach.</p>
<p>6 Think about a solution that optimizes for time complexity (i.e., use more
space for time savings). I usually ask myself: what are the redundant
computations or what can I store (and in which data structure) to reduce the
workload?</p>
<p>7 Think about a solution that optimizes for space complexity (i.e., takes longer
to run but uses less space). It’ll hopefully be more efficient (in time
complexity) than the brute-force approach. If we’re dealing with a list of
inputs, I usually ask myself: is there a way to (in-place) sort the inputs
(if they’re not already sorted) to achieve an O(n log n) runtime with O(1)
space? Or is there a way of using a few variables/pointers while iterating to
achieve an O(n) time and O(1) space solution?</p>
<p>8 Avoid committing to any solution — leaving a little time to see if any other
approaches to come to mind. Typically the current problem resembles another
problem that you’ve solved and a technique used in that solved problem can be
applied.</p>
<p>9 Ask the interviewer what we’re optimizing for (usually runtime) and narrow
down your set of solutions to a single one to code.</p>
<p>10 Outline the structure of the solution (I tend do it on the side of the
whiteboard) either with high level functions (input, purpose of the method, and
its output) or the order of loops and conditions.</p>
<p>11 Start writing code (slowly and carefully) that models the outline.</p>
<p>12 Do a light pass code review of my solution making sure it is syntactically
correct and not introducing idioms that utilize extra space/time (i.e., creating
intermediate arrays or doing implicit passes through the entire array) that
result in a different (possibly quadratic) runtime complexity than desired.</p>
<p>13 Run through your code with normal and edge-case inputs — correcting any bugs
in your solution.</p>
<p>14 If there is a follow-up tweak to the original problem, think about how to
reuse the previously implemented method(s) to implement the tweak.</p>
<p>15 Apply the same principles of analysis from this list to the follow-up
question’s solution.</p>
<h2><a class="header" href="#miscellaneous" id="miscellaneous">Miscellaneous</a></h2>
<h4><a class="header" href="#implementation" id="implementation">Implementation:</a></h4>
<ul>
<li>Recursion/Iteration</li>
<li>Logical</li>
<li>Serial/Parallel/Distributed</li>
<li>Deterministic/Non-deterministic</li>
<li>Exact/Approximate</li>
</ul>
<h4><a class="header" href="#design-paradigm" id="design-paradigm">Design Paradigm:</a></h4>
<ul>
<li>Brute Force/Exhaustive Search</li>
<li>Divide and Conquer</li>
<li>Dynamic Programming</li>
<li>Greedy</li>
<li>Linear Programming</li>
<li>Reduction</li>
<li>Search and Enumeration</li>
<li>Probabilistic &amp; Heuristic Paradigm
<ul>
<li>Probabilistic Algorithms</li>
<li>Genetic Algorithms</li>
<li>Heuristics Algorithms</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#field-of-study" id="field-of-study">Field of Study:</a></h4>
<ul>
<li>Search Algorithms</li>
<li>Sorting Algorithms</li>
<li>Merge Algorithms</li>
<li>Numerical Algorithms</li>
<li>Graph Algorithms</li>
<li>String Algorithms</li>
<li>Computational Geometry</li>
<li>Combinatorial Algorithms</li>
<li>Machine Learning</li>
<li>Cryptography</li>
<li>Data Compression Algorithms</li>
<li>Parsing Techniques</li>
</ul>
<h1><a class="header" href="#ai" id="ai">AI</a></h1>
<h1><a class="header" href="#artificial-intelligencetimeline" id="artificial-intelligencetimeline">Artificial IntelligenceTimeline</a></h1>
<p>Copyright © 1997 Atool Varma and Nathan Erhardt</p>
<ul>
<li>http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/BriefHistory</li>
<li>http://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence</li>
<li>http://biology.kenyon.edu/slonc/bio3/AI/TIMELINE/timeline.html</li>
</ul>
<pre><code>Antiquity                   Greek myths of Hephaestus, the blacksmith who manufactured mechanical servants, and the bronze man Talos incorporate the idea of intelligent robots. Many other myths in antiquity involve human-like artifacts. Many mechanical toys and models were actually constructed, e.g., by Archytas of Tarentum,Hero, Daedalus and other real persons.
Antiquity                   Greek myths of Hephaestus and Pygmalion incorporated the idea of intelligent robots (such as Talos) and artificial beings (such as Galatea and Pandora).[1]
Antiquity                   Yan Shi presented King Mu of Zhou with mechanical men.[2]
Antiquity                   Sacred mechanical statues built in Egypt and Greece were believed to be capable of wisdom and emotion. Hermes Trismegistus would write &quot;they have sensus and spiritus ... by discovering the true nature of the gods, man has been able to reproduce it.&quot; Mosaic law prohibits the use of automatons in religion.[3]

384 BC–322 BC               Aristotle described the syllogism, a method of formal, mechanical thought.

1st century                 Heron of Alexandria created mechanical men and other automatons.[4]
260                         Porphyry of Tyros wrote Isagogê which categorized knowledge and logic.[5]

5th century B.C.            Aristotle invented syllogistic logic, the first formal deductive reasoning system.
~800                        Geber (Jabir ibn Hayyan) develops the Arabic alchemical theory of Takwin, the artificial creation of life in the laboratory, up to and including human life.[6]
13th century                Talking heads were said to have been created, Roger Bacon and Albert the Great reputedly among the owners.
                            Ramon Lull, Spanish theologian, invented machines for discovering nonmathematical truths through combinatorics.
1206                        Al-Jazari created a programmable orchestra of mechanical human beings.[7]
1275                        Ramon Llull, Catalan theologian invents the Ars Magna, a tool for combining concepts mechanically, based on an Arabic astrological tool, the Zairja. The method would be developed further by Gottfried Leibniz in the 17th century.[8]

15th century                Invention of printing using moveable type. Gutenberg Bible printed (1456).

15th-16th century           Clocks, the first modern measuring machines, were first produced using lathes.
16th century                Clockmakers extended their craft to creating mechanical animals and other novelties. For example, see DaVinci's walking lion (1515).
                            Rabbi Loew of Prague is said to have invented the Golem, a clay man brought to life (1580).
~1500                       Paracelsus claimed to have created an artificial man out of magnetism, sperm and alchemy.[9]
~1580                       Rabbi Judah Loew ben Bezalel of Prague is said to have invented the Golem, a clay man brought to life.[10]

Early 17th century          René Descartes proposed that bodies of animals are nothing more than complex machines (but that mental phenomena are of a different &quot;substance&quot;).[11]
17th century                Early in the century, Descartes proposed that bodies of animals are nothing more than complex machines. Many other 17th century thinkers offered variations and elaborations of Cartesian mechanism.
                            Pascal created the first mechanical digital calculating machine (1642).
                            Thomas Hobbes published The Leviathan (1651), containing a mechanistic and combinatorial theory of thinking.
                            Leibniz improved Pascal's machine to do multiplication &amp; division with a machine called the Step Reckoner (1673) and envisioned a universal calculus of reasoning by which arguments could be decided mechanically.
1623                        Wilhelm Schickard created the first mechanical calculating machine.
1641                        Thomas Hobbes published Leviathan and presented a mechanical, combinatorial theory of cognition. He wrote &quot;...for reason is nothing but reckoning&quot;.[12][13]
1652                        Blaise Pascal created the second mechanical and first digital calculating machine[14]
1672                        Gottfried Leibniz improved the earlier machines, making the Stepped Reckoner to do multiplication and division. He also invented the binary numeral system and envisioned a universal calculus of reasoning (alphabet of human thought) by which arguments could be decided mechanically. Leibniz worked on assigning a specific number to each and every object in the world, as a prelude to an algebraic solution to all possible problems.[15]

18th century                The 18th century saw a profusion of mechanical toys, including the celebrated mechanical duck of Vaucanson and von Kempelen's phony mechanical chess player, The Turk (1769). For Edgar Allen Poe's description of the Turk, see Poe Writes about Maelzel's Chess Player April 1836.
1727                        Jonathan Swift published Gulliver's Travels, which includes this description of the Engine, a machine on the island of Laputa: &quot;a Project for improving speculative Knowledge by practical and mechanical Operations &quot; by using this &quot;Contrivance&quot;, &quot;the most ignorant Person at a reasonable Charge, and with a little bodily Labour, may write Books in Philosophy, Poetry, Politicks, Law, Mathematicks, and Theology, with the least Assistance from Genius or study.&quot;[16] The machine is a parody of Ars Magna, one of the inspirations of Gottfried Leibniz' mechanism.
1750                        Julien Offray de La Mettrie published L'Homme Machine, which argued that human thought is strictly mechanical.[17]
1769                        Wolfgang von Kempelen built and toured with his chess-playing automaton, The Turk.[18] The Turk was later shown to be a hoax, involving a human chess player.

19th century                Luddites (led by Ned Ludd) destroyed machinery in England (1811-1816).
                            Mary Shelley published the story of Frankenstein's monster (1818).
                            George Boole developed a binary algebra representing (some) &quot;laws of thought,&quot; published in The Laws of Thought.  
                            Charles Babbage &amp; Ada Byron (Lady Lovelace) designed a programmable mechanical calculating machines. A working model was built in 2002; a short video shows it working.
                            Modern propositional logic developed by Gottlob Frege in his 1879 work Begriffsschrift and later clarified and expanded by Russell, Tarski, Godel, Church and others.
1818                        Mary Shelley published the story of Frankenstein; or the Modern Prometheus, a fictional consideration of the ethics of creating sentient beings.[19]
1822–1859                   Charles Babbage &amp; Ada Lovelace worked on programmable mechanical calculating machines.[20]
1837                        The mathematician Bernard Bolzano made the first modern attempt to formalize semantics.
1854                        George Boole set out to &quot;investigate the fundamental laws of those operations of the mind by which reasoning is performed, to give expression to them in the symbolic language of a calculus&quot;, inventing Boolean algebra.[21]
1863                        Samuel Butler suggested that Darwinian evolution also applies to machines, and speculates that they will one day become conscious and eventually supplant humanity.[22]
1913                        Bertrand Russell and Alfred North Whitehead published Principia Mathematica, which revolutionized formal logic.
1915                        Leonardo Torres y Quevedo built a chess automaton, El Ajedrecista and published speculation about thinking and automata.[23]
1917                        Karel Capek coins the term `robot' (in Czech `robot' means `worker', but the English translation retained the original word).
1923                        Karel Čapek's play R.U.R. (Rossum's Universal Robots) opened in London. This is the first use of the word &quot;robot&quot; in English.[24]
1920s and 1930s             Ludwig Wittgenstein and Rudolf Carnap lead philosophy into logical analysis of knowledge. Alonzo Church develops Lambda Calculus to investigate computability using recursive functional notation.
1928                        John von Neumann's minimax theorem (later used in game playing programs).
1931                        Kurt Gödel showed that sufficiently powerful consistent formal systems permit the formulation of true theorems that are unprovable by any theorem-proving machine deriving all possible theorems from the axioms. To do this he had to build a universal, integer-based programming language, which is the reason why he is sometimes called the &quot;father of theoretical computer science&quot;.
1941                        Konrad Zuse built the first working program-controlled computers.[25]
1943                        McCulloch and Pitt propose neural-network architectures for intelligence.  
1943                        Warren Sturgis McCulloch and Walter Pitts publish &quot;A Logical Calculus of the Ideas Immanent in Nervous Activity&quot; (1943), laying foundations for artificial neural networks.[26]
1943                        Arturo Rosenblueth, Norbert Wiener and Julian Bigelow coin the term &quot;cybernetics&quot;. Wiener's popular book by that name published in 1948.
1945                        Game theory which would prove invaluable in the progress of AI was introduced with the 1944 paper, Theory of Games and Economic Behavior by mathematician John von Neumann and economist Oskar Morgenstern.
1945                        Vannevar Bush published As We May Think (The Atlantic Monthly, July 1945) a prescient vision of the future in which computers assist humans in many activities.
1948                        John von Neumann (quoted by E.T. Jaynes) in response to a comment at a lecture that it was impossible for a machine to think: &quot;You insist that there is something a machine cannot do. If you will tell me precisely what it is that a machine cannot do, then I can always make a machine which will do just that!&quot;. Von Neumann was presumably alluding to the Church-Turing thesis which states that any effective procedure can be simulated by a (generalized) computer.
1950                        Isaac Asimov, &quot;I, Robot&quot;
1950                        Shannon proposes chess program
1950                        Turing Test proposed (Turing's &quot;Computing Machinery and Intelligence&quot;)
1950                        Alan Turing proposes the Turing Test as a measure of machine intelligence.[27]
1950                        Claude Shannon published a detailed analysis of chess playing as search.
1950                        Isaac Asimov published his Three Laws of Robotics.
1951                        The first working AI programs were written in 1951 to run on the Ferranti Mark 1 machine of the University of Manchester: a checkers-playing program written by Christopher Strachey and a chess-playing program written by Dietrich Prinz.
1954                        Isaac Asimov, &quot;The Caves of Steel&quot; (Robot Science Fiction)
1955                        The first Dartmouth College summer AI conference is organized by John McCarthy, Marvin Minsky, Nathan Rochester of IBM and Claude Shannon.
1955                        Newell, Shaw, and Simon develop &quot;IPL-11&quot;, first AI language

1956                        Newell, Shaw, and Simon create &quot;The Logic Theorist&quot;, a program that solves math problems.
1956                        The name artificial intelligence is used for the first time as the topic of the second Dartmouth Conference, organized by John McCarthy[30]
1956                        AI named at Dartmouth computer conference, first meeting of McCarthy, Minsky, Newell, and Simon.
1956                        The first demonstration of the Logic Theorist (LT) written by Allen Newell, J.C. Shaw and Herbert Simon (Carnegie Institute of Technology, now Carnegie Mellon University). This is often called the first AI program, though Samuel's checkers program also has a strong claim.
1956                        CIA funds GAT machine-translation project.
1956                        Ulam develops &quot;MANIAC I&quot;, the first chess program to beat a human being.

1957                        The General Problem Solver (GPS) demonstrated by Newell, Shaw and Simon.
1957                        Chomsky writes &quot;Syntactic Structures&quot;
1957                        Newell, Shaw, &amp; Simon create General Problem Solver (GPS) means-ends analysis

1958                        McCarthy introduces &quot;LISP&quot; at MIT
1958                        John McCarthy (Massachusetts Institute of Technology or MIT) invented the Lisp programming language.
1958                        Herb Gelernter and Nathan Rochester (IBM) described a theorem prover in geometry that exploits a semantic model of the domain in the form of diagrams of &quot;typical&quot; cases.
1958                        Teddington Conference on the Mechanization of Thought Processes was held in the UK and among the papers presented were John McCarthy's Programs with Common Sense, Oliver Selfridge's Pandemonium, and Marvin Minsky's Some Methods of Heuristic Programming and Artificial Intelligence.

1959                        John McCarthy and Marvin Minsky founded the MIT AI Lab.
1959                        Minsky and McCarthy establish MIT AI lab
1959                        Rosenblatt introduces Perceptron.
1959                        Samuel's checkers program wins games against best human players.  

Late 1950s, early 1960s     Margaret Masterman and colleagues at University of Cambridge design semantic nets for machine translation.
1960s                       Ray Solomonoff lays the foundations of a mathematical theory of AI, introducing universal Bayesian methods for inductive inference and prediction.

1960                        Bar-Hillel publishes a paper describing difficulty of machine translation.
1960                        Man-Computer Symbiosis by J.C.R. Licklider.

1961                        James Slagle (PhD dissertation, MIT) wrote (in Lisp) the first symbolic integration program, SAINT, which solved calculus problems at the college freshman level.
1961                        In Minds, Machines and Gödel, John Lucas[31] denied the possibility of machine intelligence on logical or philosophical grounds. He referred to Kurt Gödel's result of 1931: sufficiently powerful formal systems are either inconsistent or allow for formulating true theorems unprovable by any theorem-proving AI deriving all provable theorems from the axioms. Since humans are able to &quot;see&quot; the truth of such theorems, machines were deemed inferior.

1952–1962                   Arthur Samuel (IBM) wrote the first game-playing program,[28] for checkers (draughts), to achieve sufficient skill to challenge a respectable amateur. His first checkers-playing program was written in 1952, and in 1955 he created a version that learned to play.[29]
1962                        McCarthy moves to Stanford, founding Stanford AI Lab in 1963.
1962                        First commercial industrial robots.
1962                        First industrial robot company, Unimation, founded.

1963                        Thomas Evans' program, ANALOGY, written as part of his PhD work at MIT, demonstrated that computers can solve the same analogy problems as are given on IQ tests.
1963                        Edward Feigenbaum and Julian Feldman published Computers and Thought, the first collection of articles about artificial intelligence.
1963                        Leonard Uhr and Charles Vossler published &quot;A Pattern Recognition Program That Generates, Evaluates, and Adjusts Its Own Operators&quot;, which described one of the first machine learning programs that could adaptively acquire and modify features and thereby overcome the limitations of simple perceptrons of Rosenblatt
1963                        ARPA gives $2 million grant to MIT AI Lab.
1963                        Sutherland's SKETCHPAD: drawing tool (CAD), constraint solver, WYSIWYG
1963                        M. Ross Quillian  (semantic networks as a knowledge representation)
1963                        Susumo Kuno's parser tested on &quot;Time flies like an arrow&quot;
1963                        Minsky's &quot;Steps towards Artificial Intelligence&quot;

1964                        Bobrow's STUDENT (solves high-school algebra word problems)
1964                        Development of BBNLisp begins at BBN

1965                        Buchanan, Feigenbaum &amp; Lederberg begin DENDRAL expert system project.
1965                        Iva Sutherland demonstrates first head-mounted display (virtual reality)
1965                        Simon predicts, &quot;by 1985 machines will be capable of doing any work a man can do&quot;
1965                        Dreyfus argues against the possibility of AI.

1966                        Donald Michie founds Edinburgh AI lab.
1966                        Weizanbaum's ELIZA

1967                        Greenblatt's MacHack defeats Hubert Deyfus at chess.
1967                        &quot;HAL&quot; stars in Clarke and Kubrick's &quot;2001&quot;

1968                        Minsky's &quot;Semantic Information Processing&quot;
1968                        Chomsky and Halle's &quot;The Sound Pattern of English&quot;

1969                        Minsky &amp; Papert's &quot;Perceptions&quot; (limits of single-layer neural networks)
1969                        Hearn &amp; Griss define Standard Lisp to port the REDUCE symbolic algebra system.  

1970                        PROLOG (Colmerauer)
1970                        Pople and Myers begin INTERNIST (aid in diagnosis of human diseases)
1970                        Terry Winograd's SHRDLU (Natural Language Processing, Blocks World)
1970                        Winston's ARCH

1971                        Colby's PARRY

1972                        Dreyfus publishes &quot;What Computer's Can't Do&quot;
1972                        Smalltalk developed at Xerox PARC (Kay)

1973                        Lighthill report kills AI funding in UK.
1973                        Schank and Alberson develop scripts.

1974                        Edward Shortliffe's thesis on MYCIN.
1974                        First computer-controlled robot.
1974                        Minsky's &quot;A Framework for Representing Knowledge&quot;.
1974                        SUMEX-AIM network established (applications of AI to medicine)

1975                        Cooper &amp; Erlbaum found Nestor to develop neural net technology.
1975                        DARPA launches image understanding funding program.
1975                        Larry Harris founds Artificial Intelligence Corp.  (NLP)

1976                        Adventure (Crowther and Woods) - first adventure game.
1976                        Greenblatt creates first LISP machine, &quot;CONS&quot;
1976                        Kurzweil introduces reading machine.
1976                        Lenat's AM (Automated Mathematician)
1976                        Marr's primal sketch as a visual presentation.

1977                        C3PO and R2D2 star in &quot;Star Wars&quot;.

1978                        Marr and Nishihara propose 2-1/2 dimensional sketch
1978                        Xerox LISP machines
1978                        Tom Mitchell, at Stanford, invented the concept of Version Spaces for describing the search space of a concept formation program.
1978                        Herb Simon wins the Nobel Prize in Economics for his theory of bounded rationality, one of the cornerstones of AI known as &quot;satisficing&quot;.
1978                        The MOLGEN program, written at Stanford by Mark Stefik and Peter Friedland, demonstrated that an object-oriented representation of knowledge can be used to plan gene-cloning experiments.

1979                        Raj Reddy founds Robotics Institute at Carnegie Mellon University.
1979                        MYCIN as good as medical experts (Journal of American Medical Assoc.)
1979                        Publication of Weinreb and Moon's MIT AI Lab memo on Flavors, an OOP offering advanced capabilities still not generally unavailable outside the LISP language family.  
1979                        Bill VanMelle's PhD dissertation at Stanford demonstrated the generality of MYCIN's representation of knowledge and style of reasoning in his EMYCIN program, the model for many commercial expert system &quot;shells&quot;.
1979                        Jack Myers and Harry Pople at University of Pittsburgh developed INTERNIST, a knowledge-based medical diagnosis program based on Dr. Myers' clinical knowledge.
1979                        Cordell Green, David Barstow, Elaine Kant and others at Stanford demonstrated the CHI system for automatic programming.
1979                        The Stanford Cart, built by Hans Moravec, becomes the first computer-controlled, autonomous vehicle when it successfully traverses a chair-filled room and circumnavigates the Stanford AI Lab.
1979                        Drew McDermott &amp; Jon Doyle at MIT, and John McCarthy at Stanford begin publishing work on non-monotonic logics and formal aspects of truth maintenance.

1980's                      Lisp Machines developed and marketed.
                            First expert system shells and commercial applications.
1980                        Expert systems up to a thousand rules.
1980                        First AAAI conference at Stanford.
1980                        Greenblatt &amp; Jacobson found LMI; Noftsker starts Symbolics.
1980                        Hofstader writes &quot;G\&quot;odel, Escher, Bach&quot;, wins Pulitzer.
1980                        McDermott's XCON for configuring VAX systems (DEC and CMU)
1980                        First biannual ACM LISP and Functional Programming Conference.
1980                        Lee Erman, Rick Hayes-Roth, Victor Lesser and Raj Reddy published the first description of the blackboard model, as the framework for the HEARSAY-II speech understanding system.
                            First National Conference of the American Association of Artificial Intelligence (AAAI) held at Stanford.
1981                        Kazuhiro Fuchi announces Japanese Fifth Generation project.
1981                        MITI wants intelligent computers by 1990.
1981                        Teknowledge founded by Feigenbaum.
1981                        PSL (Portable Standard Lisp) runs on a variety of platforms.
1981                        Lisp machines from Xerox, LMI, and Symbolics available commercially, making dynamic OOP technology available on a widespread basis.
1981                        Grass roots definition of Common Lisp as the common aspects of the family of languages- Lisp Machine Lisp, MacLisp, NIL, S-1 Lisp, Spice Lisp, Scheme.
1981                        Danny Hillis designs the connection machine, a massively parallel architecture that brings new power to AI, and to computation in general. (Later founds Thinking Machines, Inc.)

1982                        Publication of British government's &quot;Alvey Report&quot; on advanced information technology, leading to boost in Ai (Expert Systems) being used in industry.
1982                        Japan's ICOT formed.
1982                        John Hopfield resuscitates neural nets.
1982                        SRI's PROSPECTOR finds major deposit of molybdenum.

1983                        Asimov writes &quot;Robot's of Dawn&quot;.
1983                        Feigenbaum &amp; McCorduck publish &quot;The Fifth Generation&quot;.
1983                        DARPA announced Strategic Computing Initiative.
1983                        IntelliGenetics markets KEE.
1983                        MCC consortium formed under Bobby Ray Inman.
1983                        John Laird &amp; Paul Rosenbloom, working with Allen Newell, complete CMU dissertations on SOAR.
1983                        James Allen invents the Interval Calculus, the first widely used formalization of temporal events.

1984                        Publication of Steele's &quot;Common Lisp the Language&quot;
1984                        Chamberlain's RACTER `writes' book
1984                        Doug Lenat begins CYC project at MCC.
1984                        European Community starts ESPRIT program.
1984                        GM puts $4 million into Teknowledge.
1984                        Gold Hill creates Golden Common LISP.
1984                        TI wins MIT contract for Lisp machines away from Symbolics.
1984                        &quot;Wabot-2&quot; reads sheet music and plays organ.

1985                        GM and Campbell's Soup don't use Lisp for expert systems.
1985                        Kawasaki robot kills Japanese mechanic during malfunction.
1985                        MIT Media Lab founded.
1985                        Minsky publishes &quot;The Society of Mind&quot;
1985                        Palladian sells Financial Adviser.
1985                        Teknowledge abandons LISP and PROLOG for C.

Mid 80's                    Neural Networks become widely used with the Backpropagation algorithm (first described by Werbos in 1974).

1985                        Xerox wins $20 million contract for LISP machines, later cancelled.
1985                        The autonomous drawing program, Aaron, created by Harold Cohen, is demonstrated at the AAAI National Conference (based on more than a decade of work, and with subsequent work showing major developments).

1986                        X3J13 forms to produce a draft for an ANSI Common Lisp standard.
1986                        AI industry revenue now $1,000,000,000
1986                        Anderson's robotic Ping-Pong player wins against human.
1986                        Borland offers Turbo PROLOG for $99.
1986                        CMU's HiTech chess machine competes at senior master level.
1986                        Dallas Police use robot to break into an apartment.
1986                        First OOPSLA conference on object-oriented programming, at which CLOS is first publicized outside the Lisp/AI community.
1986                        IBM enters AI fray at AAAI, with a LISP, a PROLOG, and an ES shell.
1986                        Max Headroom
1986                        McClelland &amp; Rumelhart's &quot;Parallel Distributed Processing&quot; (Neural Nets)
1986                        Neural net startup companies appear.
1986                        OCR now $100 million industry.
1986                        PICON ES group leaves LMI and starts Gensym.
1986                        Paperback Software offers VP Expert for $99.
1986                        Teknowledge goes public, amid wild optimism.
1986                        Thinking Machines introduces Connection Machine.

1987                        Symbolics pioneers the OODB market with Statice, a Flavors-based system.
1987                        Lisp Pointers commences publication.
1987                        1,900 computers are working Expert systems.
1987                        AI revenue $1.4 billion, excluding robotics.
1987                        NLP revenue approximately $80 million.
1987                        Robotic-vision revenue $300 million.
1987                        DEC's &quot;XCON&quot; configures computers doing work of 300 people using 10,000 rules.
1987                        Japan's AFIS (Automated Fingerprint Identifacation System)
1987                        LMI files for bankruptcy, other bankruptcies and layoffs follow.
1987                        &quot;Ai Winter&quot;; Lisp-machine market saturated.
1987                        Marvin Minsky publishes The Society of Mind, a theoretical description of the mind as a collection of cooperating agents.

1988                        Common Lisp development environments on general- purpose platforms begin to rival those available on Lisp Machines (e.g., native CLOS, pre-emptive multitasking, full suites of integrated tools, etc.)
1988                        386 chip brings PC speeds into competition with LISP machines.
1988                        Expert systems revenue over $400 million.
1988                        Hillis's &quot;Connection Machine&quot;, capable of 65,536 parallel computations.
1988                        Minsky and Papert publish revised edition of &quot;Perceptrons&quot;
1988                        Object-oriented languages are &quot;in&quot;.
1988                        TI announces MicroExplorer (Macintosh with a LISP machine)
1988                        Teknowledge merges with American Cimflex.

1989                        Coral sold to Apple, re-marketed as Macintosh Allegro Common Lisp.
1989                        Palladian ceases production.  
1989                        Dean Pomerleau at CMU creates ALVINN (An Autonomous Land Vehicle in a Neural Network), which grew into the system that drove a car coast-to-coast under computer control for all but about 50 of the 2850 miles.

Early 90's                  TD-Gammon, a backgammon program written by Gerry Tesauro, demonstrates that reinforcement learning is powerful enough to create a championship-level game-playing program by competing favorably with world-class players.
1990's                      Major advances in all areas of AI, with significant demonstrations in machine learning, intelligent tutoring, case-based reasoning, multi-agent planning, scheduling, uncertain reasoning, data mining, natural language understanding and translation, vision, virtual reality, games, and other topics.
                            Rod Brooks' COG Project at MIT, with numerous collaborators, makes significant progress in building a humanoid robot
1990                        Steele publishes second edition of &quot;Common Lisp the Language&quot;
1990                        AICorp goes public.
1990                        Symbolics Lisp Users Group (SLUG) votes to expand its charter into an Association of Lisp Users, and to expand the scope of its annual conference correspondingly.

1991                        KnowlegeWare cancels offer to buy IntelliCorp.

1992                        Apple Computer introduces Dylan, a language in the Lisp family as its vision for the future of programming.
1992                        X3J13 creates a draft proposed American National Standard for Common Lisp.

1993                        Kurweil AI goes public.
1993                        Symbolics files for bankruptcy.

1994                        Franz Inc. announces the AllegroStore OODB.
1994                        Harlequin's real-time CLOS is used in an announced AT&amp;T switching system.
1994                        Thinking Machines files for bankruptcy.
1994                        (Projected) ANSI Common Lisp becomes the first ANSI-standard OOPL.

1997                        The Deep Blue chess program beats the current world chess champion, Garry Kasparov, in a widely followed match.
1997                        First official Robo-Cup soccer match featuring table-top matches with 40 teams of interacting robots and over 5000 spectators.

Late 90's                   Web crawlers and other AI-based information extraction programs become essential in widespread use of the world-wide-web.
                            Demonstration of an Intelligent Room and Emotional Agents at MIT's AI Lab. Initiation of work on the Oxygen Architecture, which connects mobile and stationary computers in an adaptive network.
Late 1990s                  Web crawlers and other AI-based information extraction programs become essential in widespread use of the World Wide Web.
Late 1990s                  Demonstration of an Intelligent room and Emotional Agents at MIT's AI Lab.
Late 1990s                  Initiation of work on the Oxygen architecture, which connects mobile and stationary computers in an adaptive network.

2000                        Interactive robot pets (a.k.a. &quot;smart toys&quot;) become commercially available, realizing the vision of the 18th cen. novelty toy makers.
2000                        Cynthia Breazeal at MIT publishes her dissertation on Sociable Machines, describing KISMET, a robot with a face that expresses emotions.
2000                        The Nomad robot explores remote regions of Antarctica looking for meteorite samples.
2000                        Interactive robopets (&quot;smart toys&quot;) become commercially available, realizing the vision of the 18th century novelty toy makers.
2000                        Cynthia Breazeal at MIT publishes her dissertation on Sociable machines, describing Kismet (robot), with a face that expresses emotions.
2000                        The Nomad robot explores remote regions of Antarctica looking for meteorite samples.

2004                        OWL Web Ontology Language W3C Recommendation (10 February 2004).
2004                        DARPA introduces the DARPA Grand Challenge requiring competitors to produce autonomous vehicles for prize money.

2005                        Honda's ASIMO robot, an artificially intelligent humanoid robot, is able to walk as fast as a human, delivering trays to customers in restaurant settings.
2005                        Recommendation technology based on tracking web activity or media usage brings AI to marketing. See TiVo Suggestions.
2005                        Blue Brain is born, a project to simulate the brain at molecular detail.[1].

2006                        The Dartmouth Artificial Intelligence Conference: The Next 50 Years (AI@50) AI@50 (14–16 July 2006)

2007                        Philosophical Transactions of the Royal Society, B – Biology, one of the world's oldest scientific journals, puts out a special issue on using AI to understand biological intelligence, titled Models of Natural Action Selection[37]
2007                        Checkers is solved by a team of researchers at the University of Alberta.










1964                        Danny Bobrow's dissertation at MIT (technical report #1 from MIT's AI group, Project MAC), shows that computers can understand natural language well enough to solve algebra word problems correctly.
1964                        Bertram Raphael's MIT dissertation on the SIR program demonstrates the power of a logical representation of knowledge for question-answering systems.
1965                        J. Alan Robinson invented a mechanical proof procedure, the Resolution Method, which allowed programs to work efficiently with formal logic as a representation language.
1965                        Joseph Weizenbaum (MIT) built ELIZA, an interactive program that carries on a dialogue in English language on any topic. It was a popular toy at AI centers on the ARPANET when a version that &quot;simulated&quot; the dialogue of a psychotherapist was programmed.
1965                        Edward Feigenbaum initiated Dendral, a ten-year effort to develop software to deduce the molecular structure of organic compounds using scientific instrument data. It was the first expert system.
1966                        Ross Quillian (PhD dissertation, Carnegie Inst. of Technology, now CMU) demonstrated semantic nets.
1966                        Machine Intelligence workshop at Edinburgh – the first of an influential annual series organized by Donald Michie and others.
1966                        Negative report on machine translation kills much work in Natural language processing (NLP) for many years.
1967                        Dendral program (Edward Feigenbaum, Joshua Lederberg, Bruce Buchanan, Georgia Sutherland at Stanford University) demonstrated to interpret mass spectra on organic chemical compounds. First successful knowledge-based program for scientific reasoning.
1968                        Joel Moses (PhD work at MIT) demonstrated the power of symbolic reasoning for integration problems in the Macsyma program. First successful knowledge-based program in mathematics.
1968                        Richard Greenblatt (programmer) at MIT built a knowledge-based chess-playing program, MacHack, that was good enough to achieve a class-C rating in tournament play.
1968                        Wallace and Boulton's program, Snob (Comp.J. 11(2) 1968), for unsupervised classification (clustering) uses the Bayesian Minimum Message Length criterion, a mathematical realisation of Occam's razor.
1969                        Stanford Research Institute (SRI): Shakey the Robot, demonstrated combining animal locomotion, perception and problem solving.
1969                        Roger Schank (Stanford) defined conceptual dependency model for natural language understanding. Later developed (in PhD dissertations at Yale University) for use in story understanding by Robert Wilensky and Wendy Lehnert, and for use in understanding memory by Janet Kolodner.
1969                        Yorick Wilks (Stanford) developed the semantic coherence view of language called Preference Semantics, embodied in the first semantics-driven machine translation program, and the basis of many PhD dissertations since such as Bran Boguraev and David Carter at Cambridge.
1969                        First International Joint Conference on Artificial Intelligence (IJCAI) held at Stanford.
1969                        Marvin Minsky and Seymour Papert publish Perceptrons, demonstrating previously unrecognized limits of this feed-forward two-layered structure. This book is considered by some to mark the beginning of the AI winter of the 1970s, a failure of confidence and funding for AI. Nevertheless significant progress in the field continued (see below).
1969                        McCarthy and Hayes started the discussion about the frame problem with their essay, &quot;Some Philosophical Problems from the Standpoint of Artificial Intelligence&quot;.
Early 1970s                 Jane Robinson and Don Walker established an influential Natural Language Processing group at SRI.
1970                        Jaime Carbonell (Sr.) developed SCHOLAR, an interactive program for computer assisted instruction based on semantic nets as the representation of knowledge.
1970                        Bill Woods described Augmented Transition Networks (ATN's) as a representation for natural language understanding.
1970                        Patrick Winston's PhD program, ARCH, at MIT learned concepts from examples in the world of children's blocks.
1971                        Terry Winograd's PhD thesis (MIT) demonstrated the ability of computers to understand English sentences in a restricted world of children's blocks, in a coupling of his language understanding program, SHRDLU, with a robot arm that carried out instructions typed in English.
1971                        Work on the Boyer-Moore theorem prover started in Edinburgh.[32]
1972                        Prolog programming language developed by Alain Colmerauer.
1972                        Earl Sacerdoti developed one of the first hierarchical planning programs, ABSTRIPS.
1973                        The Assembly Robotics Group at University of Edinburgh builds Freddy Robot, capable of using visual perception to locate and assemble models. (See Edinburgh Freddy Assembly Robot: a versatile computer-controlled assembly system.)
1973                        The Lighthill report gives a largely negative verdict on AI research in Great Britain and forms the basis for the decision by the British government to discontinue support for AI research in all but two universities.
1974                        Ted Shortliffe's PhD dissertation on the MYCIN program (Stanford) demonstrated a very practical rule-based approach to medical diagnoses, even in the presence of uncertainty. While it borrowed from DENDRAL, its own contributions strongly influenced the future of expert system development, especially commercial systems.
1975                        Earl Sacerdoti developed techniques of partial-order planning in his NOAH system, replacing the previous paradigm of search among state space descriptions. NOAH was applied at SRI International to interactively diagnose and repair electromechanical systems.
1975                        Austin Tate developed the Nonlin hierarchical planning system able to search a space of partial plans characterised as alternative approaches to the underlying goal structure of the plan.
1975                        Marvin Minsky published his widely-read and influential article on Frames as a representation of knowledge, in which many ideas about schemas and semantic links are brought together.
1975                        The Meta-Dendral learning program produced new results in chemistry (some rules of mass spectrometry) the first scientific discoveries by a computer to be published in a refereed journal.
Mid 1970s                   Barbara Grosz (SRI) established limits to traditional AI approaches to discourse modeling. Subsequent work by Grosz, Bonnie Webber and Candace Sidner developed the notion of &quot;centering&quot;, used in establishing focus of discourse and anaphoric references in Natural language processing.
Mid 1970s                   David Marr and MIT colleagues describe the &quot;primal sketch&quot; and its role in visual perception.
1976                        Douglas Lenat's AM program (Stanford PhD dissertation) demonstrated the discovery model (loosely-guided search for interesting conjectures).
1976                        Randall Davis demonstrated the power of meta-level reasoning in his PhD dissertation at Stanford.
1978                        Tom Mitchell, at Stanford, invented the concept of Version Spaces for describing the search space of a concept formation program.
1978                        Herbert Simon wins the Nobel Prize in Economics for his theory of bounded rationality, one of the cornerstones of AI known as &quot;satisficing&quot;.
1978                        The MOLGEN program, written at Stanford by Mark Stefik and Peter Friedland, demonstrated that an object-oriented programming representation of knowledge can be used to plan gene-cloning experiments.
1979                        Bill VanMelle's PhD dissertation at Stanford demonstrated the generality of MYCIN's representation of knowledge and style of reasoning in his EMYCIN program, the model for many commercial expert system &quot;shells&quot;.
1979                        Jack Myers and Harry Pople at University of Pittsburgh developed INTERNIST, a knowledge-based medical diagnosis program based on Dr. Myers' clinical knowledge.
1979                        Cordell Green, David Barstow, Elaine Kant and others at Stanford demonstrated the CHI system for automatic programming.
1979                        The Stanford Cart, built by Hans Moravec, becomes the first computer-controlled, autonomous vehicle when it successfully traverses a chair-filled room and circumnavigates the Stanford AI Lab.
1979                        BKG, a backgammon program written by Hans Berliner at CMU, defeats the reigning world champion.
1979                        Drew McDermott and Jon Doyle at MIT, and John McCarthy at Stanford begin publishing work on non-monotonic logics and formal aspects of truth maintenance.
Late 1970s                  Stanford's SUMEX-AIM resource, headed by Ed Feigenbaum and Joshua Lederberg, demonstrates the power of the ARPAnet for scientific collaboration.
Early 1980s                 The team of Ernst Dickmanns at Bundeswehr University of Munich builds the first robot cars, driving up to 55 mph on empty streets.
1980s                       Lisp machines developed and marketed. First expert system shells and commercial applications.
1980                        First National Conference of the American Association for Artificial Intelligence (AAAI) held at Stanford.
1981                        Danny Hillis designs the connection machine, which utilizes Parallel computing to bring new power to AI, and to computation in general. (Later founds Thinking Machines Corporation)
1982                        The Fifth Generation Computer Systems project (FGCS), an initiative by Japan's Ministry of International Trade and Industry, begun in 1982, to create a &quot;fifth generation computer&quot; (see history of computing hardware) which was supposed to perform much calculation utilizing massive parallelism.
1983                        John Laird and Paul Rosenbloom, working with Allen Newell, complete CMU dissertations on Soar (program).
1983                        James F. Allen invents the Interval Calculus, the first widely used formalization of temporal events.
Mid 1980s                   Neural Networks become widely used with the Backpropagation algorithm (first described by Paul Werbos in 1974).
1985                        The autonomous drawing program, AARON, created by Harold Cohen, is demonstrated at the AAAI National Conference (based on more than a decade of work, and with subsequent work showing major developments).
1987                        Marvin Minsky published The Society of Mind, a theoretical description of the mind as a collection of cooperating agents. He had been lecturing on the idea for years before the book came out (c.f. Doyle 1983).
1987                        Around the same time, Rodney Brooks introduced the subsumption architecture and behavior-based robotics as a more minimalist modular model of natural intelligence; Nouvelle AI.
1989                        Dean Pomerleau at CMU creates ALVINN (An Autonomous Land Vehicle in a Neural Network).
Early 1990s                 TD-Gammon, a backgammon program written by Gerry Tesauro, demonstrates that reinforcement (learning) is powerful enough to create a championship-level game-playing program by competing favorably with world-class players.
1990s                       Major advances in all areas of AI, with significant demonstrations in machine learning, intelligent tutoring, case-based reasoning, multi-agent planning, scheduling, uncertain reasoning, data mining, natural language understanding and translation, vision, virtual reality, games, and other topics.
1991                        DART scheduling application deployed in the first Gulf War paid back DARPA's investment of 30 years in AI research.[33]
1993                        Ian Horswill extended behavior-based robotics by creating Polly, the first robot to navigate using vision and operate at animal-like speeds (1 meter/second).
1993                        Rodney Brooks, Lynn Andrea Stein and Cynthia Breazeal started the widely-publicized MIT Cog project with numerous collaborators, in an attempt to build a humanoid robot child in just five years.
1993                        ISX corporation wins &quot;DARPA contractor of the year&quot;[34] for the Dynamic Analysis and Replanning Tool (DART) which reportedly repaid the US government's entire investment in AI research since the 1950s.[35]
1994                        With passengers onboard, the twin robot cars VaMP and VITA-2 of Ernst Dickmanns and Daimler-Benz drive more than one thousand kilometers on a Paris three-lane highway in standard heavy traffic at speeds up to 130 km/h. They demonstrate autonomous driving in free lanes, convoy driving, and lane changes left and right with autonomous passing of other cars.
1995                        Semi-autonomous ALVINN steered a car coast-to-coast under computer control for all but about 50 of the 2850 miles. Throttle and brakes, however, were controlled by a human driver.
1995                        In the same year, one of Ernst Dickmanns' robot cars (with robot-controlled throttle and brakes) drove more than 1000 miles from Munich to Copenhagen and back, in traffic, at up to 120 mph, occasionally executing maneuvers to pass other cars (only in a few critical situations a safety driver took over). Active vision was used to deal with rapidly changing street scenes.
1997                        The Deep Blue chess machine (IBM) beats the world chess champion, Garry Kasparov.
1997                        First official RoboCup football (soccer) match featuring table-top matches with 40 teams of interacting robots and over 5000 spectators.
1998                        Tiger Electronics' Furby is released, and becomes the first successful attempt at producing a type of A.I to reach a domestic environment.
1998                        Tim Berners-Lee published his Semantic Web Road map paper.[36]
1999                        Sony introduces an improved domestic robot similar to a Furby, the AIBO becomes one of the first artificially intelligent &quot;pets&quot; that is also autonomous.













20th century - First Half   Bertrand Russell and Alfred North Whitehead published Principia Mathematica, which revolutionaized formal logic. Russell, Ludwig Wittgenstein, and Rudolf Carnap lead philosophy into logical analysis of knowledge.
                            Karel Capek's play &quot;R.U.R.&quot; (Rossum's Universal Robots) produced in 1921 (London opening, 1923). - First use of the word 'robot' in English.
                            Warren McCulloch &amp; Walter Pitts publish &quot;A Logical Calculus of the Ideas Immanent in Nervous Activity&quot; (1943), laying foundations for neural networks.
                            Arturo Rosenblueth, Norbert Wiener &amp; Julian Bigelow coin the term &quot;cybernetics&quot; in a 1943 paper. Wiener's popular book by that name published in 1948.
                            Emil Post proves that production systems are a general computational mechanism (1943). See Ch.2 of Rule Based Expert Systems for the uses of production systems in AI. Post also did important work on completeness, inconsistency, and proof theory.
                            George Polya published his best-selling book on thinking heuristically, How to Solve It in 1945. This book introduced the term 'heuristic' into modern thinking and has influenced many AI scientists.
                            Vannevar Bush published As We May Think (Atlantic Monthly, July 1945) a prescient vision of the future in which computers assist humans in many activities.
                            Grey Walter experimented with autonomous robots, turtles named Elsie and Elmer, at Bristol (1948-49) based on the premise that a small number of brain cells could give rise to complex behaviors.
                            A.M. Turing published &quot;Computing Machinery and Intelligence&quot; (1950). - Introduction of Turing Test as a way of operationalizing a test of intelligent behavior. See The Turing Institute for more on Turing.
                            Claude Shannon published detailed analysis of chess playing as search in &quot;Programming a computer to play chess&quot; (1950).
                            Isaac Asimov published his three laws of robotics (1950).
1956                        John McCarthy coined the term &quot;artificial intelligence&quot; as the topic of the Dartmouth Conference, the first conference devoted to the subject.
                            Demonstration of the first running AI program, the Logic Theorist (LT) written by Allen Newell, J.C. Shaw and Herbert Simon (Carnegie Institute of Technology, now Carnegie Mellon University).
1957                        The General Problem Solver (GPS) demonstrated by Newell, Shaw &amp; Simon.
1952-62                     Arthur Samuel (IBM) wrote the first game-playing program, for checkers, to achieve sufficient skill to challenge a world champion. Samuel's machine learning programs were responsible for the high performance of the checkers player.
1958                        John McCarthy (MIT) invented the Lisp language.
                            Herb Gelernter &amp; Nathan Rochester (IBM) described a theorem prover in geometry that exploits a semantic model of the domain in the form of diagrams of &quot;typical&quot; cases.
                            Teddington Conference on the Mechanization of Thought Processes was held in the UK and among the papers presented were John McCarthy's Programs with Common Sense, &quot; Oliver Selfridge's &quot;Pandemonium,&quot; and Marvin Minsky's &quot;Some Methods of Heuristic Programming and Artificial Intelligence.&quot;
Late 50's &amp; Early 60's      Margaret Masterman &amp; colleagues at Cambridge design semantic nets for machine translation. See Themes in the work of Margaret Masterman by Yorick Wilks (1988).
1961                        James Slagle (PhD dissertation, MIT) wrote (in Lisp) the first symbolic integration program, SAINT, which solved calculus problems at the college freshman level.
1962                        First industrial robot company, Unimation, founded.
1963                        Thomas Evans' program, ANALOGY, written as part of his PhD work at MIT, demonstrated that computers can solve the same analogy problems as are given on IQ tests.
                            Ivan Sutherland's MIT dissertation on Sketchpad introduced the idea of interactive graphics into computing.
                            Edward A. Feigenbaum &amp; Julian Feldman published Computers and Thought, the first collection of articles about artificial intelligence.
1964                        Danny Bobrow's dissertation at MIT (tech.report #1 from MIT's AI group, Project MAC), shows that computers can understand natural language well enough to solve algebra word problems correctly.
                            Bert Raphael's MIT dissertation on the SIR program demonstrates the power of a logical representation of knowledge for question-answering systems
1965                        J. Alan Robinson invented a mechanical proof procedure, the Resolution Method, which allowed programs to work efficiently with formal logic as a representation language. (See Carl Hewitt's history of logic programming).
                            Joseph Weizenbaum (MIT) built ELIZA, an interactive program that carries on a dialogue in English on any topic. It was a popular toy at AI centers on the ARPA-net when a version that &quot;simulated&quot; the dialogue of a psychotherapist was programmed.
1966                        Ross Quillian (PhD dissertation, Carnegie Inst. of Technology; now CMU) demonstrated semantic nets.
                            First Machine Intelligence workshop at Edinburgh - the first of an influential annual series organized by Donald Michie and others.
                            Negative report on machine translation kills much work in Natural Language Processing (NLP) for many years.
1967                        Dendral program (Edward Feigenbaum, Joshua Lederberg, Bruce Buchanan, Georgia Sutherland at Stanford) demonstrated to interpret mass spectra on organic chemical compounds. First successful knowledge-based program for scientific reasoning.
                            Joel Moses (PhD work at MIT) demonstrated the power of symbolic reasoning for integration problems in the Macsyma (PDF file) program. First successful knowledge-based program in mathematics.
                            Richard Greenblatt at MIT built a knowledge-based chess-playing program, MacHack, that was good enough to achieve a class-C rating in tournament play.
Late 60s                    Doug Engelbart invented the mouse at SRI.
1968                        Marvin Minsky &amp; Seymour Papert publish Perceptrons, demonstrating limits of simple neural nets.
1969                        SRI robot, Shakey, demonstrated combining locomotion, perception and problem solving.
                            Roger Schank (Stanford) defined conceptual dependency model for natural language understanding. Later developed (in PhD dissertations at Yale) for use in story understanding by Robert Wilensky and Wendy Lehnert, and for use in understanding memory by Janet Kolodner.
                            First International Joint Conference on Artificial Intelligence (IJCAI) held in Washington, D.C.
1970                        Jaime Carbonell (Sr.) developed SCHOLAR, an interactive program for computer-aided instruction based on semantic nets as the representation of knowledge.
                            Bill Woods described Augmented Transition Networks (ATN's) as a representation for natural language understanding.
                            Patrick Winston's PhD program, ARCH, at MIT learned concepts from examples in the world of children's blocks.
Early 70's                  Jane Robinson &amp; Don Walker established influential Natural Language Processing group at SRI.
1971                        Terry Winograd's PhD thesis (MIT) demonstrated the ability of computers to understand English sentences in a restricted world of children's blocks, in a coupling of his language understanding program, SHRDLU, with a robot arm that carried out instructions typed in English.
1972                        Prolog developed by Alain Colmerauer.
1973                        The Assembly Robotics group at Edinburgh University builds Freddy, the Famous Scottish Robot, capable of using vision to locate and assemble models.
1974                        Ted Shortliffe's PhD dissertation on MYCIN (Stanford) demonstrated the power of rule-based systems for knowledge representation and inference in the domain of medical diagnosis and therapy. Sometimes called the first expert system.
                            Earl Sacerdoti developed one of the first planning programs, ABSTRIPS, and developed techniques of hierarchical planning.
1975                        Marvin Minsky published his widely-read and influential article on Frames as a representation of knowledge, in which many ideas about schemas and semantic links are brought together.
                            The Meta-Dendral learning program produced new results in chemistry (some rules of mass spectrometry) the first scientific discoveries by a computer to be published in a refereed journal.
Mid 70's                    Barbara Grosz (SRI) established limits to traditional AI approaches to discourse modeling. Subsequent work by Grosz, Bonnie Webber and Candace Sidner developed the notion of &quot;centering&quot;, used in establishing focus of discourse and anaphoric references in NLP.
                            Alan Kay and Adele Goldberg (Xerox PARC) developed the Smalltalk language, establishing the power of object-oriented programming and of icon-oriented interfaces.
                            David Marr and MIT colleagues describe the &quot;primal sketch&quot; and its role in visual perception.
1976                        Doug Lenat's AM program (Stanford PhD dissertation) demonstrated the discovery model (loosely-guided search for interesting conjectures).
                            Randall Davis demonstrated the power of meta-level reasoning in his PhD dissertation at Stanford.
Late 70's                   Stanford's SUMEX-AIM resource, headed by Ed Feigenbaum and Joshua Lederberg, demonstrates the power of the ARPAnet for scientific collaboration.
</code></pre>
<h1><a class="header" href="#belief-desires-intentions-model" id="belief-desires-intentions-model">Belief-Desires-Intentions Model</a></h1>
<pre><code>loop:
  - perceive                      P = perceive
  - revise knowledge              B = belief_revision(B, P)
  - reason about knowledge 
    to obtain current desires     D = option_selection(B)
  - reconsider intentions 
    based on desires and beliefs  I = intention_selection(B, D, I)
  - planning                      A = action_selection(B, I)
  - act and communicate
</code></pre>
<pre><code>  +-----+      +--------+     +-+
  |     |------&gt;belief  |-----&gt;B|-----------+
  |  E  |      |revision|     +++           |
  |  N  |      +--------+      |            |
  |  V  |                      |            |
  |  I  |          +-----------+            |
  |  R  |          |                        |
  |  O  |          |                        |
  |  N  |     +----v----+     +-+     +-----v---+
  |  M  |     |intention&lt;-----|D&lt;-----|option   |
  |  E  |     |selection|     +-+     |selection|
  |  N  |     +----^----+             +-----^---+
  |  T  |          |                        |
  |     |          |                        |
  |     |          +-----------+            |
  |     |                      |            |
  |     |                      |            |
  |     |     +---------+     +v+           |
  |     &lt;-----|action   &lt;-----|I|-----------+
  |     |     |selection|     +-+
  +-----+     +---------+
</code></pre>
<p>Los deseos y las intenciones comparten sus elementos, ya que la seleccion
de intenciones 'filtra' a los deseos que el agente ha seleccionado. Por lo tanto las intenciones en un ciclo deliberativo seran un subconjunto de los deseos.</p>
<h2><a class="header" href="#wikipedia" id="wikipedia">Wikipedia:</a></h2>
<p>Provides a mechanism for separating the activity of selecting a plan (from a plan library or an external planner application) from the execution of currently active plans.</p>
<p>Consequently, BDI agents are able to balance the time spent on deliberating about plans (choosing what to do) and executing those plans (doing it).</p>
<p>A third activity, creating the plans in the first place (planning), is not within the scope of the model, and is left to the system designer and programmer.</p>
<h2><a class="header" href="#bratman" id="bratman">Bratman:</a></h2>
<p>Implements the notions of belief, desire and (in particular) intention.
Intention and desire are both pro-attitudes (mental attitudes concerned with action), but intention is distinguished as a conduct-controlling pro-attitude.</p>
<p>He identifies commitment as the distinguishing factor between desire and intention, noting that it leads to (1) temporal persistence in plans and (2) further plans being made on the basis of those to which it is already committed.</p>
<p>Temporal persistence, in the sense of explicit reference to time, is not explored.
The hierarchical nature of plans is more easily implemented: a plan consists of a number of steps, some of which may invoke other plans.</p>
<p>The hierarchical definition of plans itself implies a kind of temporal persistence, since the overarching plan remains in effect while subsidiary plans are being executed.</p>
<p>The BDI software model is closely associated with intelligent agents, but does not, of itself, ensure all the characteristics associated with such agents.
For example, it allows agents to have private beliefs, but does not force them to be private.</p>
<p>It also has nothing to say about agent communication.
Ultimately, the BDI software model is an attempt to solve a problem that has more to do with plans and planning (the choice and execution thereof) than it has to do with the programming of intelligent agents.</p>
<h3><a class="header" href="#beliefs" id="beliefs">Beliefs:</a></h3>
<p>Beliefs represent the informational state of the agent, in other words its beliefs about the world (including itself and other agents). Beliefs can also include inference rules, allowing forward chaining to lead to new beliefs. Using the term belief rather than knowledge recognizes that what an agent believes may not necessarily be true (and in fact may change in the future).</p>
<h3><a class="header" href="#beliefset" id="beliefset">Beliefset:</a></h3>
<p>Beliefs are stored in database (sometimes called a belief base or a belief set), although that is an implementation decision.</p>
<h3><a class="header" href="#desires" id="desires">Desires:</a></h3>
<p>Desires represent the motivational state of the agent. They represent objectives or situations that the agent would like to accomplish or bring about. Examples of desires might be: find the best price, go to the party or become rich.</p>
<h3><a class="header" href="#goals" id="goals">Goals:</a></h3>
<p>A goal is a desire that has been adopted for active pursuit by the agent. Usage of the term goals adds the further restriction that the set of active desires must be consistent. For example, one should not have concurrent goals to go to a party and to stay at home - even though they could both be desirable.</p>
<h3><a class="header" href="#intentions" id="intentions">Intentions:</a></h3>
<p>Intentions represent the deliberative state of the agent - what the agent has chosen to do. Intentions are desires to which the agent has to some extent committed. In implemented systems, this means the agent has begun executing a plan.</p>
<h3><a class="header" href="#plans" id="plans">Plans:</a></h3>
<p>Plans are sequences of actions (recipes or knowledge areas) that an agent can perform to achieve one or more of its intentions. Plans may include other plans: my plan to go for a drive may include a plan to find my car keys. This reflects that in Bratman's model, plans are initially only partially conceived, with details being filled in as they progress.</p>
<h3><a class="header" href="#events" id="events">Events:</a></h3>
<p>These are triggers for reactive activity by the agent. An event may update beliefs, trigger plans or modify goals. Events may be generated externally and received by sensors or integrated systems. Additionally, events may be generated internally to trigger decoupled updates or plans of activity.</p>
<h3><a class="header" href="#bdi-interpreter" id="bdi-interpreter">BDI Interpreter</a></h3>
<p>This section defines an idealized BDI interpreter that provides the basis of the PRS linage of BDI systems:</p>
<ol>
<li>initialize-state</li>
<li>repeat
<ol>
<li>options: option-generator(event-queue)</li>
<li>selected-options: deliberate(options)</li>
<li>update-intentions(selected-options)</li>
<li>execute()</li>
<li>get-new-external-events()</li>
<li>drop-unsuccessful-attitudes()</li>
<li>drop-impossible-attitudes()</li>
</ol>
</li>
<li>end repeat</li>
</ol>
<h3><a class="header" href="#limitations-and-criticisms" id="limitations-and-criticisms">Limitations and Criticisms</a></h3>
<p>The BDI software model is one example of a reasoning architecture for a single rational agent, and one concern in a broader multi-agent system. This section bounds the scope of concerns for the BDI software model, highlighting known limitations of the architecture.</p>
<ul>
<li>Learning: BDI agents lack any specific mechanisms within the architecture to learn from past behavior and adapt to new situations[6][7].</li>
<li>Three Attitudes: Classical decision theorists and planning research questions the necessity of having all three attitudes, distributed AI research questions whether the three attitudes are sufficient[1].</li>
<li>Logics: The multi-modal logics that underlie BDI (that do not have complete axiomatizations and are not efficiently computable) have little relevance in practice[1][8].</li>
<li>Multiple Agents: In addition to not explicitly supporting learning, the framework may not be appropriate to learning behavior. Further, the BDI model does not explicitly describe mechanisms for interaction with other agents and integration into a multi-agent system.[9].</li>
<li>Explicit Goals: Most BDI implementations do not have an explicit representation of goals[10].</li>
<li>Lookahead: The architecture does not have (by design) any lookahead deliberation or forward planning. This may not be desirable because adopted plans may use up limited resources, actions may not be reversible, task execution may take longer than forward planning, and actions may have undesirable side effects if unsuccessful[11].</li>
</ul>
<h2><a class="header" href="#book" id="book">Book</a></h2>
<pre><code>1 Intelligent Agents
2 Multiagent Systems and Societies of Agents
3 Distributed Problem Solving and Planning
4 Search Algorithms for Agents
5 Distributed Rational Decision Making
6 Learning in Multiagent Systems
7 Computational Organization Theory
8 Formal Methods in DAI: Logic-Based Representation and Reasoning
9 Industrial and Practical Applications of DAIH.
10 Groupware and Computer Supported Cooperative Work
11 Distributed Models for Decision Support
12 Concurrent Programming for DAI
13 Distributed Control Algorithms for AI

Prologue
    Multiagent Systems and Distributed Artificial Intelligence
        Intelligent Agents that Interact
        Challenging Issues
        Applications
        Rationales for Multiagent Systems
    A Guide to This Book
        The Chapters
        The Exercises
        A Few Pointers to Further Readings
        References
Part I: Basic Themes
    1 Intelligent Agents
        1.1 Introduction
        1.2 What Are Agents?
            1.2.1 Examples of Agents
            1.2.2 Intelligent Agents
            1.2.3 Agents and Objects
            1.2.4 Agents and Expert Systems
        1.3 Abstract Architectures for Intelligent Agents
            1.3.1 Purely Reactive Agents
            1.3.2 Perception
            1.3.3 Agents with State
        1.4 Concrete Architectures for Intelligent Agents
            1.4.1 Logic-based Architectures
            1.4.2 Reactive Architectures
            1.4.3 Belief-Desire-Intention Architectures
            1.4.4 Layered Architectures
        1.5 Agent Programming Languages
            1.5.1 Agent-Oriented Programming
            1.5.2 Concurrent METATEM
        1.6 Conclusions
        1.7 Exercises
        1.8 References
    2 Multiagent Systems and Societies of Agents
        2.1 Introduction
            2.1.1 Motivations
            2.1.2 Characteristics of Multiagent Environments
        2.2 Agent Communications
            2.2.1 Coordination
            2.2.2 Dimensions of Meaning
            2.2.3 Message Types
            2.2.4 Communication Levels
            2.2.5 Speech Acts
            2.2.6 Knowledge Query and Manipulation Language (KQML)
            2.2.7 Knowledge Interchange Format (KIF)
            2.2.8 Ontologies
            2.2.9 Other Communication Protocols
        2.3 Agent Interaction Protocols
            2.3.1 Coordination Protocols
            2.3.2 Cooperation Protocols
            2.3.3 Contract Net
            2.3.4 Blackboard Systems
            2.3.5 Negotiation
            2.3.6 Multiagent Belief Maintenance
            2.3.7 Market Mechanisms
        2.4 Societies of Agents
        2.5 Conclusions
        2.6 Exercises
        2.7 References
    3 Distributed Problem Solving and Planning
        3.1 Introduction
        3.2 Example Problems
        3.3 Task Sharing
            3.3.1 Task Sharing in the Tower of Hanoi (Toll) Problem
            3.3.2 Task Sharing in Heterogeneous Systems
            3.3.3 Task Sharing for Distributed Sensor Network Establishment (DSNE)
            3.3.4 Task Sharing for Interdependent Tasks
        3.4 Result Sharing
            3.4.1 Functionally Accurate Cooperation
            3.4.2 Shared Repositories and Negotiated Search
            3.4.3 Distributed Constrained Heuristic Search
            3.4.4 Organizational Structuring
            3.4.5 Communication Strategies
            3.4.6 Task Structures
        3.5 Distributed Planning
            3.5.1 Centralized Planning for Distributed Plans
            3.5.2 Distributed Planning for Centralized Plans
            3.5.3 Distributed Planning for Distributed Plans
        3.6 Distributed Plan Representations
        3.7 Distributed Planning and Execution
            3.7.1 Post-Planning Coordination
            3.7.2 Pre-Planning Coordination
            3.7.3 Interleaved Planning, Coordination, and Execution
            3.7.4 Runtime Plan Coordination Without Communication
        3.8 Conclusions
        3.9 Exercises
        3.10 References
    4 Search Algorithms for Agents
        4.1 Introduction
        4.2 Constraint Satisfaction
            4.2.1 Definition of a Constraint Satisfaction Problem
            4.2.2 Filtering Algorithm
            4.2.3 Hyper-Resolution-Based Consistency Algorithm
            4.2.4 Asynchronous Backtracking
            4.2.5 Asynchronous Weak-Commitment Search
        4.3 Path-Finding Problem
            4.3.1 Definition of a Path-Finding Problem
            4.3.2 Asynchronous Dynamic Programming
            4.3.3 Learning Real-Time A*
            4.3.4 Real-Time A*
            4.3.5 Moving Target Search
            4.3.6 Real-Time Bidirectional Search
            4.3.7 Real-Time Multiagent Search
        4.4 Two-Player Games
            4.4.1 Formalization of Two-Player Games
            4.4.2 Minimax Procedure
            4.4.3 Alpha-Beta Pruning
        4.5 Conclusions
        4.6 Exercises
        4.7 References
    5 Distributed Rational Decision Making
        5.1 Introduction
        5.2 Evaluation Criteria
            5.2.1 Social Welfare
            5.2.2 Pareto Efficiency
            5.2.3 Individual Rationality
            5.2.4 Stability
            5.2.5 Computational Efficiency
            5.2.6 Distribution and Communication Efficiency
        5.3 Voting
            5.3.1 Truthful Voters
            5.3.2 Strategic (Insincere) Voters
        5.4 Auctions
            5.4.1 Auction Settings
            5.4.2 Auction Protocols
            5.4.3 Efficiency of the Resulting Allocation
            5.4.4 Revenue Equivalence and Non-Equivalence
            5.4.5 Bidder Collusion
            5.4.6 Lying Auctioneer
            5.4.7 Bidders Lying in Non-Private-Value Auctions
            5.4.8 Undesirable Private Information Revelation
            5.4.9 Roles of Computation in Auctions
        5.5 Bargaining
            5.5.1 Axiomatic Bargaining Theory
            5.5.2 Strategic Bargaining Theory
            5.5.3 Computation in Bargaining
        5.6 General Equilibrium Market Mechanisms
            5.6.1 Properties of General Equilibrium
            5.6.2 Distributed Search for a General Equilibrium
            5.6.3 Speculative Strategies in Equilibrium Markets
        5.7 Contract Nets
            5.7.1 Task Allocation Negotiation
            5.7.2 Contingency Contracts and Leveled Commitment Contracts
        5.8 Coalition Formation
            5.8.1 Coalition Formation Activity 1: Coalition Structure Generation
            5.8.2 Coalition Formation Activity 2: Optimization within a Coalition
            5.8.3 Coalition Formation Activity 3: Payoff Division
        5.9 Conclusions
        5.10 Exercises
        5.11 References
    6 Learning in Multiagent Systems
        6.1 Introduction
            6.2 A General Characterization
            6.2.1 Principal Categories
            6.2.2 Differencing Features
            6.2.3 The Credit-Assignment Problem
        6.3 Learning and Activity Coordination
            6.3.1 Reinforcement Learning
            6.3.2 Isolated, Concurrent Reinforcement Learners
            6.3.3 Interactive Reinforcement Learning of Coordination
        6.4 Learning about and from Other Agents
            6.4.1 Learning Organizational Roles
            6.4.2 Learning in Market Environments
            6.4.3 Learning to Exploit an Opponent
        6.5 Learning and Communication
            6.5.1 Reducing Communication by Learning
            6.5.2 Improving Learning by Communication
        6.6 Conclusions
        6.7 Exercises
        6.8 References
    7 Computational Organization Theory
        7.1 Introduction
            7.1.1 What Is an Organization?
            7.1.2 What Is Computational Organization Theory?
            7.1.3 Why Take a Computational Approach?
        7.2 Organizational Concepts Useful in Modeling Organizations
            7.2.1 Agent and Agency
            7.2.2 Organizational Design
            7.2.3 Task
            7.2.4 Technology
        7.3 Dynamics
        7.4 Methodological Issues
            7.4.1 Virtual Experiments and Data Collection
            7.4.2 Validation and Verification
            7.4.3 Computational Frameworks
        7.5 Conclusions
        7.6 Exercises
        7.7 References
    8 Formal Methods in DAI: Logic-Based Representation and Reasoning
        8.1 Introduction
        8.2 Logical Background
            8.2.1 Basic Concepts
            8.2.2 Propositional and Predicate Logic
            8.2.3 Modal Logic
            8.2.4 Deontic Logic
            8.2.5 Dynamic Logic
            8.2.6 Temporal Logic
        8.3 Cognitive Primitives
            8.3.1 Knowledge and Beliefs
            8.3.2 Desires and Goals
            8.3.3 Intentions
            8.3.4 Commitments
            8.3.5 Know-How
            8.3.6 Sentential and Hybrid Approaches
            8.3.7 Reasoning with Cognitive Concepts
        8.4 BDI Implementations
            8.4.1 Abstract Architecture
            8.4.2 Practical System
        8.5 Coordination
            8.5.1 Architecture
            8.5.2 Specification Language
            8.5.3 Common Coordination Relationships
        8.6 Communications
            8.6.1 Semantics
            8.6.2 Ontologies
        8.7 Social Primitives
            8.7.1 Teams and Organizational Structure
            8.7.2 Mutual Beliefs and Joint Intentions
            8.7.3 Social Commitments
            8.7.4 Group Know-How and Intentions
        8.8 Tools and Systems
            8.8.1 Direct Implementations
            8.8.2 Partial Implementations
            8.8.3 Traditional Approaches
        8.9 Conclusions
            8.10 Exercises
            8.11 References
    9 Industrial and Practical Applications of DAIH.
        9.1 Introduction
        9.2 Why Use DAI in Industry?
        9.3 Overview of the Industrial Life-Cycle
        9.4 Where in the Life Cycle Are Agents Used?
            9.4.1 Questions that Matter
            9.4.2 Agents in Product Design
            9.4.3 Agents in Planning and Scheduling
            9.4.4 Agents in Real-Time Control
        9.5 How Does Industry Constrain the Life Cycle of an Agent-Based System?
            9.5.1 Requirements, Positioning, and Specification
            9.5.2 Design: The Conceptual Context
            9.5.3 Design: The Process
            9.5.4 System Implementation
            9.5.5 System Operation
        9.6 Development Tools
        9.7 Conclusions
        9.8 Exercises
        9.9 References
Part II: Related Themes
    10 Groupware and Computer Supported Cooperative Work
        10.1 Introduction
        10.1.1 Well-Known Groupware Examples
        10.2 Basic Definitions
            10.2.1 Groupware
            10.2.2 Computer Supported Cooperative Work
        10.3 Aspects of Groupware
            10.3.1 Keepers
            10.3.2 Coordinators
            10.3.3 Communicators
            10.3.4 Team-Agents
            10.3.5 Agent Models
            10.3.6 An Example of Aspect Analysis of a Groupware
        10.4 Multi-Aspect Groupware
            10.4.1 Chautauqua — A Multi-Aspect System
        10.5 Social and Group Issues in Designing Groupware Systems
        10.6 Supporting Technologies and Theories
            10.6.1 Keepers
            10.6.2 Coordinators
            10.6.3 Communicators
            10.6.4 Team-Agents
        10.7 Other Taxonomies of Groupware
            10.7.1 Space/Time Matrix
            10.7.2 Application Area
        10.8 Groupware and Internet
            10.8.1 Internet as Infrastructure
            10.8.2 Internet as Presumed Software
        10.9 Conclusions
            10.9.1 Incorporating Communicators into Keepers
            10.9.2 Incorporating Keepers and Communicators into Coordinators
            10.9.3 Future Research on Agents
            10.9.4 Future Research on Keepers
        10.10 Exercises
        10.11 References
    11 Distributed Models for Decision Support
        11.1 Introduction
        11.2 Decision Support Systems
            11.2.1 The Decision Support Problem
            11.2.2 Knowledge-Based Decision Support
            11.2.3 Distributed Decision Support Models
        11.3 An Agent Architecture for Distributed Decision Support Systems
            11.3.1 Information Model
            11.3.2 Knowledge Model
            11.3.3 Control Model
        11.4 Application Case Studies
            11.4.1 Environmental Emergency Management
            11.4.2 Energy Management
            11.4.3 Road Traffic Management
        11.5 Couclusions
        11.6 Exercises
        11.7 References
    12 Concurrent Programming for DAI
        12.1 Introduction
        12.2 Defining Multiagent Systems
        12.3 Actors
            12.3.1 Semantics of Actors
            12.3.2 Equivalence of Actor Systems
            12.3.3 Actors and Concurrent Programming
        12.4 Representing Agents as Actors
            12.4.1 Mobility of Actors
            12.4.2 Resource Model
        12.5 Agent Ensembles
            12.5.1 Customizing Execution Contexts
            12.5.2 Interaction Protocols
            12.5.3 Coordination
            12.5.4 Naming and Groups
        12.6 Related Work
        12.7 Conclusions
        12.8 Exercises
        12.9 References
    13 Distributed Control Algorithms for AI
        13.1 Introduction
            13.1.1 Model of Computation
            13.1.2 Complexity Measures
            13.1.3 Examples of Distributed Architectures in AI
        13.2 Graph Exploration
            13.2.1 Depth-First Search
            13.2.2 Pseudo-Fast Exploration: the Echo Algorithm
            13.2.3 Searching for Connectivity Certificates
        13.3 Termination Detection
            13.3.1 Problem Definition
            13.3.2 Tracing Algorithms
            13.3.3 Probe Algorithms
        13.4 Distributed Arc Consistency and the Constraint Satisfaction Problem (CSP)
            13.4.1 Constraint Satisfaction and Arc Consistency
            13.4.2 The AC4 Algorithm
            13.4.3 The Distributed AC4 Algorithm
            13.4.4 Termination Detection
            13.4.5 Partitioning for Multiprocessor Computers
            13.4.6 Distributed Constraint Satisfaction Algorithm
        13.5 Distributed Graph Processing
            13.5.1 The Problem: Loop Cutset
            13.5.2 Distributed Execution of the Algorithm
            13.5.3 Complexity and Conclusions
        13.6 Conclusions
        13.7 Exercises
        13.8 References
</code></pre>
<h1><a class="header" href="#richard-sutton" id="richard-sutton">Richard Sutton</a></h1>
<p><a href="http://incompleteideas.net/">Source</a></p>
<h2><a class="header" href="#whats-wrong-with-artificial-intelligence" id="whats-wrong-with-artificial-intelligence">What's Wrong with Artificial Intelligence</a></h2>
<p><a href="http://incompleteideas.net/IncIdeas/WrongWithAI.html">Source</a>
November 12, 2001</p>
<p>I hold that AI has gone astray by neglecting its essential objective --- the turning over of responsibility for the decision-making and organization of the AI system to the AI system itself. It has become an accepted, indeed lauded, form of success in the field to exhibit a complex system that works well primarily because of some insight the designers have had into solving a particular problem. This is part of an anti-theoretic, or &quot;engineering stance&quot;, that considers itself open to any way of solving a problem. But whatever the merits of this approach as engineering, it is not really addressing the objective of AI. For AI it is not enough merely to achieve a better system; it matters how the system was made. The reason it matters can ultimately be considered a practical one, one of scaling. An AI system too reliant on manual tuning, for example, will not be able to scale past what can be held in the heads of a few programmers. This, it seems to me, is essentially the situation we are in today in AI. Our AI systems are limited because we have failed to turn over responsibility for them to them.</p>
<p>Please forgive me for this which must seem a rather broad and vague criticism of AI. One way to proceed would be to detail the criticism with regard to more specific subfields or subparts of AI. But rather than narrowing the scope, let us first try to go the other way. Let us try to talk in general about the longer-term goals of AI which we can share and agree on. In broadest outlines, I think we all envision systems which can ultimately incorporate large amounts of world knowledge. This means knowing things like how to move around, what a bagel looks like, that people have feet, etc. And knowing these things just means that they can be combined flexibly, in a variety of combinations, to achieve whatever are the goals of the AI. If hungry, for example, perhaps the AI can combine its bagel recognizer with its movement knowledge, in some sense, so as to approach and consume the bagel. This is a cartoon view of AI -- as knowledge plus its flexible combination -- but it suffices as a good place to start. Note that it already places us beyond the goals of a pure performance system. We seek knowledge that can be used flexibly, i.e., in several different ways, and at least somewhat independently of its expected initial use.</p>
<p>With respect to this cartoon view of AI, my concern is simply with ensuring the correctness of the AI's knowledge. There is a lot of knowledge, and inevitably some of it will be incorrrect. Who is responsible for maintaining correctness, people or the machine? I think we would all agree that, as much as possible, we would like the AI system to somehow maintain its own knowledge, thus relieving us of a major burden. But it is hard to see how this might be done; easier to simply fix the knowledge ourselves. This is where we are today.</p>
<h2><a class="header" href="#verification-the-key-to-ai" id="verification-the-key-to-ai">Verification, The Key to AI</a></h2>
<p><a href="http://incompleteideas.net/IncIdeas/KeytoAI.html">Source</a>
November 15, 2001</p>
<p>It is a bit unseemly for an AI researcher to claim to have a special insight or plan for how his field should proceed. If he has such, why doesn't he just pursue it and, if he is right, exhibit its special fruits? Without denying that, there is still a role for assessing and analyzing the field as a whole, for diagnosing the ills that repeatedly plague it, and to suggest general solutions.</p>
<p>The insight that I would claim to have is that the key to a successful AI is that it can tell for itself whether or not it is working correctly. At one level this is a pragmatic issue. If the AI can't tell for itself whether it is working properly, then some person has to make that assessment and make any necessary modifications. An AI that can assess itself may be able to make the modifications itself.</p>
<p>The Verification Principle:</p>
<blockquote>
<p>An AI system can create and maintain knowledge only to the extent that it can verify that knowledge itself.</p>
</blockquote>
<p>Successful verification occurs in all search-based AI systems, such as planners, game-players, even genetic algorithms. Deep Blue, for example, produces a score for each of its possible moves through an extensive search. Its belief that a particular move is a good one is verified by the search tree that shows its inevitable production of a good position. These systems don't have to be told what choices to make; they can tell for themselves. Image trying to program a chess machine by telling it what kinds of moves to make in each kind of position. Many early chess programs were constructed in this way. The problem, of course, was that there were many different kinds of chess positions. And the more advice and rules for move selection given by programmers, the more complex the system became and the more unexpected interactions there were between rules. The programs became brittle and unreliable, requiring constant maintainence, and before long this whole approach lost out to the &quot;brute force&quot; searchers.</p>
<p>Although search-based planners verify at the move selection level, they typically cannot verify at other levels. For example, they often take their state-evaluation scoring function as given. Even Deep Blue cannot search to the end of the game and relies on a human-tuned position-scoring function that it does not assess on its own. A major strength of the champion backgammon program, TD-Gammon, is that it does assess and improve its own scoring function.</p>
<p>Another important level at which search-based planners are almost never subject to verification is that which specifies the outcomes of the moves, actions, or operators. In games such as chess with a limited number of legal moves we can easily imagine programming in the consequences of all of them accurately. But if we imagine planning in a broader AI context, then many of the allowed actions will not have their outcomes completely known. If I take the bagel to Leslie's office, will she be there? How long will it take to drive to work? Will I finish this report today? So many of the decisions we take every day have uncertain and changing effects. Nevertheless, modern AI systems almost never take this into account. They assume that all the action models will be entered accurately by hand, even though these may be most of the knowledge in or ever produced by the system.</p>
<p>Finally, let us make the same point about knowledge in general. Consider any AI system and the knowledge that it has. It may be an expert system or a large database like CYC. Or it may be a robot with knowledge of a building's layout, or knowledge about how to react in various situations. In all these cases we can ask if the AI system can verify its own knowledge, or whether it requires people to intervene to detect errors and unforeseen interactions, and make corrections. As long as the latter is the case we will never be able to build really large knowledge systems. They will always be brittle and unreliable, and limited in size to what people can monitor and understand themselves.</p>
<blockquote>
<p>&quot;Never program anything bigger than your head&quot;</p>
</blockquote>
<p>And yet it is overwhelmingly the case that today's AI systems are not able to verify their own knowledge. Large ontologies and knowledge bases are built that are totally reliant on human construction and maintainence. &quot;Birds have wings&quot; they say, but of course they have no way of verifying this. </p>
<h2><a class="header" href="#verification" id="verification">Verification</a></h2>
<p><a href="http://incompleteideas.net/IncIdeas/Verification.html">Source</a>
11/14/2001</p>
<p>If the human designers of an AI are not to be burdened with ensuring that what their AI knows is correct, then the AI will have to ensure it itself. It will have to be able to verify the knowledge that it has gained or been given.</p>
<p>Giving an AI the ability to verify its knowledge is no small thing. It is in fact a very big thing, not easy to do. Often a bit of knowledge can be written very compactly, whereas its verification is very complex. It is easy to say &quot;there is a book on the table&quot;, but very complex to express even a small part of its verification, such as the visual and tactile senations involved in picking up the book. It is easy to define an operator such as &quot;I can get to the lunchroom by going down one floor&quot;, but to verify this one must refer to executable routines for finding and descending the stairs, recognizing the lunchroom, etc. These routines involve enormously greater detail and closed-loop contingences, such as opening doors, the possibility of a stairway being closed, or meeting someone on the way, than does the knowledge itself. One can often suppress all this detail when using the knowledge, e.g., in planning, but to verify the knowledge requires its specification at the low level. There is no comparison between the ease of adding unverified knowledge and the complexity of including a means for its autonomous verification.</p>
<p>Note that although all the details of execution are needed for verification, the execution details are not themselves the verification. There is a procedure for getting to the lunchroom, but separate from this would be the verifier for determining if it has succeeded. It is perfectly possible for the procedure to be fully grounded in action and sensation, while completely leaving out the verifier and thus the possibility of autonomous knowledge maintainence. At the risk of being too broad-brush about it, this is what typically happens in modern AI robotics systems. They have extensive grounded knowledge, but still no way of verifying almost any of it. They use visual routines to recognize doors and hallways, and they make decisions based on these conclusions, but they cannot themselves correct their errors. If something is recognized as a &quot;doorway&quot; yet cannot be passed through, this failure will not be recognized and not used to correct future doorway recognitions, unless it is done by people.</p>
<p>On the other hand, once one has grounding, the further step to include verification is less daunting. One need only attach to the execution procedures appropriate tests and termination conditions that measure in some sense the veracity of the original statement, while at the same time specifying what it really means in detail. What is a chair? Not just something that lights up your visual chair detector! That would be grounded knowledge, but not verifiable; it would rely on people to say which were and were not chairs. But suppose you have routines for trying to sit. Then all you need for a verifier is to be able to measure your success at sitting. You can then verify, improve, and maintain your &quot;sittable thing&quot; recognizer on your own.</p>
<p>There is a great contrast between the AI that I am proposing and what might be considered classical &quot;database AI&quot;. There are large AI efforts to codify vast amounts of knowledge in databases or &quot;ontologies&quot;, of which Doug Lenat's CYC is only the most widely known. In these efforts, the idea of people maintaining the knowledge is embraced. Special knowledge representation methods and tools are emphasized to make it easier for people to understand and access the knowledge, and to try to keep it right. These systems tend to emphasize static, world knowledge like &quot;Springfield is the capital of Illinois&quot;, &quot;a canary is a kind of bird&quot;, or even &quot;you have a meeting scheduled with John at 3:30&quot;, rather than the dynamic knowledge needed say by a robot to interact in real time with its environment. A major problem is getting people to use the same categories and terms when they enter knowledge and, more importantly, to mean the same things by them. There is a search for an ultimate &quot;ontology&quot;, or codification of all objects and their possible relationships, so that clear statements can be made about them. But so far this has not proven possible; there always seem to be far more cases that don't fit than do. People are good about being fluid with there concepts, and knowing when they don't apply.</p>
<p>Whatever the ultimate success of the symbolic &quot;database AI&quot; approach, it should be clear that it is the anti-thesis of what I am calling for. The database approach calls for heroic efforts organizing and entering an objective, public, and disembodied knowledge base. I am calling for an AI that maintains its own representations, perhaps different from those of others, while interacting in real time with a dynamic environment. Most important of all, the database approach embraces human maintainence and human organization of the AI's knowledge. I am calling for automating these functions, for the AI being able to understand its knowledge well enough to verify it itself. </p>
<h2><a class="header" href="#mind-is-about-information" id="mind-is-about-information">Mind is About Information</a></h2>
<p><a href="http://incompleteideas.net/IncIdeas/Information.html">Source</a>
11/19/2001</p>
<p>What is the mind? Of course, &quot;mind&quot; is just a word, and we can mean anything we want by it. But if we examine the way we use the word, and think about the kinds of things we consider more mindful than others, I would argue that the idea of choice is the most important. We consider things to be more or less mindful to the extent that they appear to be making choices. To make a choice means to distinguish, and to create a difference. In this basic sense the mind is about information. Its essential function is to process bits into other bits. This position has two elements:</p>
<ul>
<li>Mind is Computational, not Material</li>
<li>Mind is Purposive</li>
</ul>
<h3><a class="header" href="#mind-is-computational-not-material" id="mind-is-computational-not-material">Mind is Computational, not Material</a></h3>
<p>The idea that the mind's activities are best viewed as information processing, as computation, has become predominant in our sciences over the last 40 years. People do not doubt that minds have physical, material form, of course, either as brains or perhaps as computer hardware. But, as is particularly obvious in the latter case, the hardware is often unimportant. Is is how the information flows which matters.</p>
<p>I like to bring this idea down to our basest intuition. What things are more mindlike and less mindlike? A thermostat is slightly mindlike. It converts a gross physical quanitity, the air temperature of your home, to a small deviation in a piece of metal, which tips a small lump of mercury which in turn triggers a fire in your furnace. Large physical events are reduced and processed as small ones, the physical is reduced to mere distinctions and processed as information. The sensors and effectors of our brains are essentially similar. Relatively powerful physical forces impinge on us, and our sensors convert them to tiny differences in nerve firings. These filter and are further processed until signals are sent to our muscles and there amplified into gross changes in our limbs and other large physical things. At all stages it is all physical, but inside our heads there are only small physical quanities that are easily altered and diverted as they interact with each other. This is what we mean by information processing. Information is not non-physical. It is a way of thinking about what is happening that is sometime much more revealing and useful than its physical properties.</p>
<p>Or so is one view, the view that takes a material physical reality as primary. The informational view of mind is just as compatible with alternative philosophical orientations. The one I most appreciate is that which takes the individual mind and its exchanging of information with the world as the primary and base activity. This is the so-called &quot;buttons and lights&quot; model, in which the mind is isolated behind an interface of output bits (buttons) and input bits (lights). In this view, the idea of the physical world is created by the mind so as to explain the pattern of input bits and how they respond to the output bits. This is a cartoon view, certainly, but a very clear one. There is no confusion about mind and body, material and ideal. There is just information, distinctions observed and differences made.</p>
<h3><a class="header" href="#mind-is-purposive" id="mind-is-purposive">Mind is Purposive</a></h3>
<p>Implicit in the idea of choice, particularly as the essense of mindfulness, is some reason or purpose for making the choices. In fact it is difficult even to talk about choice without alluding to some purpose. One could say a rock &quot;chooses&quot; to do nothing, but only by suggesting that its purpose is to sit still. If a device generated decisions at random one would hesitate to say that it was &quot;choosing.&quot; No, the whole idea of choice implies purpose, a reason for making the choice.</p>
<p>Purposiveness is at heart of mindfulness, and the heart of purposeness is the varying of means to achieve fixed ends. William James in 1890 identified this as &quot;the mark and criterion of mentality&quot;. He discussed an air bubble rising rising in water until trapped in an inverted jar, contrasting it with a frog, which may get trapped temporarily but keeps trying things until it finds a way around the jar. Varying means and fixed ends. In AI we call it generate and test. Or trial and error. Variation and selective survival. There are many names and many variations, but this idea is the essense of purpose, choice, and Mind. </p>
<h2><a class="header" href="#mind-is-about-conditional-predictions" id="mind-is-about-conditional-predictions">Mind Is About Conditional Predictions</a></h2>
<p>March 21, 2000</p>
<p>Simplifying and generalizing, one thing seems clear to me about mental activity---that the purpose of much of it can be considered to be the making of predictions. By this I mean a fairly general notion of prediction, including conditional predictions and predictions of reward. And I mean this in a sufficiently strong and specific sense to make it non-vacuous.</p>
<p>For concreteness, assume the world is a Markov Decision Process (MDP), that is, that we have discrete time and clear actions, sensations, and reward on each time step. Then, obviously, among the interesting predictions to make are those of immediate rewards and state transitions, as in &quot;If I am in this state and do this action, then what will the next state and reward be?&quot; The notion of value function is also a prediction, as in &quot;If I am in this state and follow this policy, what will my cumulative discounted future reward be?&quot; Of course one could make many value-function predictions, one for each of many different policies.</p>
<p>Note that both kinds of prediction mentioned above are conditional, not just on the state, but on action selections. They are hypothetical predictions. One is hypothetical in that it is dependent on a single action, and the other is hypothetical in that it is dependent on a whole policy, a whole way of behaving. Action conditional predictions are of course useful for actually selecting actions, as in many reinforcement learning methods in which the action with the highest estimated value is preferentially chosen. More generally, it is commonsensical that much of our knowledge is beliefs about what would happen IF we chose to behave in certain ways. The knowledge about how long it takes to drive to work, for example, is knowledge about the world in interaction with a hypothetical purposive way in which we could behave.</p>
<p>Now for the key step, which is simply to generalize the above two clear kinds of conditional predictions to cover much more of what we normally think of as knowledge. For this we need a new idea, a new way of conditioning predictions that I call conditioning on outcomes. Here we wait until one of some clearly designated set of outcomes occurs and ask (or try to predict) something about which one it is. For example, we might try to predict how old we will be when we finish graduate school, or how much we will weigh at the end of the summer, or how long it will take to drive to work, or much you will have learned by the time you reach the end of this article. What will the dice show when they have stopped tumbling? What will the stock price be when I sell it? In all these cases the prediction is about what the state will be when some clearly identified event occurs. It is a little like when you make a bet and establish some clear conditions at which time the bet will be over and it will be clear who has won.</p>
<p>A general conditional prediction, then, is conditional on three things: 1) the state in which it is made, 2) the policy for behaving, and 3) the outcome that triggers the time at which the predicted event is to occur. Of course the policy need only be followed from the time the prediction is made until the outcome triggering event. Actions taken after the trigger are irrelevant. [This notion of conditional prediction has been previously explored as the models of temporally extended actions, also known as &quot;options&quot; (Sutton, Precup, and Singh, 1999; Precup, thesis in preparation).</p>
<p>Let us return now to the claim with which I started, that much if not most mental activity is focused on such conditional predictions, on learning and computing them, on planning and reasoning with them. I would go so far as to propose that much if not most of our knowledge is represented in the form of such predictions, and that they are what philosophers refer to as &quot;concepts&quot;. To properly argue these points would of course be a lengthy undertaking. For now let us just cover some high points, starting with some of the obvious advantages of conditional predictions for knowledge representation.</p>
<p>Foremost among these is just that predictions are grounded in the sense of having a clear, mechanically determinable meaning. The accuracy of any prediction can be determined just by running its policy from its state until an outcome occurs, then checking the prediction against the outcome. No human intervention is required to interpret the representation and establish the truth or falsness of any statement. The ability to compare predictions to actual events also make them suitable for beling learned automatically. The semantics of predictions also make it clear how they are to be used in automatic planning methods such as are commonly used with MDPs and SMDPs. In fact, the conditional predictions we have discussed here are of exactly the form needed for use in the Bellman equations at the heart of these methods.</p>
<p>A less obvious but just as important advantage of outcome-conditional predictions is that they can compactly express much that would otherwise be difficult and expensize to represent. This happens very often in commonsense knowledge; here we give a simple example. The knowledge we want to represent is that you can go to the street corner and a bus will come to take you home within an hour. What this means of course is that if it is now 12:00 then the bus might come at 12:10 and it might come at 12:20, etc., but it will definitely come by 1:00. Using outcome conditioning, the idea is easy to express: we either make the outcome reaching 1:00 and predict that the bus will have come by then, or we make the outcome the arrival of the bus and predict that at that time it will be 1:00 or earlier.</p>
<p>A natural but naive alternative way to try to represent this knowledge would be as a probability of the bus arriving in each time slot. Perhaps it has one-sixth chance of arriving in each 10-minute interval. This approach is unsatisfactory not just because it forces us to say more than we may know, but because it does not capture the important fact that the bus will come eventually. Formally, the problem here is that the events of the bus coming at different times are not independent. If may have only a one-sixth chance of coming exactly at 1:00, but if it is already 12:55 then it is in fact certain to come at 1:00. The naive representation does not capture this fact that is actually absolutely important to using this knowledge. A more complicated representation could capture all these dependencies but would be just that -- more complicated. The outcome-conditional form represents the fact simply and represents just what is needed to reason with the knowledge this way. Of course, other circumstances may require the more detailed knowledge, and this is not precluded by the outcome-conditional form. This form just permits greater flexibility, in particular, the ability to omit these details while still being of an appropriate form for planning and learning. </p>
<h2><a class="header" href="#subjective-knowledge" id="subjective-knowledge">Subjective Knowledge</a></h2>
<p>April 6, 2001</p>
<p>I would like to revive an old idea about the mind. This is the idea that the mind arises from, and is principally about, our sensori-motor interaction with the world. It is the idea that all our sense of the world, of space, objects, and other people, arises from our experience squeezed through the narrow channel of our sensation and action. This is a radical view, but in many ways an appealing one. It is radical because it says that experience is the only thing that we directly know, that all our sense of the material world is constructed to better explain our subjective experience. It is not just that the mental is made primary and held above the physical, but that the subjective is raised over the objective.</p>
<p>Subjectivity is the most distinctive aspect of this view of the mind, and inherent in it. If all of our understanding of the world arises from our experience, then it is inherently personal and specific to us.</p>
<p>As scientists and observers we are accustomed to prasing the objective and denigrating the subjective, so reversing this customary assessment requires some defense.</p>
<p>The approach that I am advocating might be termed the subjective viewpoint. In it, all knowledge and understanding arises out of an individual's experience, and in that sense is inherently in terms that are private, personal, and subjective. An individual might know, for example, that a certain action tends to be followed by a certain sensation, or that one sensation invariably follows another. But these are its sensations and its actions. There is no necessary relationship between them and the sensations and actions of another individual. To hypothesize such a link might be useful, but always secondary to the subjective experience itself.</p>
<p>The subjective view of knowledge and understanding might be constrasted with the objective, realist view. In this view there are such things as matter, physical objects, space and time, other people, etc. Things happen, and causally interact, largely independent of observers. Occasionally we experience something subjectively, but later determine that it did not really, objectively happen. For example, we felt the room get hot, but the thermometer registered no change. In this view there is a reality independent of our experience. This would be easy to deny if there were only one agent in the world. In that case it is clear that that agent is merely inventing things to explain its experience. The objective view gains much of its force because it can be shared by different people. In science, this is almost the definition of the subjective/objective distinction: that which is private to one person is subjective whereas that which can be observed by many, and replicated by others, is objective.</p>
<p>I hasten to say that the subjective view does not deny the existence of the physical world. The conventional physical world is still the best hypothesis for explaining our subjective data. It is just that that world is held as secondary to the data that it is used to explain. And a little more: it is that the physical world hypothesis is just that, a hypothesis, an explanation. There are not two kinds of things, the mental and the physical. There are just mental things: the data of subjective experience and hypotheses constructed to explain it.</p>
<p>The appeal of the subjective view is that it is grounded. Subjective experience can be viewed as data in need of explanation. There is a sense in which only the subjective is clear and unambiguous. &quot;Whatever it means, I definitely felt warm in that room.&quot; No one can argue with our subjective experience, only with its explanation and relationship to other experiences that we have or might have. The closer the subjective is inspected, the firmer and less interpreted it appears, the more is becomes like data, whereas the objective often becomes vaguer and more complex. Consider the old saw about the person who saw red whenever everybody else saw green, and vice versa, but didn't realize it because he used the words &quot;red&quot; and &quot;green&quot; the wrong way around as well. This nonsense points out that different people's subjective experiences are not comparable. The experience that I call seeing red and the experience you call seeing red are related only in a very complicated way including, for example, effects of lighting, reflectance, viewpoint, and colored glasses. We have learned to use the same word to capture an important aspect of our separate experience, but ultimately the objective must bow to the subjective.</p>
<p>The appeal of the objective view is that it is common across people. Something is objectively true if it predicts the outcome of experiments that you and I both can do and get the same answer. But how is this sensible? How can we get the same answer when you see with your eyes and I with mine? For that matter, how can we do the &quot;same&quot; experiment? All these are problematic and require extensive theories about what is the same and what is different. In particular, they require calibration of our senses with each other. It is not just a question of us using the same words for the same things -- the red/green example shows the folly of that kind of thinking -- it is that there is no satisfactory notion of same things, across individuals, at the level of experience. Subjective experience as the ultimate data is clear, but not the idea that it can be objectively compared across persons. That idea can be made to work, approximately, but should be seen as following from the primacy of subjective experience.</p>
<p>At this point, you are probably wondering why I am belaboring this philosphical point. The reason is that the issue comes up, again and again, that it is difficult to avoid the pitfalls associated with the objective view without explicitly identifying them. This fate has befallen AI researchers many times in the past. So let us close with as clear a statement as we can of the implications of the subjective view for approaches to AI. What must be avoided, and what sought, in developing a subjective view of knowledge and mind?</p>
<p>All knowledge must be expressed in terms that are ultimately subjective, that are expressed in terms of the data of experience, of sensation and action. Thus we seek ways of clearly expressing all kinds of human knowledge in subjective terms. This is a program usually associated with the term &quot;associationism&quot; and often denigrated. Perhaps it is impossible, but it should be tried, and it is difficult to disprove, like a null hypothesis. In addition to expressing knowledge subjectively, we should also look to ways of learning and working with subjective knowledge. How can we reason with subjective knowledge to obtain more knowledge? How can it be tested, verified, and learned? How can goals be expressed in subjective terms?</p>
<p>Notes:</p>
<ul>
<li>McCarthy quote.</li>
<li>Relate to logical positivism.</li>
<li>Then Dyna as a simple example, and which highlights what is missing. </li>
</ul>
<h2><a class="header" href="#fourteen-declarative-principles-of-experience-oriented-intelligence" id="fourteen-declarative-principles-of-experience-oriented-intelligence">Fourteen Declarative Principles of Experience-Oriented Intelligence</a></h2>
<ol>
<li>all goals and purposes can be well thought of as the maximization of the expected value of the cumulative sum of a single externally received number (reward).  “the reward hypothesis”  thus life is a sequential decision-making problem, also known as a Markov decision process.  “learning is adaptive optimal control”</li>
<li>a major thing that the mind does is learn a state representation and a process for updating it on a moment-by-moment basis.  the input to the update process is the current sensation, action, and state (representation).  “state is constructed”</li>
<li>all action is taken at the shortest possible time scale, by a reactive, moment-by-moment policy function mapping from state to action.  anything higher or at longer time scales is for thinking about action, not for taking it.  “all behavior is reactive”</li>
<li>all efficient methods for solving sequential decision-making problems compute, as an intermediate step, an estimate for each state of the long-term cumulative reward that follows that state (a value function).  subgoals are high-value states.  “values are more important than rewards”</li>
<li>a major thing that the mind does is learn a predictive model of the worldʼs dynamics at multiple time scales.  this model is used to anticipate the outcome (consequences) of different ways of behavior, and then learn from them as if they had actually happened (planning).</li>
<li>learning and planning are fundamentally the same process, operating in the one case on real experience, and in the other on simulated experience from a predictive model of the world.  “thought is learning from imagined experience”</li>
<li>all world knowledge can be well thought of as predictions of experience.  “knowledge is prediction”  in particular, all knowledge can be thought of as predictions of the outcomes of temporally extended ways of behaving, that is, policies with termination conditions, also known as “options.”  these outcomes can be abstract state representations if those in turn are predictions of experience.</li>
<li>state representations, like all knowledge, should be tied to experience as much as possible.  thus, the bayesian and POMDP conceptions of state estimation are mistaken.</li>
<li>temporal-difference learning is not just for rewards, but for learning about everything, for all world knowledge.  any moment-by-moment signal (e.g., a sensation or a state variable) can substitute for the reward in a temporal-difference error.  “TD learning is not just for rewards”</li>
<li>learning is continual, with the same processes operating at every moment, with only the content changing at different times and different levels of abstraction. “the one learning algorithm”</li>
<li>evidence adds and subtracts to get an overall prediction or action tendency.  thus policy and prediction functions can be primarily linear in the state representation, with learning restricted to the linear parameters.  this is possible because the state representation contains many state variables other than predictions and that are linearly independent of each other.  these include immediate non-linear functions of the other state variables as well as variables with their own dynamics (e.g., to create internal “micro-stimuli”).</li>
<li>a major thing that the mind does is to sculpt and manage its state representation.  it discovers a) options and option models that induce useful abstract state variables and predictive world models, and b) useful non-linear, non-predictive state variables.   it continually assesses all state variables for utility, relevance, and the extent to which they generalize.  researching the process of discovery is difficult outside of the context of a complete agent.</li>
<li>learning itself is intrinsically rewarding.  the tradeoff between exploration and exploitation always comes down to “learning feels good.”</li>
<li>options are not data structures, and are not executed.  they may exist only as abstractions.</li>
</ol>
<p>some of these principles are stated in radical, absolutist, and reductionist terms.  this is as it should be.  in some cases, softer versions of the principles (for example, removing the word “all”) are still interesting.  moreover, the words “is” and “are” in the principles are a shorthand and simplification.  they should be interpreted in the sense of Marrʼs “levels of explanation of a complex information-processing system.”  that is, “is” can be read as “is well thought of as” or “insight can be gained by thinking of it as.”</p>
<p>a complete agent can be obtained from just two processes:</p>
<ul>
<li>a moment-by-moment state-update process, and</li>
<li>a moment-by-moment action selection policy.</li>
</ul>
<p>everything else has an effect only by changing these two.  a lot can be done purely by learning processes (operating uniformly as in principle 10), before introducing planning.  this can be done in the following stages:</p>
<ul>
<li>(a) a policy and value function can be learned by conventional model-free reinforcement learning using the current state variables</li>
<li>(b) state variables with a predictive interpretation can learn to become more accurate predictors</li>
<li>(c) discovery processes can operate to find more useful predictive and non-predictive state variables</li>
<li>(d) prediction of outcomes, together with fast learning, can produce a simple form of foresight and behavior controlled by anticipated consequences</li>
</ul>
<p>much of the learning above constitutes learning a predictive world model, but it is not yet planning.  planning requires learning from anticipated experience at states other than the current one.  the agent must disassociate himself from the current state and imagine absent others.</p>
<h2><a class="header" href="#the-definition-of-intelligence" id="the-definition-of-intelligence">The Definition of Intelligence</a></h2>
<p>July 9, 2016</p>
<p>John McCarthy long ago gave one of the best definitions: &quot;Intelligence is the computational part of the ability to achieve goals in the world”. That is pretty straightforward and does not require a lot of explanation. It also allows for intelligence to be a matter of degree, and for intelligence to be of several varieties, which is as it should be. Thus a person, a thermostat, a chess-playing program, and a corporation all achieve goals to various degrees and in various senses. For those looking for some ultimate ‘true intelligence’, the lack of an absolute, binary definition is disappointing, but that is also as it should be.</p>
<p>The part that might benefit from explanation is what it means to achieve goals. What does it mean to have a goal? How can I tell if a system really has a goal rather than seems to? These questions seem deep and confusing until you realize that a system having a goal or not, despite the language, is not really a property of the system itself. It is in the relationship between the system and an observer. (In Dennett's words, it is a ‘stance’ that the observer take with respect to the system.)</p>
<p>What is it in the relationship between the system and the observer that makes it a goal-seeking system? It is that the system is most usefully understood (predicted, controlled) in terms of its outcomes rather than its mechanisms. Thus, for a home-owner a thermostat is most usefully understood in terms of its keeping the temperature constant, as achieving that outcome, as having that goal. But if i am an engineer designing a thermostat, or a repairman fixing one, then i need to understand it at a mechanistic level—and thus it does not have a goal. The thermostat does or does not have a goal depending of the observer. Another example is the person playing the chess computer. If I am a naive person, and a weaker player, I can best understand the computer as having the goal of beating me, of checkmating my king. But if I wrote the chess program (and it does not look very deep) I have a mechanistic way of understanding it that may be more useful for predicting and controlling it (and beating it).</p>
<p>Putting these two together, we can define intelligence concisely (though without much hope of being genuinely understood without further explanation):</p>
<blockquote>
<p>Intelligence is the computational part of the ability to achieve goals. A goal achieving system is one that is more usefully understood in terms of outcomes than in terms of mechanisms.</p>
</blockquote>
<h2><a class="header" href="#the-bitter-lesson" id="the-bitter-lesson">The Bitter Lesson</a></h2>
<p><a href="http://incompleteideas.net/IncIdeas/BitterLesson.html">Source</a>
March 13, 2019</p>
<p>The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin. The ultimate reason for this is Moore's law, or rather its generalization of continued exponentially falling cost per unit of computation. Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available. Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation. These two need not run counter to each other, but in practice they tend to. Time spent on one is time not spent on the other. There are psychological commitments to investment in one approach or the other. And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.  There were many examples of AI researchers' belated learning of this bitter lesson, and it is instructive to review some of the most prominent.</p>
<p>In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess. When a simpler, search-based approach with special hardware and software proved vastly more effective, these human-knowledge-based chess researchers were not good losers. They said that &quot;brute force&quot; search may have won this time, but it was not a general strategy, and anyway it was not how people played chess. These researchers wanted methods based on human input to win and were disappointed when they did not.</p>
<p>A similar pattern of research progress was seen in computer Go, only delayed by a further 20 years. Enormous initial efforts went into avoiding search by taking advantage of human knowledge, or of the special features of the game, but all those efforts proved irrelevant, or worse, once search was applied effectively at scale. Also important was the use of learning by self play to learn a value function (as it was in many other games and even in chess, although learning did not play a big role in the 1997 program that first beat a world champion). Learning by self play, and learning in general, is like search in that it enables massive computation to be brought to bear. Search and learning are the two most important classes of techniques for utilizing massive amounts of computation in AI research. In computer Go, as in computer chess, researchers' initial effort was directed towards utilizing human understanding (so that less search was needed) and only much later was much greater success had by embracing search and learning.</p>
<p>In speech recognition, there was an early competition, sponsored by DARPA, in the 1970s. Entrants included a host of special methods that took advantage of human knowledge---knowledge of words, of phonemes, of the human vocal tract, etc. On the other side were newer methods that were more statistical in nature and did much more computation, based on hidden Markov models (HMMs). Again, the statistical methods won out over the human-knowledge-based methods. This led to a major change in all of natural language processing, gradually over decades, where statistics and computation came to dominate the field. The recent rise of deep learning in speech recognition is the most recent step in this consistent direction. Deep learning methods rely even less on human knowledge, and use even more computation, together with learning on huge training sets, to produce dramatically better speech recognition systems. As in the games, researchers always tried to make systems that worked the way the researchers thought their own minds worked---they tried to put that knowledge in their systems---but it proved ultimately counterproductive, and a colossal waste of researcher's time, when, through Moore's law, massive computation became available and a means was found to put it to good use.</p>
<p>In computer vision, there has been a similar pattern. Early methods conceived of vision as searching for edges, or generalized cylinders, or in terms of SIFT features. But today all this is discarded. Modern deep-learning neural networks use only the notions of convolution and certain kinds of invariances, and perform much better.</p>
<p>This is a big lesson. As a field, we still have not thoroughly learned it, as we are continuing to make the same kind of mistakes. To see this, and to effectively resist it, we have to understand the appeal of these mistakes. We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.</p>
<p>One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.</p>
<p>The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries. All these are part of the arbitrary, intrinsically-complex, outside world. They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity. Essential to these methods is that they can find good approximations, but the search for them should be by our methods, not by us. We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.</p>
<h1><a class="header" href="#compilers" id="compilers">Compilers</a></h1>
<h2><a class="header" href="#compiler-design-in-c-1990-holub" id="compiler-design-in-c-1990-holub">Compiler Design in C (1990, Holub)</a></h2>
<ul>
<li>1 Basic Concepts</li>
<li>1.1 The Parts of the Compiler</li>
<li>1.2 Representing Computer Languages</li>
<li>1.3 A Recursive-Descent Expression Compiler</li>
<li>2 Input and Lexical Analysis</li>
<li>2.1 The Lexical Analyzer as Part of a Compiler</li>
<li>2.2 Error Recovery in Lexical Analysis</li>
<li>2.3 Input Systems</li>
<li>2.4 Lexical Analysis</li>
<li>2.5 Lex - a Lexical-Analyzer Generator</li>
<li>3 Context-Free Grammars</li>
<li>3.1 Sentences, Phrases, and Context-Free Grammars</li>
<li>3.2 Derivations and Sentential Forms</li>
<li>3.3 Parse Trees and Semantic Difficulties</li>
<li>3.4 Epsilon Productions</li>
<li>3.5 The End-of-Input Marker</li>
<li>3.6 Right-Linear Grammars</li>
<li>3.7 Lists, Recursion, and Associativity</li>
<li>3.8 Expressions</li>
<li>3.9 Ambiguous Grammars</li>
<li>3.10 Syntax-Directed Translation</li>
<li>3.11 Representing Generic Grammars</li>
<li>4 Top-Down Parsing</li>
<li>4.1 Push-Down Automata</li>
<li>4.2 Using a PDA for a Top-Down Parse</li>
<li>4.3 Error Recovery in a Top-Down Parser</li>
<li>4.4 Augmented Grammars and Table-Driven Parsers</li>
<li>4.5 Automating the Top-Down Parse Process</li>
<li>4.6 LL(1) Grammars and Their Limitations</li>
<li>4.7 Making the Parse Tables</li>
<li>4.8 Modifying Grammars</li>
<li>4.9 Implementing LL(1) Grammars</li>
<li>4.10 LLama - Implementing an LL(1) Parser-Generator</li>
<li>5 Bottom-Up Parsing</li>
<li>5.1 How Bottom-Up Parsing Works</li>
<li>5.2 Recursion in Bottom-Up Parsing</li>
<li>5.3 Implementing the Parser as a State Machine</li>
<li>5.4 Error Recovery in an LR Parser</li>
<li>5.5 The Value Stack and Attribute Processing</li>
<li>5.6 Creating LR Parse Tables - Theory</li>
<li>5.7 Representing LR State Tables</li>
<li>5.8 Eliminating Single-Reduction States</li>
<li>5.9 Using Ambiguous Grammars</li>
<li>5.10 Implementing an LALR(1) Parser - The Occs Output File</li>
<li>5.11 Implementing an LALR(1) Parser Generator - Occs Internals</li>
<li>5.12 Parser-File Generation</li>
<li>5.13 Generating LALR(1) Parse Tables</li>
<li>6 Code Generation</li>
<li>6.1 Intermediate Languages</li>
<li>6.2 C-Code An Intermediate Language and Virtual Machine</li>
<li>6.3 The Symbol Table</li>
<li>6.4 The Parser: Configuration</li>
<li>6.5 The Lexical Analyzer</li>
<li>6.6 Declarations</li>
<li>6.7 The gen() Subroutine</li>
<li>6.8 Expressions</li>
<li>6.8 Statements and Control Flow</li>
<li>7 Optimization Strategies</li>
<li>7.1 Parser Optimizations</li>
<li>7.2 Linear (Peephole) Optimizations</li>
<li>7.3 Structural Optimizations</li>
<li>7.4 Aliasing Problems</li>
</ul>
<h2><a class="header" href="#parsing-techniques-a-practical-guide-1990-grune" id="parsing-techniques-a-practical-guide-1990-grune">Parsing Techniques. A Practical Guide (1990, Grune)</a></h2>
<h2><a class="header" href="#compiler-construction-1996-waite-goos" id="compiler-construction-1996-waite-goos">Compiler Construction (1996, Waite, Goos)</a></h2>
<ul>
<li>1 Introduction and Overview</li>
<li>2 Properties of Programming Languages</li>
<li>3 Properties of Real and Abstract Machines</li>
<li>4 Abstract Program Representation</li>
<li>5 Elements of Formal Systems</li>
<li>6 Lexical Analysis</li>
<li>7 Parsing</li>
<li>8 Attribute Grammars</li>
<li>9 Semantic Analysis</li>
<li>10 Code Generation</li>
<li>11 Assembly</li>
<li>12 Error Handling</li>
<li>13 Optimization</li>
<li>14 Implementation</li>
</ul>
<h2><a class="header" href="#building-an-optimizing-compiler-1997-morgan" id="building-an-optimizing-compiler-1997-morgan">Building an Optimizing Compiler (1997, Morgan)</a></h2>
<ul>
<li>1 Overview</li>
<li>2 Compiler Structure</li>
<li>3 Graphs</li>
<li>4 Flow Graph</li>
<li>5 Local Optimization</li>
<li>6 Alias Analysis</li>
<li>7 Static Single Assignment</li>
<li>8 Dominator-Based Optimization</li>
<li>9 Advanced Techniques</li>
<li>10 Global Optimization</li>
<li>11 Limiting Resources</li>
<li>12 Scheduling and Rescheduling</li>
<li>13 Register Allocation</li>
<li>14 The Object Module</li>
<li>15 Completion and Futures</li>
</ul>
<h2><a class="header" href="#modern-compiler-implementation-in-c-1998-appel" id="modern-compiler-implementation-in-c-1998-appel">Modern Compiler Implementation in C (1998, Appel)</a></h2>
<ul>
<li>Part I Fundamentals of Compilation
<ul>
<li>1 Introduction</li>
<li>2 Lexical Analysis</li>
<li>3 Parsing</li>
<li>4 Abstract Syntax</li>
<li>5 Semantic Analysis</li>
<li>6 Activation Records</li>
<li>7 Translation to Intermediate Code</li>
<li>8 Basic Blocks and Traces</li>
<li>9 Instruction Selection</li>
<li>10 Liveness Analysis</li>
<li>11 Register Allocation</li>
<li>12 Putting it All Together</li>
</ul>
</li>
<li>Part II Advanced Topics
<ul>
<li>13 Garbage Collection</li>
<li>14 Object-Oriented Languages</li>
<li>15 Functional Programming Languages</li>
<li>16 Polymorphic Types</li>
<li>17 Dataflow Analysis</li>
<li>18 Loop Optimization</li>
<li>19 Static Single Assignment Form</li>
<li>20 Pipelining and Scheduling</li>
<li>21 The Memory Hierarchy</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#modern-compiler-implementation-in-ml-1998-appel" id="modern-compiler-implementation-in-ml-1998-appel">Modern Compiler Implementation in ML (1998, Appel)</a></h2>
<ul>
<li>Part I Fundamentals of Compilation
<ul>
<li>1 Introduction</li>
<li>2 Lexical Analysis</li>
<li>3 Parsing</li>
<li>4 Abstract Syntax</li>
<li>5 Semantic Analysis</li>
<li>6 Activation Records</li>
<li>7 Translation to Intermediate Code</li>
<li>8 Basic Blocks and Traces</li>
<li>9 Instruction Selection</li>
<li>10 Liveness Analysis</li>
<li>11 Register Allocation</li>
<li>12 Putting it All Together</li>
</ul>
</li>
<li>Part II Advanced Topics
<ul>
<li>13 Garbage Collection</li>
<li>14 Object-Oriented Languages</li>
<li>15 Functional Programming Languages</li>
<li>16 Polymorphic Types</li>
<li>17 Dataflow Analysis</li>
<li>18 Loop Optimization</li>
<li>19 Static Single Assignment Form</li>
<li>20 Pipelining and Scheduling</li>
<li>21 The Memory Hierarchy</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#compiler-design-handbook-optimizations-and-machine-code-generation-2003-srikant-shankar" id="compiler-design-handbook-optimizations-and-machine-code-generation-2003-srikant-shankar">Compiler Design Handbook. Optimizations and Machine Code Generation (2003, Srikant, Shankar)</a></h2>
<ul>
<li>1 Data Flow Analysis</li>
<li>2 Automatic Generation of Code Optimizers from Formal Specifications</li>
<li>3 Scalar Compiler Optimizations on the Single Static Assignment</li>
<li>4 Profile-Guided Compiler Optimizations</li>
<li>5 Shape Analysis and Applications</li>
<li>6 Optimizations for Object-Oriented Languages</li>
<li>7 Data Flow Testing</li>
<li>8 Program Slicing</li>
<li>9 Debuggers for Programming Languages</li>
<li>10 Dependence Analysis and Parallelization Transformations</li>
<li>11 Compilation for Distributed Memory Architectures</li>
<li>12 Automatic Data Distribution</li>
<li>13 Register Allocation</li>
<li>14 Architecture Description Language for Retargetable Compilation</li>
<li>15 Instruction Selection Using Tree Parsing</li>
<li>16 Retargetable Very Long Instruction Word Compiler Framework</li>
<li>17 Instruction Scheduling</li>
<li>18 Software Pipelining</li>
<li>19 Dynamic Compilation</li>
<li>20 Compiling Safe Mobile Code</li>
<li>21 Type Systems in Programming Languages</li>
<li>22 Introduction to Operational Semantics</li>
</ul>
<h2><a class="header" href="#compiler-construction-2005-wirth" id="compiler-construction-2005-wirth">Compiler Construction (2005, Wirth)</a></h2>
<ul>
<li>1 Introduction</li>
<li>2 Language and Syntax</li>
<li>3 Regular Languages</li>
<li>4 Analysis of Context-Free Language</li>
<li>5 Attributed Grammars and Semantics</li>
<li>6 The Programming Language Oberon-0</li>
<li>7 A Parser for Oberon-0</li>
<li>8 Consideation of Context Specified by Declarations</li>
<li>9 A RISC Architecture as a Target</li>
<li>10 Expressions and Assignments</li>
<li>11 Conditional and Repeated Statements and Boolean Expressions</li>
<li>12 Procedures and the Concept of Locality</li>
<li>13 Elementary Data Types</li>
<li>14 Open Arrays, Pointers, and Procedure Types</li>
<li>15 Modules and Separate Compilation</li>
<li>16 Code Optimizations and the Frontend/Backend Structure</li>
</ul>
<h2><a class="header" href="#compilers-principles-techniques-and-tools-2006-2nd-ed-aho-lam-sethi-ullman" id="compilers-principles-techniques-and-tools-2006-2nd-ed-aho-lam-sethi-ullman">Compilers. Principles, Techniques and Tools (2006, 2nd Ed, Aho, Lam, Sethi, Ullman)</a></h2>
<pre><code>  Introduction
  A simple syntax-directed translator
  Lexical analysis
  Syntax analysis
  Syntax-directed translation
  Intermediate code generation
  Run-time environments
    Storage organization
      Static versus dynamic storage allocation
    Stack allocation of space
      Activation trees
      Activation records
      Calling sequences
      Variable-length data on the stack
    Access to nonlocal data on the stack
      Data access without nested procedures
      Issues with nested procedures
      A language with nested procedure declarations
      Nesting depth
      Access links
      Manipulating access links
      Displays
    Heap management
      The memory manager
      The memory hierarchy of a computer
      Locality in programs
        Optimization using the memory hierarchy
      Reducing fragmentation
        Best-fit and next-fit object placement
        Managing and coalescing free space
      Manual deallocation requests
        Problems with manual deallocation
        Programming conventions and tools
    Introduction to garbage collection
      Design goals for garbage collection
        Basic requirement: type safety
        Performance metrics
      Reachability
      Reference counting garbage collection
    Introduction to trace-based collection
      A basic mark-and-sweep collector
      Basic abstraction
      Optimizing mark-and-sweep
      Mark-and-compact garbage collection
      Copying collectors
      Comparing costs
    Short-pause garbage collection
      Incremental garbage collection
        Prtecision of incremental collection
      Incremental reachability analysis
        Implementing write barriers
        Combining incremental and copying techniques
      Partial-collection basics
      Generational garbage collection
      The train algorithm
        Remembered sets
        Managing trains
        Garbage collecting a car
        Panic mode
    Advance topics in garbage collection
      Parallel and concurrent garbage collection
      Partial object relocation
      Conservative collection for unsafe languages
      Weak references
    Summary
  Code generation
    Issues in the design of a code generator
      Input to the code generator
      The target program
      Instruction selection
      Register allocation
    The target language
      A simple target machine model
      Program and instruction costs
    Addresses in the target code
      Static allocation
      Stack allocation
      Run-time addresses for names
    Basic blocks and flow graphs
      Basic blocks
      Next-use information
      Flow graphs
      Representation of flow graphs
      Loops
    Optimization of basic blocks
      The DAG representation of basic blocks
      Finding local common subexpressions
      Dead code elimination
      The use of algebraic identities
      Representation of array references
      Pointer assignments and procedure calls
      Reassembling basic blocks from DAGs
    A simple code generator
      Register and address descriptors
      The code-generation algorithm
        Machine instructions for copy statements
        Ending the basic block
        Managing register and address descriptors
      Design of the function getReg
    Peephole optimization
      Eliminating redundant loads and stores
      Eliminating unreachable code
      Flow-of-control optimizations
      Algebraic simplification and reduction in strength
      Use of machine idioms
    Register allocation and assignment
      Global register allocation
      Usage counts
      Register assignment for outer loops
      Register allocation by graph coloring
    Instruction selection by tree-rewriting
      Tree-translation scheme
      Code generation by tiling an input tree
      Pattern matching by parsing
      Routines for semantic checking
      General tree matching
    Code generation for expressions
      Ershov numbers
      Generating code from labeled expression trees
      Evaluating expression with an insufficient supply of registers
    Dynamic programming code-generation
      Contiguous evaluation
      The dynamic programming algorithm
    Summary
  Machine-independent optimizations
  Instruction-level parallelism
  Optimizing for parallelism and locality
  Interprocedural analysis
</code></pre>
<h2><a class="header" href="#compiler-construction-an-advanced-course-2007" id="compiler-construction-an-advanced-course-2007">Compiler Construction: An Advanced Course (2007)</a></h2>
<h2><a class="header" href="#basics-of-compiler-design-2010-torben-mogensen" id="basics-of-compiler-design-2010-torben-mogensen">Basics of Compiler Design (2010, Torben Mogensen)</a></h2>
<ul>
<li>1 Introduction</li>
<li>2 Lexical Analysis</li>
<li>3 Syntax Analysis</li>
<li>4 Scopes and Symbol Tables</li>
<li>5 Interpretation</li>
<li>6 Type Checking</li>
<li>7 Intermediate-Code Generation</li>
<li>8 Machine Code Generation</li>
<li>9 Register Allocation</li>
<li>10 Function Calls</li>
<li>11 Analysis and Optimization</li>
<li>12 Memory Management</li>
<li>13 Bootstrapping a Compiler</li>
</ul>
<h2><a class="header" href="#compiler-design-theory-tools-examples-cc-edition-2010-bergmann" id="compiler-design-theory-tools-examples-cc-edition-2010-bergmann">Compiler Design. Theory, Tools, Examples. C/C++ Edition (2010, Bergmann)</a></h2>
<ul>
<li>1 Introduction</li>
<li>2 Lexical Analysis</li>
<li>3 Syntax Analysis</li>
<li>4 Top-Down Parsing</li>
<li>5 Bottom-Up Parsing</li>
<li>6 Code Generation</li>
<li>7 Optimization</li>
</ul>
<h2><a class="header" href="#engineering-a-compiler-2011-2nd-ed-cooper-torczon" id="engineering-a-compiler-2011-2nd-ed-cooper-torczon">Engineering A Compiler (2011, 2nd Ed, Cooper, Torczon)</a></h2>
<ul>
<li>1 Overview of Compilation
<ul>
<li>1.1 Introduction</li>
<li>1.2 Compiler Structure</li>
<li>1.3 Overview of Translation</li>
</ul>
</li>
<li>2 Scanners
<ul>
<li>2.1 Introduction</li>
<li>2.2 Recognizing words</li>
<li>2.3 Regular Expressions</li>
<li>2.4 From Regular Expression to Scanner</li>
<li>2.5 Implementing Scanners</li>
<li>2.6 Advanced Topics</li>
</ul>
</li>
<li>3 Parsers
<ul>
<li>3.1 Introduction</li>
<li>3.2 Expressing Syntax</li>
<li>3.3 Top-Down Parsing</li>
<li>3.4 Bottom-Up Parsing</li>
<li>3.5 Practical Issues</li>
<li>3.6 Advanced Topics</li>
</ul>
</li>
<li>4 Context-sensitive Analysis
<ul>
<li>4.1 Introduction</li>
<li>4.2 An Introduction to Type Systems</li>
<li>4.3 An Attribute-Grammar Framework</li>
<li>4.4 Ad Hoc Syntax-Directed Translation</li>
<li>4.5 Advanced Topics</li>
</ul>
</li>
<li>5 Intermediate Representations
<ul>
<li>5.1 Introduction</li>
<li>5.2 Graphical IRs</li>
<li>5.3 Linear IRs</li>
<li>5.4 Mapping Values to Names</li>
<li>5.5 Symbol Tables</li>
</ul>
</li>
<li>6 Procedure Abstraction
<ul>
<li>6.1 Introduction</li>
<li>6.2 Procedure Calls</li>
<li>6.3 Name Spaces</li>
<li>6.4 Communicating Values Between Procedures</li>
<li>6.5 Advanced Topics</li>
</ul>
</li>
<li>7 Code Shape
<ul>
<li>7.1 Introduction</li>
<li>7.2 Assigning Storage Locations</li>
<li>7.3 Arithmetic Operators</li>
<li>7.4 Boolean and Relational Operators</li>
<li>7.5 Storing and Accessing Arrays</li>
<li>7.6 Character Strings</li>
<li>7.7 Structure References</li>
<li>7.8 Control Flow Constructs</li>
<li>7.9 Procedure Calls</li>
</ul>
</li>
<li>8 Introduction to Optimization
<ul>
<li>8.1 Introduction</li>
<li>8.2 Background</li>
<li>8.3 Scope of Optimizations</li>
<li>8.4 Local Optimization</li>
<li>8.5 Regional Optimization</li>
<li>8.6 Global Optimization</li>
<li>8.7 Interprocedural Optimization</li>
</ul>
</li>
<li>9 Data-Flow Analysis
<ul>
<li>9.1 Introduction</li>
<li>9.2 Iterative Data-Flow Analysis</li>
<li>9.3 Static Single-Assigment Form</li>
<li>9.4 Interprocedural Analysis</li>
<li>9.5 Advanced Topics</li>
</ul>
</li>
<li>10 Scalar Optimization
<ul>
<li>10.1 Introduction</li>
<li>10.2 Eliminating Useless and Unreachable Code</li>
<li>10.3 Code Motion</li>
<li>10.4 Specialization</li>
<li>10.5 Redundancy Elimination</li>
<li>10.6 Finishing Other Transformations</li>
<li>10.7 Advanced Topics</li>
</ul>
</li>
<li>11 Instruction Selection
<ul>
<li>11.1 Introduction</li>
<li>11.2 Code Generation</li>
<li>11.3 Extending the Simple Treewalk Scheme</li>
<li>11.4 Instruction Selection via Tree Pattern Matching</li>
<li>11.5 Instruction Selection via Peephole Optimization</li>
<li>11.6 Advanced Topics</li>
</ul>
</li>
<li>12 Instruction Scheduling
<ul>
<li>12.1 Introduction</li>
<li>12.2 The Instruction-Scheduling Problem</li>
<li>12.3 Local List Scheduling</li>
<li>12.4 Regional Scheduling</li>
<li>12.5 Advanced Topics</li>
</ul>
</li>
<li>13 Register Allocation
<ul>
<li>13.1 Introduction</li>
<li>13.2 Background Issues</li>
<li>13.3 Local Register Allocation and Assignment</li>
<li>13.4 Global Register Allocation and Assignment</li>
<li>13.5 Advanced Topics</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#lets-build-a-compiler-2012-crenshaw" id="lets-build-a-compiler-2012-crenshaw">Let's Build A Compiler (2012, Crenshaw)</a></h2>
<h2><a class="header" href="#modern-compiler-design-2012-2nd-ed-grune" id="modern-compiler-design-2012-2nd-ed-grune">Modern Compiler Design (2012, 2nd Ed, Grune)</a></h2>
<ul>
<li>1 Introduction</li>
<li>Part I
<ul>
<li>2 Program Text to Tokens - Lexical Analysis</li>
<li>3 Tokens to Syntax Tree - Syntax Analysis</li>
</ul>
</li>
<li>Part II
<ul>
<li>4 Annotating the Abstract Syntax Tree</li>
<li>5 Manual Context Handling</li>
</ul>
</li>
<li>Part III
<ul>
<li>6 Interpretation</li>
<li>7 Code Generation</li>
<li>8 Assemblers, Disassemblers, Linkers and Loaders</li>
<li>9 Optimization Techniques</li>
</ul>
</li>
<li>Part IV Memory Management
<ul>
<li>10 Explicit and Implicit Memory Management</li>
<li>Part V From Abstract Syntax Tree to Intermediate Code</li>
<li>11 Imperative and Object-Oriented Programs</li>
<li>12 Functional Programs</li>
<li>13 Logic Programs</li>
<li>14 Parallel and Distributed Programs</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#distributed-systems" id="distributed-systems">Distributed Systems</a></h1>
<h2><a class="header" href="#designing-data-intesive-applications" id="designing-data-intesive-applications">DESIGNING DATA INTESIVE APPLICATIONS</a></h2>
<pre><code>I foundations of data systems
	1 reliable, scalable, and maintainable applications
		1.1 thinking about data systems
		1.2 reliability
		1.3 scalability
		1.4 maintainability
	2 data models and query languages
		2.1 relational model vs document model
		2.2 query languages for data
		2.3 graph-like data models
	3 storage and retrieval
		3.1 data structures that power your database
		3.2 transaction processing or analytics?
		3.3 column-oriented storage
	4 encoding and evolution
		4.1 formats for encoding data
		4.2 modes of dataflow
II distributed data
	5 replication
		5.1 leaders and followers
		5.2 problems with replication lag
		5.3 multi-leader replication
		5.4 leaderless replication
	6 partitioning
		6.1 partitioning and replication
		6.2 partitioning of key-value data
		6.3 partitioning and secondary indexes
		6.4 rebalancing partitions
		6.5 request routing
	7 transactions
		7.1 the slippery concept of a transaction
		7.2 weak isolation levels
		7.3 serializability
	8 the trouble with distributed systems
		8.1 faults and partial failures
		8.2 unreliable networks
		8.3 unreliable clocks
		8.4 knowledge, truth and lies
	9 consistency and consensus
		9.1 consistency guarantees
		9.2 linearizability
		9.3 ordering guarantees
		9.4 distributed transactions and consensus
III derived data
	10 batch processing
		10.1 batch processing with unix tools
		10.2 mapreduce and distributed filesystems
		10.3 beyond mapreduce
	11 stream processing
		11.1 transmitting event streams
		11.2 database and streams
		11.3 processing streams
	12 the future of data systems
		12.1 data integration
		12.2 unbundling databases
		12.3 aiming for correctness
		12.4 doing the right thing
</code></pre>
<h2><a class="header" href="#guide-to-reliable-distributed-systems" id="guide-to-reliable-distributed-systems">GUIDE TO RELIABLE DISTRIBUTED SYSTEMS</a></h2>
<pre><code>    I computing in the cloud
        1 introduction
        2 the way of the cloud
        3 client perspective
        4 network perspective
        5 the structure of cloud data centers
        6 remote procedure calls and the client/server model
        7 corba: the common object request broker architecture
        8 system support for fast client/server communication
    II reliable distributed computing
        9 how and why computer systems fail
        10 overcoming failures in a distributed system
        11 dynamic membership
        12 group communication systems
        13 point to point and multi-group considerations
        14 the virtual synchrony execution model
        15 consistency in distributed systems
    III applications of reliability techniques
        16 retrofitting reliability into complex systems
        17 software architectures for group communication
    IV related technologies
        18 security options for distributed settings
        19 clock synchronization and synchronization systems
        20 transactional systems
        21 peer-to-peer systems and probabilistic protocols
        22 appendix A: virtualy synchronous methodology for building dynamic reliable services
        23 appendix B: isis API
</code></pre>
<h2><a class="header" href="#protocol-design" id="protocol-design">Protocol Design</a></h2>
<pre><code>    1 introduction
        1.1 what is a protocol?
        1.2 protocols as processes
        1.3 techniques for actual proofs
        1.4 real protocols
        1.5 readers's guide
    2 CSP descriptions and proof rules
        2.1 processes and process synchronization
        2.2 channel history semantics
        2.3 failure semantics
    3 protocols and services
        3.1 providing a service
        3.2 service features
        3.3 OSI and other layered architectures
    4 basic protocol mechanisms
        4.1 sequence control and error control
        4.2 flow control
        4.3 indication of change of peer state
        4.4 change of service mode
        4.5 multiplexing and splitting
        4.6 segmentation and reassembly
        4.7 prioritisation
    5 multi-peer consensus
        5.1 reliable consensus
        5.2 election
        5.3 commitment
        5.4 byzantine agreement
        5.5 clock synchronization
        5.6 finding the global state
    6 security
        6.1 cryptographic methods
        6.2 integrity
        6.3 digital signatures
        6.4 entity authentication
        6.5 key exchange
        6.6 non-cryptographic methods
    7 naming addressing and routing
        7.1 general principles of naming and addressing
        7.2 addressing structures
        7.3 routing
        7.4 congestion
    8 protocol encoding
        8.1 simple binary encoding
        8.2 TLV encoding
        8.3 ASN.1 encoding
        8.4 ASCII encodings
    9 protocols in the OSI lower layers
        9.1 data link layer
        9.2 network layer
        9.3 transport layer
    10 application support protocols
        10.1 session layer
        10.2 presentation layer
        10.3 application layer
        10.4 basic application service elements
        10.5 commitment, concurrency and recovery
        10.6 client-server systems
        10.7 security middleware
    11 application protocols
        11.1 file transfer
        11.2 distributed transaction processing
        11.3 message handling
        11.4 hypertext and the world wide web
        11.5 web services
    A notation
        A.1 data types and variables
        A.2 data values and expressions
        A.3 processes and process expressions
        A.4 traces, failures, and transitions
        A.5 inference rules for process specifications
        A.6 security
    B standarization
        B.1 standards organizations
        B.2 standards documents
</code></pre>
<h2><a class="header" href="#introduction-to-reliable-and-secure-distributed-programming-carlos-varela-cachin" id="introduction-to-reliable-and-secure-distributed-programming-carlos-varela-cachin">INTRODUCTION TO RELIABLE AND SECURE DISTRIBUTED PROGRAMMING (CARLOS VARELA, CACHIN)</a></h2>
<pre><code>    1 introduction
        1.1 motivation
        1.2 distributed programming abstractions
        1.3 the end-to-end argument
        1.4 software components
        1.5 classes of algorithms
    2 basic abstractions
        2.1 distributed computation
        2.2 abstracting processes
        2.3 cryptographics abstractions
        2.4 abstracting communication
        2.5 timing assumptions
        2.6 abstracting time
        2.7 distributed system models
    3 reliable broadcast
        3.1 motivation
        3.2 best-effort broadcast
        3.3 regular reliable broadcast
        3.4 uniform reliable broadcast
        3.5 stubborn broadcast
        3.6 logged best-effort broadcast
        3.7 logged uniform reliable broadcast
        3.8 probabilistic broadcast
        3.9 FIFO and causal broadcast
        3.10 byzantine consistent broadcast
        3.11 byzantine reliable broadcast
        3.12 byzantine broadcast channels
    4 shared memory
        4.1 introduction
        4.2 (1,N) regular register
        4.3 (1,N) atomic register
        4.4 (N,N) atomic register
        4.5 (1,N) logged regular register
        4.6 (1,N) byzantine safe register
        4.7 (1,N) byzantine regular register
        4.8 (1,N) byzantine atomic register
    5 consensus
        5.1 regular consensus
        5.2 uniform consensus
        5.3 uniform consensus in the fail-noisy model
        5.4 logged consensus
        5.5 randomized consensus
        5.6 byzantine consensus
        5.7 byzantine randomized consensus
    6 consensus variants
        6.1 total-order broadcast
        6.2 byzantine total order broadcast
        6.3 terminating reliable broadcast
        6.4 fast consensus
        6.5 fast byzantine consensus
        6.6 nonblocking atomic commit
        6.7 group membership
        6.8 view-synchronous communication
    7 concluding remarks
        7.1 implementation in appia
        7.2 further implementations
        7.3 further reading
</code></pre>
<h2><a class="header" href="#tanenbaum---distributed-systems-principles-and-paradigms" id="tanenbaum---distributed-systems-principles-and-paradigms">TANENBAUM - DISTRIBUTED SYSTEMS PRINCIPLES AND PARADIGMS</a></h2>
<pre><code>    1 introduction
        1.1 definition of distributed system
        1.2 goals
        1.3 types of distributed systems
    2 architectures
        2.1 architectural styles
        2.2 system architectures
        2.3 architectures versus middleware
        2.4 self-management in distributed systems
    3 processes
        3.1 threads
        3.2 virtualization
        3.3 clients
        3.4 servers
        3.5 code migration
    4 communication
        4.1 fundamentals
        4.2 remote procedure call
        4.3 message-oriented communication
        4.4 stream-oriented communication
        4.5 multicast communication
    5 naming
        5.1 names, identifiers and addresses
        5.2 flat naming
        5.3 structured naming
        5.4 attribute-based naming
    6 synchronization
        6.1 clock synchronization
        6.2 logical clocks
        6.3 mutual exlusion
        6.4 global positioning of nodes
        6.5 election algorithms
    7 consistency and replication
        7.1 introduction
        7.2 data-centric consistency models
        7.3 client-centric consistency models
        7.4 replica management
        7.5 consistency protocols
    8 fault tolerance
        8.1 introduction to fault tolerance
        8.2 process resilience
        8.3 reliable client-server communication
        8.4 reliable group communication
        8.5 distributed commit
        8.6 recovery
    9 security
        9.1 introduction to security
        9.2 secure channels
        9.3 access control
        9.4 security management
    10 distributed object-based systems
        10.1 architecture
        10.2 processes
        10.3 communication
        10.4 naming
        10.5 synchronization
        10.6 consistency and replication
        10.7 fault tolerance
        10.8 security
    11 distributed file systems
        11.1 architecture
        11.2 processes
        11.3 communication
        11.4 naming
        11.5 synchronization
        11.6 consistency and replication
        11.7 fault tolerance
        11.8 security
    12 distributed web-based systems
        12.1 architecture
        12.2 processes
        12.3 communication
        12.4 naming
        12.5 synchronization
        12.6 consistency and replication
        12.7 fault tolerance
        12.8 security
    13 distributed coordination-based systems
        13.1 introduction to coordination models
        13.2 architectures
        13.3 processes
        13.4 communication
        13.5 naming
        13.6 synchronization
        13.7 consistency and replication
        13.8 fault tolerance
        13.9 security
    14 suggestions for further reading and bibliography
</code></pre>
<h2><a class="header" href="#distributed-systems-concepts-and-design-colouris" id="distributed-systems-concepts-and-design-colouris">Distributed Systems: Concepts and Design (Colouris)</a></h2>
<pre><code>    1 characterization of distributed systems
        1.1 introduction
        1.2 examples of distributed systems
        1.3 trends in distributed systems
        1.4 focus on resource sharing
        1.5 challenges
        1.6 case study: the world wide web
    2 system models
        2.1 introduction
        2.2 physical models
        2.3 architectural models
        2.4 fundamental models
    3 networking and internetworking
        3.1 introduction
        3.2 types of network
        3.3 network principles
        3.4 internet protocols
        3.5 case studies: ethernet, wifi and bluetooth
    4 interprocess communication
        4.1 introduction
        4.2 the api for the internet protocols
        4.3 external data representation and marshalling
        4.4 multicast communication
        4.5 network virtualization: overlay networks
        4.6 case study: MPI
    5 remote invocation
        5.1 introduction
        5.2 request-reply protocols
        5.3 remote procedure call
        5.4 remote procedure invocation
        5.5 case study: java RMI
    6 indirect communication
        6.1 introduction
        6.2 group communication
        6.3 publish-subscribe systems
        6.4 message queues
        6.5 shared memory approaches
    7 operating systems support
        7.1 introduction
        7.2 the operating system layer
        7.3 protection
        7.4 processes and threads
        7.5 communication and invocation
        7.6 operating system architecture
        7.7 virtualization at the operating system level
    8 distributed objects and components
        8.1 introduction
        8.2 distributed objects
        8.3 case study: CORBA
        8.4 from objects to components
        8.5 case studies: enterprise javabeans and fractal
    9 web services
        9.1 introduction
        9.2 web services
        9.3 service descriptions and IDL for web services
        9.4 a directory service for use with web services
        9.5 XML security
        9.6 coordination of web services
        9.7 applications of web services
    10 peer-to-peer systems
        10.1 introduction
        10.2 napster and its legacy
        10.3 peer-to-peer middleware
        10.4 routing overlays
        10.5 overlay case studies: pastry, tapestry
        10.6 application case studies: squirrel, oceanstore, ivy
    11 security
        11.1 introduction
        11.2 overview of security techniques
        11.3 digital signatures
        11.4 cryptography pragmatics
        11.6 case studies: needham-schroeder, kerberos, tls, 802.11 wifi
    12 distributed file systems
        12.1 introduction
        12.2 file service architecture
        12.3 case study: sun network file system
        12.4 case study: the andrew file system
        12.5 enhancements and further developments
    13 name services
        13.1 introduction
        13.2 name services and the domain name system
        13.3 directory services
        13.5 case study: the X.500 directory service
    14 time and global states
        14.1 introduction
        14.2 clocks, events and process states
        14.3 synchronizing physical clocks
        14.4 logical time and logical clocks
        14.5 global states
        14.6 distributed debugging
    15 coordination and agreement
        15.1 introduction
        15.2 distributed mutual exclusion
        15.3 elections
        15.4 coordination and agreement in group communication
        15.5 consensus and related problems
</code></pre>
<h2><a class="header" href="#distributed-operating-systems-tanenbaum" id="distributed-operating-systems-tanenbaum">Distributed Operating Systems (Tanenbaum)</a></h2>
<pre><code>    1 introduction to distributed systems
        1.1 what is a distributed system?
        1.2 goals
        1.3 hardware concepts
        1.4 software concepts
        1.5 design issues
    2 communication in distributed systems
        2.1 layered protocols
        2.2 asynchronous transfer mode networks
        2.3 the client-server model
        2.4 remote procedure call
        2.5 group communication
    3 synchronization in distributed systems
        3.1 clock synchronization
        3.2 mutual exclusion
        3.3 election algorithms
        3.4 atomic transactions
        3.5 deadlocks in distributed systems
    4 processes and processors in distributed systems
        4.1 threads
        4.2 system models
        4.3 processor allocation
        4.4 scheduling in distributed systems
        4.5 fault tolerance
        4.6 real-time distributed systems
    5 distributed file systems
        5.1 distributed file system design
        5.2 distributed file system implementation
        5.3 trends in distributed file systems
    6 distributed shared memory
        6.1 introduction
        6.2 what is shared memory?
        6.3 consistency models
        6.4 paged-based distributed shared memory
        6.5 shared-variable distributed shared memory
        6.6 object-based distributed shared memory
        6.7 comparison
    7 case study 1: amoeba
        7.1 introduction to amoeba
        7.2 objects and capabilities in amoeba
        7.3 process management in amoeba
        7.4 memory management in amoeba
        7.5 communication in amoeba
        7.6 the amoeba servers
    8 case study 2: mach
        8.1 introduction to mach
        8.2 process management in mach
        8.3 memory management in mach
        8.4 communication in mach
        8.5 unix emulation in mach
    9 case study 3: chorus
        9.1 introduction to chorus
        9.2 process management in chorus
        9.3 memory management in chorus
        9.4 communication in chorus
        9.5 unix emulation in chorus
        9.6 cool: an object oriented subsystem
        9.7 comparison of amoeba, mach and chorus
    10 case study 4: DCE
        10.1 introduction to DCE
        10.2 threads
        10.3 remote procedure call
        10.4 time service
        10.5 directory service
        10.6 security service
        10.7 distributed file system
</code></pre>
<h2><a class="header" href="#lamport---distributed-operating-systems-theory-and-practice" id="lamport---distributed-operating-systems-theory-and-practice">LAMPORT - DISTRIBUTED OPERATING SYSTEMS: THEORY AND PRACTICE</a></h2>
<pre><code>    1 formal aspects of concurrent systems
        1.1 a formal basis for the specification of concurrent systems
        1.2 on the construction of distributed programs
        1.3 derivation of distributed algorithms
    2 design issues for distributed systems
        2.1 design of highly decentralised operating systems
        2.2 communication models for distributed computation
        2.3 new concepts for distributed system structuring
    3 hardware support for distributed computing systems
        3.1 distributed computing system architectures: hardware
        3.2 hardware support for the distributed operating system of the heidelberg polyp processor
    4 case studies
        4.1 the apollo domain distributed file system
        4.2 the chorus distributed operating system: some design issues
        4.3 the conic support environment for distributed systems
        4.4 an experience in solving a transactions ordering problem in a distributed system
        4.5 distributed transaction processing and the camelot system
        4.6 work programs
</code></pre>
<h2><a class="header" href="#lamport---specifying-systems-tla" id="lamport---specifying-systems-tla">LAMPORT - SPECIFYING SYSTEMS (TLA+)</a></h2>
<pre><code>    I getting started
        1 a little simple math
        2 specifying a simple clock
        3 an asynchronous interface
        4 a FIFO
        5 a caching memory
        6 some more math
        7 writing a specification: some advice
    II more advanced topics
        8 liveness and fairness
        9 real time
        10 composing specifications
        11 advanced examples
    III the tools
        12 the syntactic analyzer
        13 the TLATEX typesetter
        14 the TLC model checker
    IV the TLA+ language
        15 the syntax of TLA+
        16 the operators of TLA+
        17 the meaning of a module
        18 the standard modules
</code></pre>
<h2><a class="header" href="#lynch---distributed-algorithms" id="lynch---distributed-algorithms">LYNCH - DISTRIBUTED ALGORITHMS</a></h2>
<pre><code>    I synchronous network algorithms
        1 introduction
        2 modelling 1: synchronous network model
        3 leader election in a synchronous ring
        4 algorithms in general synchronous networks
        5 distributed consensus with link failures
        6 distributed consensus with process failures
        7 more consensus problems
    II asynchronous algorithms
        8 modelling 2: asynchronous system model
    IIA asynchronous shared memory algorithms
        9 modelling 3: asynchronous shared memory model
        10 mutual exclusion
        11 resource allocation
        12 consensus
        13 atomic objects
    IIB asynchronous network algorithms
        14 modelling 4: asynchronous network model
        15 basic asynchronous network algorithms
        16 synchronizers
        17 shared memory versus networks
        18 logical time
        19 global snapshots and stable properties
        20 network resource allocation
        21 asynchronous network with process failures
        22 data link protocols
    III partially synchronous algorithms
        23 partially synchronous system models
        24 mutual exlusion with partial synchrony
        25 consensus with partial synchrony
</code></pre>
<h2><a class="header" href="#raynal---distributed-algorithms-for-message-passing-systems" id="raynal---distributed-algorithms-for-message-passing-systems">RAYNAL - DISTRIBUTED ALGORITHMS FOR MESSAGE-PASSING SYSTEMS</a></h2>
<pre><code>    I distributed graph algorithms
        1 basic definitions and network traversal algorithms
        2 dsitributed graph algorithms
        3 an algorithmic framework to compute global functions on a process graph
        4 leader election algorithms
        5 mobile objects navigating a network
    II logical time and global states in distributed systems
        6 nature of distributed computations and the concept of a global state
        7 logical time in asynchronous distributed systems
        8 asynchronous distributed checkpointing
        9 simulating synchrony on top of asynchronous systems
    III mutual exclusion and resource allocation
        10 permission-based mutual exclusion algorithms
        11 distributed resource allocation
    IV high-level communication abstractions
        12 order constraints on message delivery
        13 rendezvous (synchronous) communication
    V detection properties on distributed executions
        14 distributed termination detection
        15 distributed deadlock detection
    VI distributed shared memory
        16 atomic consistency (linearizability)
        17 sequential consistency
        18 afterword
</code></pre>
<h2><a class="header" href="#ghosh---distributed-systems-an-algorithmic-approach" id="ghosh---distributed-systems-an-algorithmic-approach">GHOSH - DISTRIBUTED SYSTEMS AN ALGORITHMIC APPROACH</a></h2>
<pre><code>    I background materials
        1 introduction
            1.1 what is a distributed system
            1.2 why distributed systems
            1.3 examples of distributed systems
            1.4 important issues in distributed systems
            1.5 common subproblems
            1.6 implementing a distributed system
            1.7 parallel versus distributed systems
        2 interprocess communication: an overview
            2.1 introduction
            2.2 network protocols
            2.3 naming
            2.4 remote procedure call
            2.5 remote method invocation
            2.6 messages
            2.7 web services
            2.8 event notification
            2.9 virtualization: cloud computing
            2.10 mobile agents
            2.11 basic group communication services
            2.12 concluding remarks
    II foundational topics
        3 models for communication
            3.1 need for a model
            3.2 message-passing model for interprocess communication
            3.3 shared variables
            3.4 modeling mobile agents
            3.5 relationship among models
            3.6 classification based on special properties
            3.7 complexity measures
            3.8 concluding remarks
        4 representing distributed algorithms: syntax and semantics
            4.1 introduction
            4.2 guarded actions
            4.3 nondeterminism
            4.4 atomic operations
            4.5 fairness
            4.6 central versus distributed schedulers
            4.7 concluding remarks
        5 program correctness
            5.1 introduction
            5.2 correctness criteria
            5.3 correctness proofs
            5.4 assertional reasoning: proving safety priorities
            5.5 proving liveness properties using well-founded sets
            5.6 programming logic
            5.7 predicate transformers
            5.8 concluding remarks
        6 time in a distributed system
            6.1 introduction
            6.2 logical clocks
            6.3 vector clocks
            6.4 physical clock synchronization
            6.5 concluding remarks
    III important paradigms
        7 mutual exclusion
            7.1 introduction
            7.2 solutions on message-passing systems
            7.3 token-passing algorithms
            7.4 solutions on the shared-memory model
            7.5 mutual exclusion using special instructions
            7.6 group mutual exclusion
            7.7 concluding remarks
        8 distributed snapshot
            8.1 introduction
            8.2 properties of consisten snapshots
            8.3 chandy-lamport algorithm
            8.4 lai-yang algorithm
            8.5 distributed debugging
            8.6 concluding remarks
        9 global state collection
            9.1 introduction
            9.2 elementary algorithm for all-to-all broadcasting
            9.3 termination-detection algorithms
            9.4 wave algorithms
            9.5 distributed deadlock detection
            9.6 concluding remarks
        10 graph algorithms
            10.1 introduction
            10.2 routing algorithms
            10.3 graph traversal
            10.4 graph coloring
            10.5 cole-vishkin reduction algorithm for tree coloring
            10.6 maximal independent set: luby's algorithm
            10.7 concluding remarks
        11 coordination algorithms
            11.1 introduction
            11.2 leader election
            11.3 synchronizers
            11.4 concluding remarks
    IV faults and fault-tolerant systems
        12 fault-tolerant systems
            12.1 introduction
            12.2 classification of faults
            12.3 specification of faults
            12.4 fault-tolerant systems
            12.5 tolerating crash failures
            12.6 tolerating omission failures
            12.7 concluding remarks
        13 distributed consensus
            13.1 introduction
            13.2 consensus in asynchronous systems
            13.3 consensus in synchronous systems: byzantine generals problem
            13.4 paxos algorithm
            13.5 failure detectors
            13.6 concluding remarks
        14 distributed transactions
            14.1 introduction
            14.2 classification of transactions
            14.3 implementing transactions
            14.4 concurrency control and serializability
            14.5 atomic commit protocols
            14.6 recovery from failures
            14.7 conclusing remarks
        15 group communication
            15.1 introduction
            15.2 atomic multicast
            15.3 ip multicast
            15.4 application layer multicast
            15.5 ordered multicasts
            15.6 reliable multicast
            15.7 open groups
            15.8 overview of transis
            15.9 concluding remarks
        16 replicated data management
            16.1 introduction
            16.2 architecture of replicated data management
            16.3 data-centric consistency tools
            16.4 client-centric consistency protocols
            16.5 implementation of data-centric consistency models
            16.6 quorum-based protcols
            16.7 replica placement
            16.8 brewer's cap theorem
            16.9 case studies
            16.10 concluding remarks
        17 self-stabilizing systems
            17.1 introduction
            17.2 theoretical foundation
            17.3 stabilizing mutual exclusion
            17.4 stabilizing graph coloring
            17.5 stabilizing spanning tree protocol
            17.6 stabilizing maximal matching
            17.7 distributed reset
            17.8 stabilizing clock phase synchronization
            17.9 concluding remarks
    V real-world issues
        18 distributed discrete-event simulation
            18.1 introduction
            18.2 distributed simulation
            18.3 conservative simulation
            18.4 optimistic simulation and time warp
            18.5 concluding remarks
        19 security in distributed systems
            19.1 introduction
            19.2 security mechanisms
            19.3 common security attacks
            19.4 encryption
            19.5 secret key cryptosystem
            19.6 public key cryptosystems
            19.7 digital signatures
            19.8 hashing algorithms
            19.9 elliptic curve cryptography
            19.10 authentication server
            19.11 digital certificates
            19.12 case studies
            19.13 virtual private networks  and firewalls
            19.14 sharing a secret
            19.15 concluding remarks
        20 sensor networks
            20.1 vision
            20.2 architecture of sensor nodes
            20.3 challenges in wireless sensor networks
            20.4 routing algorithms
            20.5 time synchronization using reference broadcast
            20.6 localization algorithms
            20.7 security in sensor networks
            20.8 applications
            20.9 concluding remarks
        21 social and peer-to-peer networks
            21.1 introduction to social networks
            21.2 metrics of social networks
            21.3 modeling socail networks
            21.4 centrality measures in social networks
            21.5 community detection
            21.6 introduction to peer-to-peer networks
            21.7 first-generation p2p systems
            21.8 second-generation p2p systems
            21.9 koorde and de bruijn graph
            21.10 skip graph
            21.11 replication management
            21.12 bittorrent and free riding
            21.13 censorship resistance, anonimity
            21.14 concluding remarks
</code></pre>
<h2><a class="header" href="#wan-fokkink---distributed-systems-an-intuitive-approach" id="wan-fokkink---distributed-systems-an-intuitive-approach">WAN FOKKINK - DISTRIBUTED SYSTEMS AN INTUITIVE APPROACH</a></h2>
<pre><code>    I message passing
        1 introduction
        2 preliminaries
        3 snapshots
        4 waves
        5 deadlock detection
        6 terminatino detection
        7 garbage collection
        8 routing
        9 election
        10 anonymous networks
        11 synchronous networks
        12 crash failures
        13 byzantine failures
        14 mutual exlusion
    II shared memory
        15 preliminaries
        16 mutual exclusion II
        17 barriers
        18 self-stabilization
        19 online scheduling
</code></pre>
<h2><a class="header" href="#notes-on-theory-of-distributed-systems" id="notes-on-theory-of-distributed-systems">NOTES ON THEORY OF DISTRIBUTED SYSTEMS</a></h2>
<pre><code>    I message passing
        1 introduction
        2 model
        3 coordinated attack
        4 broadcast and convergecast
        5 distributed breadth-first search
        6 leader election
        7 synchronous agreement
        8 byzantine agreement
        9 impossibility of asynchronous agreement
        10 paxos
        11 failure detectors
        12 logical clocks
        13 synchronizers
        14 quorum systems
    II shared memory
        15 model
        16 distributed shared memory
        17 mutual exclusion
        18 the wait-free hiararchy
        19 atomic snapshots
        20 lower bounds on perturbable objects
        21 restricted-use objects
        22 common2
        23 randomized consensus and test-and-set
        24 renaming
        25 software transactional memory
        26 obstruction-freedom
        27 BG simulation
        28 topological methods
        29 approximate agreement
</code></pre>
<h2><a class="header" href="#uns-sistemas-distribuidos" id="uns-sistemas-distribuidos">UNS SISTEMAS DISTRIBUIDOS</a></h2>
<pre><code>    PROGRAMA SINTETICO
        1) Introducción a los Sistemas Distribuidos.
        2) Comunicación en Sistemas Distribuidos.
        3) Sincronización en Sistemas Distribuidos.
        4) Planificación de Procesos en Sistemas Distribuidos.
        5) Consistencia, Replicación y Memoria Compartida Distribuida.
        6) Sistemas de Archivos en Sistemas Distribuidos.
        7) Transacciones Distribuidas.
        8) Sistema de Nombres.
        9) Tolerancia a las Fallas
        10) Seguridad en Sistemas Distribuidos.
        11) Sistemas Distribuidos Basados en Documentos

    PROGRAMA ANALITICO
        1.0 - Introducción a los Sistemas Distribuidos.
            1.1 Computación paralela y distribuida.
            1.2 Desventajas y limitaciones.
            1.3 Requerimientos de Hardware y Software.
        2.0 - Comunicación en Sistemas Distribuidos.
            2.1 Pasaje de mensajes
            2.2 Modelo Cliente-Servidor
            2.3 Llamadas a Procedimiento Remoto
            2.4 Grupos de Comunicación
        3.0 - Sincronización en Sistemas Distribuidos.
            3.1 Sincronización de Reloj
            3.2 Estado Global
            3.3 Exclusión Mutua
            3.4 Algoritmos de Elección
            3.5 Interbloqueos
        4.0 - Planificación de Procesos en Sistemas Distribuidos.
            4.1 Estrategias de Distribución de Carga.
            4.2 Migración de Procesos y Movilidad
        5.0 - Consistencia, Replicación y Memoria Compartida Distribuida.
            5.1 Modelos de Consistencia centrados en los datos
            5.2 Modelos de Consistencia centrados en el cliente
            5.3 Protocolos de distribución
            5.4 Protocolos de consistencia
            5.5 Memoria Compartida Distribuida
        6.0 - Sistemas de Archivos Distribuidos
            6.1 Propósito de uso
            6.2 Servicios
            6.3 Características deseables de los SAD
            6.4 Modelos de archivos y sus accesos
            6.5 Semánticas
            6.6 Esquemas de caché
            6.7 Tolerancia a las fallas
        7.0 - Transacciones Distribuidas
            7.1 Modelo Transaccional
            7.2 Protocolos de commit
        8.0 - Sistema de Nombres
            8.1 Nombres, Entidades
            8.2 Sistema de nombres y localización de objetos
            8.3 Remoción de Entidades no Referenciadas
        9.0 - Tolerancia a las Fallas
            9.1 Conceptos básicos
            9.2 Enmascaramiento
            9.3 Ordenamiento de mensajes
            9.4 Checkpointing
        10.0 - Seguridad en Sistemas Distribuidos
            10.1 Introducción
            10.2 Ataques
            10.3 Criptografía
            10.4 Autenticación
            10.5 Código móvil
        11.0 - Sistemas Distribuidos Basados en Documentos
            11.1 Caso: WWW
</code></pre>
<h2><a class="header" href="#distributed-systems-questions" id="distributed-systems-questions">DISTRIBUTED SYSTEMS QUESTIONS</a></h2>
<ol>
<li>explain the life of an http request.</li>
<li>what does the FLP result teach us?</li>
<li>what is a byzantine failure?</li>
<li>explain CRDTs</li>
<li>explain linearizability.</li>
<li>how does DNS work?</li>
<li>crash-stop vs crash-recovery?</li>
<li>difference between soft and hard real time</li>
<li>model GC in an eventually consistent system</li>
<li>discuss clock skew, NTP, and AWS vs metal</li>
<li>what is causal consistency?</li>
<li>whats the difference between a vector clock and a version vector?</li>
<li>what is chain replication?</li>
<li>at-most v at-least once</li>
<li>model RYOW in an EC system.</li>
<li>why does fail-stop rely on perfect fault detection?</li>
<li>how is this flawed?</li>
<li>how does 2PC fail?</li>
<li>how does 3PC fail?</li>
<li>why can Raft survive byzantine failures?</li>
<li>why CANT Raft survive byzantine failures?</li>
<li>how is 2PC different from fast-consensus?</li>
<li>what do merkel trees accomplish?</li>
<li>how do replicated logs work?</li>
<li>discuss an EC system that implement idempotent increments and decrements of counters</li>
<li>why are timeouts common in RPC?</li>
<li>push vs poll for stats and why?</li>
<li>advantages and limitations of the actor model?</li>
<li>what is process calculus?</li>
<li>what does termination, agreement, and validity guarantee in consensus protocols, respectfully?</li>
<li>which systems are best optimized for safety? 31) liveness?</li>
<li>what are the characteristic differences among the two?</li>
<li>why is WAN replication difficult?</li>
<li>which programming languages are best suited for building concurrent systems? why?</li>
<li>have you ever been to a RICON?</li>
<li>watched the videos?</li>
<li>what are 3 fundamental diffs between Cassandra and Riak?</li>
<li>how can you reduce tail latencies in distributed systems?</li>
<li>why do they matter?</li>
<li>explain set union vs set intersection</li>
<li>in your opinion why arent there any decent distributed time series databases on the market?</li>
<li>how can you break paxos?</li>
<li>why is a total order reflexive?</li>
<li>what are the fundamentals of atomic broadcast?</li>
<li>what does a POSET guarantee?</li>
<li>what is TCP incast?</li>
<li>compare and contrast Kafka, Storm, and Spark</li>
<li>are you familiar with LASP?</li>
<li>difficulties of programming concurrent systems in shared memory env?</li>
<li>(last one) do you even know how vector clocks work?</li>
</ol>
<h2><a class="header" href="#scaling-reliably" id="scaling-reliably">SCALING RELIABLY</a></h2>
<pre><code>    Improving the Scalability of the Erlang Distributed Actor Platform

    1 INTRODUCTION

        Controlling shared state is the only way to build reliable scalable systems. 
        State shared by multiple units of computation limits scalability due to high synchronisation and communication costs.
        Moreover, shared state is a threat for reliability as failures corrupting or permanently locking shared state may poison the entire system.

        To facilitate the development of scalable Erlang systems and make them maintainable, we have developed three new tools—Devo, SDMon, and WombatOAM—and enhanced two others—the visualisation tool Percept and the refactorer Wrangler.

    2 CONTEXT
        2.1 Scalable Reliable Programming Models
        2.2 Actor Languages
        2.3 Erlang’s Support for Concurrency
        2.4 Scalability and Reliability in Erlang Systems
        2.5 ETS: Erlang Term Storage
    3 BENCHMARKS FOR SCALABILITY AND RELIABILITY
        3.1 Orbit
        3.2 Ant Colony Optimisation (ACO)
    4 ERLANG SCALABILITY LIMITS
        4.1 Scaling Erlang on a Single Host
        4.2 Distributed Erlang Scalability
        4.3 Persistent Storage
    5 IMPROVING LANGUAGE SCALABILITY
        5.1 SD Erlang Design
        5.2 S_group Semantics
        5.3 Semantics Validation
    6 IMPROVING VM SCALABILITY
        6.1 Improvements to Erlang Term Storage
        6.2 Improvements to Schedulers
        6.3 Improvements to Time Management
    7 SCALABLE TOOLS
        7.1 Refactoring for Scalability
        7.2 Scalable Deployment
        7.3 Monitoring and Visualisation
    8 SYSTEMIC EVALUATION
        8.1 Orbit
        8.2 Ant Colony Optimisation (ACO)
        8.3 Evaluation Summary
    9 DISCUSSION
    APPENDIX: ARCHITECTURE SPECIFICATIONS
</code></pre>
<h1><a class="header" href="#excellency" id="excellency">Excellency</a></h1>
<h1><a class="header" href="#tools" id="tools">Tools</a></h1>
<h1><a class="header" href="#code-searching" id="code-searching">Code Searching</a></h1>
<h2><a class="header" href="#ag---the-silver-searcher" id="ag---the-silver-searcher">ag - the silver searcher</a></h2>
<p>You can limit the files it searches with <code>-G &lt;pattern&gt;</code></p>
<pre><code>ag -i -G '\.py$' 'string or RE I am looking for'
</code></pre>
<h2><a class="header" href="#grep" id="grep">GREP</a></h2>
<p>I'm pretty accustomed to using <code>find | xargs grep</code>.
This lets me completely tailor the file I search using find's filters (e.g., only search files with a <code>.py</code> extension, and skip <code>.svn/</code> directory). </p>
<p>E.g. assuming I'm in my project's root directory:</p>
<pre><code>find . -name .svn -prune -o -name '*.py' -print | xargs grep -Hi 'string or RE I am looking for'
</code></pre>
<pre><code>grep bar -A 5 -B 5 files... | grep foo
</code></pre>
<p><code>-A n</code> prints n lines following the match (bar) and <code>-B n</code> prints <code>n</code> lines before the match.</p>
<h2><a class="header" href="#ack" id="ack">Ack</a></h2>
<pre><code>ack --python PATTERN [DIRECTORY]
</code></pre>
<h2><a class="header" href="#git" id="git">Git</a></h2>
<p>If you use GIT, checkout also 'git grep' command.
Yes, more people need to know about &quot;git grep&quot;. Did you know you can do things like <code>git grep -e foo --and -e bar --and --not -e baz</code>? &quot;git grep&quot; is great.</p>
<h1><a class="header" href="#cli" id="cli">CLI</a></h1>
<h2><a class="header" href="#shell" id="shell">Shell</a></h2>
<ul>
<li>In bash, 'ctrl-r' searches your command history as you type</li>
</ul>
<ul>
<li>Add &quot;set -o vi&quot; in your ~/.bashrc to make use the vi keybindings instead
of the Emacs ones. Takes some time to get used to, but it's fantastic!</li>
<li>Input from the commandline as if it were a file by replacing
'command &lt; file.in' with 'command &lt;&lt;&lt; &quot;some input text&quot;'</li>
<li>'^' is a sed-like operator to replace chars from last command
'ls docs; ^docs^web^' is equal to 'ls web'. The second argument can be empty.</li>
</ul>
<ul>
<li>'!!:n' selects the nth argument of the last command, and '!$' the last arg
'ls file1 file2 file3; cat !!:1-2' shows all files and cats only 1 and 2</li>
</ul>
<ul>
<li>More in-line substitutions: http://tiny.cc/ecv0cw http://tiny.cc/8zbltw</li>
<li>'nohup ./long_script &amp;' to leave stuff in background even if you logout</li>
<li>'cd -' change to the previous directory you were working on</li>
<li>'ctrl-x ctrl-e' opens an editor to work with long or complex command lines</li>
</ul>
<ul>
<li>Use traps for cleaning up bash scripts on exit http://tiny.cc/traps</li>
<li>'shopt -s cdspell' automatically fixes your 'cd folder' spelling mistakes</li>
</ul>
<ul>
<li>'dict' is a commandline dictionary</li>
</ul>
<ul>
<li>'trash-cli' sends files to the trash instead of deleting them forever.
Be very careful with 'rm' or maybe make a wrapper to avoid deleting '<em>' by
accident (e.g. you want to type 'rm tmp</em>' but type 'rm tmp *')</li>
</ul>
<ul>
<li>'file' gives information about a file, as image dimensions or text encoding</li>
<li>'echo start_backup.sh | at midnight' starts a command at the specified time</li>
<li>Pipe any command over 'column -t' to nicely align the columns</li>
</ul>
<ul>
<li>Google 'magic sysrq' and learn how to bring you machine back from the dead</li>
</ul>
<ul>
<li>'diff --side-by-side fileA.txt fileB.txt | pager' to see a nice diff</li>
</ul>
<ul>
<li>'j.py' http://tiny.cc/62qjow remembers your most used folders and is an
incredible substitute to browse directories by name instead of 'cd'</li>
</ul>
<ul>
<li>'dropbox_uploader.sh' http://tiny.cc/o2qjow is a fantastic solution to
upload by commandline via Dropbox's API if you can't use the official client</li>
<li>learn to use 'pushd' to save time navigating folders (j.py is better though)</li>
<li>if you liked the 'psgrep' alias, check 'pgrep' as it is far more powerful</li>
</ul>
<ul>
<li>never run 'chmod o+x * -R', capitalize the X to avoid executable files. If
you want <em>only</em> executable folders: 'find . -type d -exec chmod g+x {} ;'</li>
</ul>
<ul>
<li>'xargs' gets its input from a pipe and runs some command for each argument</li>
</ul>
<h3><a class="header" href="#interesting-aliases" id="interesting-aliases">Interesting Aliases</a></h3>
<ul>
<li><code>function lt() { ls -ltrsa &quot;$@&quot; | tail; }</code></li>
<li><code>function psgrep() { ps axuf | grep -v grep | grep &quot;$@&quot; -i --color=auto; }</code></li>
<li><code>function fname() { find . -iname &quot;*$@*&quot;; }</code></li>
</ul>
<h3><a class="header" href="#redirecting-output-to-other-terminal" id="redirecting-output-to-other-terminal">Redirecting output to other terminal</a></h3>
<p>There are many reasons one might want to see output from shell commands in
another terminal emulator but it definitely has its uses. The other day it just
so happended that I needed such a functionality. Without going into details I’m
going to show you how to achieve such behaviour – and more – easily, by
leveraging the fact that under the hood <code>std(in|out|err)</code> are just *nix file
descriptors.</p>
<p>All that’s needed is the snippet below</p>
<pre><code>exec 1&gt;/proc/&lt;PID&gt;/fd/1
</code></pre>
<p>Where <code>&lt;PID&gt;</code> is id of the process you want to redirect your output to (and you
can obtain it for instance by running <code>echo $$</code> inside the target terminal).</p>
<p>But don’t take my word for it – let’s see for ourselves how it works.</p>
<pre><code>exec me
</code></pre>
<p>I think the biggest revelation comes with acknowledging the fact that exec is
used for something more than to (according to man): &quot;replace the shell with 
command without creating a new process&quot;</p>
<p>Because this functionality isn’t even the first thing mentioned in man. The
first thing man has to say about exec is that</p>
<pre><code>The exec utility shall open, close, and/or copy file descriptors as specified by
any redirections as part of the command.
</code></pre>
<p>And before you ask – yes, there’s a caveat. Unfortunately (or fortunately for
process security), once the process has started there’s no way to change its
file descriptors, unless you resort to some gdb wizardry – and even then it’s
not always possible.</p>
<p>Wrapping up – while it’s not really a game-changer, it’s still a feature that
can sometimes be put to good use.</p>
<h3><a class="header" href="#invoke-an-editor-to-write-a-long-complex-or-tricky-command" id="invoke-an-editor-to-write-a-long-complex-or-tricky-command">Invoke an editor to write a long, complex, or tricky command</a></h3>
<pre><code>$ ctrl-x e
</code></pre>
<p>Next time you are using your shell, try typing <code>ctrl-x e</code> (that is holding
control key press x and then e). The shell will take what you've written on
the command line thus far and paste it into the editor specified by <code>$EDITOR</code>.
Then you can edit at leisure using all the powerful macros and commands of
vi, emacs, nano, or whatever.</p>
<h3><a class="header" href="#list-of-commands-you-use-most-often" id="list-of-commands-you-use-most-often">List of commands you use most often</a></h3>
<pre><code>$ history | awk $({a[$2]++}END{for(i in a){print a[i] &quot; &quot; i}}) | sort -rn | head
</code></pre>
<h3><a class="header" href="#check-command-history-but-avoid-running-it" id="check-command-history-but-avoid-running-it">Check command history, but avoid running it</a></h3>
<pre><code>$ !whatever:p
</code></pre>
<p><code>!whatever</code> will search your command history and execute the first command
that matches 'whatever' If you don’t feel safe doing this put <code>:p</code> on the end
to print without executing. Recommended when running as superuser.</p>
<h3><a class="header" href="#run-the-last-command-as-root" id="run-the-last-command-as-root">Run the last command as root</a></h3>
<pre><code>$ sudo !!
</code></pre>
<p>Useful when you forget to use sudo for a command. <code>!!</code> grabs the last run command.
Similarly <code>!$</code> gets the last argument of the previous command
And <code>!&lt;#&gt;</code> repeats that line number from bash history, so:</p>
<pre><code>$ history
332   ls -l
$ !332
ls -l
</code></pre>
<p>Along the same line <code>$_</code>. Repeat the last argument.</p>
<pre><code>ping mybox.domain
ssh $_
</code></pre>
<p>You can also append it so something like:</p>
<pre><code>ping mybox.domain
scp file $_:
</code></pre>
<p>Meta period (<code>esc-.</code>) cycles the last argument from the previous commands.
It works on the current prompt.</p>
<h3><a class="header" href="#create-a-script-of-the-last-executed-command" id="create-a-script-of-the-last-executed-command">Create a script of the last executed command</a></h3>
<pre><code>$ echo &quot;!!&quot; &gt; foo.sh
</code></pre>
<p>Sometimes commands are long, but useful, so it's helpful to be able to make
them permanent without having to retype them.</p>
<h2><a class="header" href="#files" id="files">Files</a></h2>
<h3><a class="header" href="#like-top-but-for-files" id="like-top-but-for-files">Like top, but for files</a></h3>
<pre><code>$ watch -d -n 2 $(df; ls -FlAt;)
</code></pre>
<h3><a class="header" href="#empty-a-file" id="empty-a-file">Empty a file</a></h3>
<pre><code>$ &gt; file.txt
</code></pre>
<p>For when you want to flush all content from a file without removing it.</p>
<h3><a class="header" href="#zeroing-out-the-empty-space-and-making-deleted-information-non-recoverable" id="zeroing-out-the-empty-space-and-making-deleted-information-non-recoverable">Zeroing out the empty space and making deleted information non-recoverable</a></h3>
<pre><code>$ sudo su
$ touch junk.bin # Create a dummy file named junk.bin on the USB flash drive
$ fdisk -l and locate the partition you would like to zero out
$ mkdir /tmp/ddusb
$ mount -o loop /dev/sdxx /tmp/ddsdb (replacing sdxxx with your partition)
$ dd if=/dev/zero of=/tmp/ddusb/junk.bin
$ rm /tmp/ddusb/junk.bin
</code></pre>
<h3><a class="header" href="#copy-folder-structure-without-files" id="copy-folder-structure-without-files">Copy folder structure without files</a></h3>
<pre><code>$ cd /new/dir
$ (cd /old/dir; find -type d ! -name . -printf &quot;\&quot;%p\&quot;\n&quot;) | xargs mkdir
</code></pre>
<p><code>&quot;\&quot;%p\&quot;\n&quot;</code> Double quoted path names or else xargs and mkdir will fail.</p>
<h3><a class="header" href="#find-all-extensions-in-a-directory-tree" id="find-all-extensions-in-a-directory-tree">Find all extensions in a directory tree</a></h3>
<pre><code>$ find . -type f | awk -F . '{print $NF}' | tr '[:upper:]' '[:lower:]' | sort | uniq
</code></pre>
<h3><a class="header" href="#tail-a-file-with-less" id="tail-a-file-with-less">Tail a file with less</a></h3>
<pre><code>$ less +F somelogfile
</code></pre>
<p>Using <code>+F</code> will put less in follow mode. This works similar to <code>'tail -f'</code>
To stop scrolling, use the interrupt. Then you’ll get the normal benefits of
less (scroll, etc.).
Pressing <code>SHIFT-F</code> will resume the 'tailing'.</p>
<h2><a class="header" href="#text" id="text">Text</a></h2>
<h3><a class="header" href="#trim-trailing-whitespace-and-expand-tabs-to-spaces-in-a-tree" id="trim-trailing-whitespace-and-expand-tabs-to-spaces-in-a-tree">Trim trailing whitespace and expand tabs to spaces in a tree</a></h3>
<pre><code>$ find . -type f \( -name &quot;*.ex&quot; -o -name &quot;*.exs&quot; \) -exec bash -c 'echo &quot;$0&quot; &amp;&amp; sed -i &quot;&quot; -e &quot;s/[[:space:]]*$//&quot; &quot;$0&quot; &amp;&amp; expand -t 4 &quot;$0&quot; &gt; /tmp/e &amp;&amp; mv /tmp/e &quot;$0&quot;' {} \;
</code></pre>
<p>The command finds all erlang and elixir source files and expands tabs to 4
spaces and removes trailing whitespace.</p>
<ul>
<li><code>-type f \( -name &quot;*.erl&quot; -o -name &quot;*.ex&quot; -o -name &quot;*.exs&quot; \)</code> filters all
erlang and elixir source files. The escaped parentheses are necessary to
tell find that the <code>-name</code> filters are part of one condition, otherwise it
will short-circuit evaluate them.</li>
<li><code>-exec bash -c</code> tell find to run a bash command on each matching file.</li>
<li><code>echo &quot;$0&quot;</code> will print out the first parameter (i.e. the filename) passed
to the bash command.</li>
<li><code>sed -i &quot;&quot; -e &quot;s/[[:space:]]*$//&quot; &quot;$0&quot;</code> will run sed in-place on the file,
telling it to match all whitespace at the end of line and replace it with
nothing.</li>
<li><code>expand -t 4 &quot;$0&quot; &gt; /tmp/e &amp;&amp; mv /tmp/e &quot;$0&quot;</code> will run expand on the file,
since expand does not have an option to run it in-place we redirect output
to a temporary file and then copy it over the original file.</li>
</ul>
<h3><a class="header" href="#convert-between-dos--unix-textfile-formats" id="convert-between-dos--unix-textfile-formats">Convert between DOS / UNIX textfile formats</a></h3>
<pre><code>$ cp &lt;fileid&gt; &lt;fileid&gt;.dos &amp;&amp;
$ cat &lt;fileid&gt;.dos | tr -d '\r' &gt; &lt;fileid&gt;
</code></pre>
<h3><a class="header" href="#diff-two-unsorted-files-without-creating-temporary-files" id="diff-two-unsorted-files-without-creating-temporary-files">Diff two unsorted files without creating temporary files</a></h3>
<pre><code>$ diff &lt;(sort file1) &lt;(sort file2)
</code></pre>
<p>bash subshell redirection (as file descriptors) used as input to diff</p>
<h3><a class="header" href="#ascii-table" id="ascii-table">ASCII table</a></h3>
<pre><code>$ man ascii
</code></pre>
<h2><a class="header" href="#system" id="system">System</a></h2>
<h3><a class="header" href="#display-which-distro-is-installed" id="display-which-distro-is-installed">Display which distro is installed</a></h3>
<pre><code>cat /etc/issue
</code></pre>
<h3><a class="header" href="#currently-mounted-filesystems" id="currently-mounted-filesystems">Currently mounted filesystems</a></h3>
<pre><code>$ mount | column -t
</code></pre>
<p>Particularly useful if you're mounting different drives, using the following
command will allow you to see all the filesystems currently mounted on your
computer and their respective specs with the added benefit of nice
formatting.</p>
<h3><a class="header" href="#execute-a-command-at-a-given-time" id="execute-a-command-at-a-given-time">Execute a command at a given time</a></h3>
<pre><code>$ echo &quot;ls -l&quot; | at midnight
</code></pre>
<p>This is an alternative to cron which allows a one-off task to be scheduled
for a certain time.</p>
<h3><a class="header" href="#mount-a-temporary-ram-partition" id="mount-a-temporary-ram-partition">Mount a temporary ram partition</a></h3>
<pre><code>$ mount -t tmpfs tmpfs /mnt -o size=1024m
</code></pre>
<p>Makes a partition in ram which is useful if you need a temporary working
space as read/write access is fast. Be aware that anything saved in this
partition will be gone after your computer is turned off.</p>
<h2><a class="header" href="#memory" id="memory">Memory</a></h2>
<h3><a class="header" href="#see-all-strings-in-ram" id="see-all-strings-in-ram">See all strings in RAM</a></h3>
<pre><code>$ sudo dd if=/dev/mem | cat | strings
</code></pre>
<p>This command will show you all the string (plain text) values in ram.
A fun thing to do with ram is actually open it up and take a peek.</p>
<h3><a class="header" href="#display-the-top-ten-running-processes-sorted-by-memory-usage" id="display-the-top-ten-running-processes-sorted-by-memory-usage">Display the top ten running processes sorted by memory usage</a></h3>
<pre><code>ps aux | sort -nk +4 | tail
</code></pre>
<p><code>ps</code> returns all running processes which are then sorted by the 4th field in
numerical order and the top 10 are sent to STDOUT.</p>
<h2><a class="header" href="#networking" id="networking">Networking</a></h2>
<h3><a class="header" href="#set-audible-alarm-when-an-ip-address-comes-online" id="set-audible-alarm-when-an-ip-address-comes-online">Set audible alarm when an ip address comes online.</a></h3>
<pre><code>$ ping -i 60 -a IP_address
</code></pre>
<p>Waiting for your server to finish rebooting? Issue the command above and you will 
hear a beep when it comes online. The <code>-i 60</code> flag tells ping to wait for 60 
seconds between ping, putting less strain on your system. Vary it to your need. 
The <code>-a</code> flag tells ping to include an audible bell in the output when a package 
is received (that is, when your server comes online).</p>
<h3><a class="header" href="#serve-files-locally" id="serve-files-locally">Serve files locally</a></h3>
<p><code>python -m SimpleHTTPServer 8080</code> shares all the files in the current
folder over HTTP, port 8080</p>
<h3><a class="header" href="#port-forwarding" id="port-forwarding">Port forwarding</a></h3>
<pre><code>ssh -R 12345:localhost:22 server.com &quot;sleep 1000; exit&quot;
</code></pre>
<p>forwards server.com's port 12345 to your local ssh port, even if you machine is not externally visible on the net.
Now you can <code>ssh localhost -p 12345</code> from server.com and you will log into your machine.
'sleep' avoids getting kicked out from server.com for inactivity</p>
<h3><a class="header" href="#network-monitoring" id="network-monitoring">Network monitoring</a></h3>
<p>Some tools to monitor network connections and bandwith:</p>
<ul>
<li><code>lsof -i</code> monitors network connections in real time</li>
<li><code>iftop</code> shows bandwith usage per <em>connection</em></li>
<li><code>nethogs</code> shows the bandwith usage per <em>process</em></li>
</ul>
<h3><a class="header" href="#ssh-configuration" id="ssh-configuration">SSH configuration</a></h3>
<p>Use this trick on <code>.ssh/config</code> to directly access 'host2' which is on a private
network, and must be accessed by ssh-ing into 'host1' first</p>
<pre><code>  Host host2
      ProxyCommand ssh -T host1 'nc %h %p'
  	  HostName host2
</code></pre>
<h3><a class="header" href="#pipe-over-network" id="pipe-over-network">Pipe over network</a></h3>
<p>Pipe a compressed file over ssh to avoid creating large temporary .tgz files</p>
<pre><code>tar cz folder/ | ssh server &quot;tar xz&quot; 
</code></pre>
<p>DOCKER</p>
<p>computer running out of disk space?</p>
<pre><code>docker stop $(docker ps -a -q)
docker rm -f $(docker ps -a -q)
docker rmi -f $(docker images -q)
</code></pre>
<p>computer no longer running out of disk space.</p>
<p>DOCKER PS</p>
<pre><code>$ docker ps
list running containers
</code></pre>
<p>DOCKER IMAGES</p>
<pre><code>$ docker images
lists images
</code></pre>
<p>DOCKER RUN</p>
<pre><code>$ docker run -it --name &lt;NAME&gt; &lt;IMAGE NAME&gt; &lt;ARGS&gt;

    -i interactive
    -t terminal
    -v FULL_VOLUME_PATH

    -v ${PWD}/.:/home/test_directory

    copies everything in ./ on local to /home/test_directory in the container

    -p HOST_PORT:CONTAINER_PORT

    -p 1234:80
    maps port 1234 to port 80 inside the container

$ docker help run

Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]

Run a command in a new container

Options:
      --add-host list                  Add a custom host-to-IP mapping (host:ip)
  -a, --attach list                    Attach to STDIN, STDOUT or STDERR
      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)
      --blkio-weight-device list       Block IO weight (relative device weight) (default [])
      --cap-add list                   Add Linux capabilities
      --cap-drop list                  Drop Linux capabilities
      --cgroup-parent string           Optional parent cgroup for the container
      --cidfile string                 Write the container ID to the file
      --cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period
      --cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota
      --cpu-rt-period int              Limit CPU real-time period in microseconds
      --cpu-rt-runtime int             Limit CPU real-time runtime in microseconds
  -c, --cpu-shares int                 CPU shares (relative weight)
      --cpus decimal                   Number of CPUs
      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)
      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)
  -d, --detach                         Run container in background and print container ID
      --detach-keys string             Override the key sequence for detaching a container
      --device list                    Add a host device to the container
      --device-cgroup-rule list        Add a rule to the cgroup allowed devices list
      --device-read-bps list           Limit read rate (bytes per second) from a device (default [])
      --device-read-iops list          Limit read rate (IO per second) from a device (default [])
      --device-write-bps list          Limit write rate (bytes per second) to a device (default [])
      --device-write-iops list         Limit write rate (IO per second) to a device (default [])
      --disable-content-trust          Skip image verification (default true)
      --dns list                       Set custom DNS servers
      --dns-option list                Set DNS options
      --dns-search list                Set custom DNS search domains
      --entrypoint string              Overwrite the default ENTRYPOINT of the image
  -e, --env list                       Set environment variables
      --env-file list                  Read in a file of environment variables
      --expose list                    Expose a port or a range of ports
      --group-add list                 Add additional groups to join
      --health-cmd string              Command to run to check health
      --health-interval duration       Time between running the check (ms|s|m|h) (default 0s)
      --health-retries int             Consecutive failures needed to report unhealthy
      --health-start-period duration   Start period for the container to initialize before starting health-retries countdown (ms|s|m|h) (default 0s)
      --health-timeout duration        Maximum time to allow one check to run (ms|s|m|h) (default 0s)
      --help                           Print usage
  -h, --hostname string                Container host name
      --init                           Run an init inside the container that forwards signals and reaps processes
  -i, --interactive                    Keep STDIN open even if not attached
      --ip string                      IPv4 address (e.g., 172.30.100.104)
      --ip6 string                     IPv6 address (e.g., 2001:db8::33)
      --ipc string                     IPC mode to use
      --isolation string               Container isolation technology
      --kernel-memory bytes            Kernel memory limit
  -l, --label list                     Set meta data on a container
      --label-file list                Read in a line delimited file of labels
      --link list                      Add link to another container
      --link-local-ip list             Container IPv4/IPv6 link-local addresses
      --log-driver string              Logging driver for the container
      --log-opt list                   Log driver options
      --mac-address string             Container MAC address (e.g., 92:d0:c6:0a:29:33)
  -m, --memory bytes                   Memory limit
      --memory-reservation bytes       Memory soft limit
      --memory-swap bytes              Swap limit equal to memory plus swap: '-1' to enable unlimited swap
      --memory-swappiness int          Tune container memory swappiness (0 to 100) (default -1)
      --mount mount                    Attach a filesystem mount to the container
      --name string                    Assign a name to the container
      --network string                 Connect a container to a network (default &quot;default&quot;)
      --network-alias list             Add network-scoped alias for the container
      --no-healthcheck                 Disable any container-specified HEALTHCHECK
      --oom-kill-disable               Disable OOM Killer
      --oom-score-adj int              Tune host's OOM preferences (-1000 to 1000)
      --pid string                     PID namespace to use
      --pids-limit int                 Tune container pids limit (set -1 for unlimited)
      --platform string                Set platform if server is multi-platform capable
      --privileged                     Give extended privileges to this container
  -p, --publish list                   Publish a container's port(s) to the host
  -P, --publish-all                    Publish all exposed ports to random ports
      --read-only                      Mount the container's root filesystem as read only
      --restart string                 Restart policy to apply when a container exits (default &quot;no&quot;)
      --rm                             Automatically remove the container when it exits
      --runtime string                 Runtime to use for this container
      --security-opt list              Security Options
      --shm-size bytes                 Size of /dev/shm
      --sig-proxy                      Proxy received signals to the process (default true)
      --stop-signal string             Signal to stop a container (default &quot;SIGTERM&quot;)
      --stop-timeout int               Timeout (in seconds) to stop a container
      --storage-opt list               Storage driver options for the container
      --sysctl map                     Sysctl options (default map[])
      --tmpfs list                     Mount a tmpfs directory
  -t, --tty                            Allocate a pseudo-TTY
      --ulimit ulimit                  Ulimit options (default [])
  -u, --user string                    Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;])
      --userns string                  User namespace to use
      --uts string                     UTS namespace to use
  -v, --volume list                    Bind mount a volume
      --volume-driver string           Optional volume driver for the container
      --volumes-from list              Mount volumes from the specified container(s)
  -w, --workdir string                 Working directory inside the container
</code></pre>
<p>EXITING</p>
<pre><code>- close terminal, process and container will still run
- ctrl-p ctrl-q detaches the terminal from the container
- stop the process
</code></pre>
<p>DOCKER ATTACH</p>
<pre><code>$ docker attach &lt;CONTAINER NAME&gt;
</code></pre>
<p>DOCKER START</p>
<pre><code>$ docker ps -a
lists all containers, including those not running

if a container is not running (stopped) it can be
started with

$ docker start &lt;CONTAINER_NAME&gt;
</code></pre>
<p>DOCKER EXEC</p>
<pre><code>$ docker exec -it &lt;CONTAINER NAME&gt; &lt;COMMAND&gt;

runs another process inside a container
</code></pre>
<p>DOCKER STOP</p>
<pre><code>$ docker stop &lt;CONTAINER NAME&gt;
</code></pre>
<p>DOCKER RM</p>
<pre><code>$ docker rm &lt;CONTAINER NAME&gt;*

removes a container
</code></pre>
<p>DOCKER RMI</p>
<pre><code>removes docker images
</code></pre>
<p>DOCKER INSPECT</p>
<pre><code>$ docker inspect &lt;CONTAINER NAME&gt;

$ docker stats
$ docker system df
$ docker system events
$ docker system info
$ docker system prune
</code></pre>
<p>DOCKER-COMPOSE</p>
<pre><code>Define and run multi-container applications with Docker.

Usage:
  docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...]
  docker-compose -h|--help

Options:
  -f, --file FILE             Specify an alternate compose file
                              (default: docker-compose.yml)
  -p, --project-name NAME     Specify an alternate project name
                              (default: directory name)
  --verbose                   Show more output
  --log-level LEVEL           Set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  --no-ansi                   Do not print ANSI control characters
  -v, --version               Print version and exit
  -H, --host HOST             Daemon socket to connect to

  --tls                       Use TLS; implied by --tlsverify
  --tlscacert CA_PATH         Trust certs signed only by this CA
  --tlscert CLIENT_CERT_PATH  Path to TLS certificate file
  --tlskey TLS_KEY_PATH       Path to TLS key file
  --tlsverify                 Use TLS and verify the remote
  --skip-hostname-check       Don't check the daemon's hostname against the
                              name specified in the client certificate
  --project-directory PATH    Specify an alternate working directory
                              (default: the path of the Compose file)
  --compatibility             If set, Compose will attempt to convert deploy
                              keys in v3 files to their non-Swarm equivalent

Commands:
  build              Build or rebuild services
  bundle             Generate a Docker bundle from the Compose file
  config             Validate and view the Compose file
  create             Create services
  down               Stop and remove containers, networks, images, and volumes
  events             Receive real time events from containers
  exec               Execute a command in a running container
  help               Get help on a command
  images             List images
  kill               Kill containers
  logs               View output from containers
  pause              Pause services
  port               Print the public port for a port binding
  ps                 List containers
  pull               Pull service images
  push               Push service images
  restart            Restart services
  rm                 Remove stopped containers
  run                Run a one-off command
  scale              Set number of containers for a service
  start              Start services
  stop               Stop services
  top                Display the running processes
  unpause            Unpause services
  up                 Create and start containers
  version            Show the Docker-Compose version information
</code></pre>
<p>DOCKER LINKS</p>
<pre><code>- https://docs.docker.com/
- https://forums.docker.com/t/how-can-i-view-the-dockerfile-in-an-image/5687/3


- helloworld
    - https://hub.docker.com/_/hello-world
- postgres
    - https://github.com/docker-library/postgres
    - https://docs.docker.com/engine/examples/postgresql_service/
    - https://docs.docker.com/samples/library/postgres/
    - https://hub.docker.com/_/postgres
- luigi
    - https://hub.docker.com/r/pysysops/luigid
    - https://hub.docker.com/r/stockport/luigid
    - https://hub.docker.com/r/stockport/luigi-taskrunner
    - https://hub.docker.com/r/mada/luigid
    - https://hub.docker.com/r/spiside/luigi
    -

- redis
    - https://hub.docker.com/_/redis
- memcached
    - https://hub.docker.com/_/memcached
- cassandra
    - https://hub.docker.com/_/cassandra
- neo4j
    - https://hub.docker.com/_/neo4j
- arangodb
    - https://hub.docker.com/_/arangodb
- rethinkdb
    - https://hub.docker.com/_/rethinkdb
- orientdb
    - https://hub.docker.com/_/orientdb
- cratedb
    - https://hub.docker.com/_/crate
- rabbitmq
    - https://hub.docker.com/_/rabbitmq
- kafka
    - https://hub.docker.com/r/spotify/kafka
- elasticsearch
    - https://hub.docker.com/_/elasticsearch
- logstash
    - https://hub.docker.com/_/logstash
- kibana
    - https://hub.docker.com/_/kibana
- prometheus
    - https://hub.docker.com/r/prom/prometheus
- influxdb
    - https://hub.docker.com/_/influxdb
    - https://hub.docker.com/_/influxdata-influxdb
- telegraf
    - https://hub.docker.com/_/telegraf
- chronograf
    - https://hub.docker.com/_/chronograf
- fluentd
    - https://hub.docker.com/_/fluentd
- datadog agent
    - https://hub.docker.com/_/datadog-agent
- haproxy
    - https://hub.docker.com/_/haproxy
- jenkins
    - https://hub.docker.com/_/jenkins
- sonarqube
    - https://hub.docker.com/_/sonarqube
- erlang
    - https://hub.docker.com/_/erlang
- rust
    - https://hub.docker.com/_/rust

- misc
      - https://hub.docker.com/r/diyan/percona-toolkit/
      - https://hub.docker.com/r/diyan/redis-commander/

- docker compose
    - https://github.com/realpython/orchestrating-docker/blob/master/docker-compose.yml</code></pre>
<p># Elasticsearch</p>
<ul>
<li>concepts
<ul>
<li>documents</li>
<li>indexes</li>
<li>mappings</li>
</ul>
</li>
<li>features</li>
<li>administration</li>
<li>scaling</li>
<li>optimizing</li>
<li>caveats</li>
</ul>
<h2><a class="header" href="#elasticsearch-server" id="elasticsearch-server">Elasticsearch Server</a></h2>
<ul>
<li>1 Getting started with the elasticsearch cluster
<ul>
<li>Full-text searching</li>
<li>The basic of elasticsearch</li>
<li>Installing and configuring your cluster</li>
<li>Manipulating your data with the REST API</li>
</ul>
</li>
<li>2 Indexing your data
<ul>
<li>Elasticsearch indexing</li>
<li>Mappings configuration</li>
<li>Batch indexing to speed up your indexing process</li>
<li>Extending your index structure with additional internal information</li>
</ul>
</li>
<li>3 Searching your data
<ul>
<li>Querying elasticsearch</li>
<li>Understanding the query process</li>
<li>Basic queries</li>
<li>Compound queries</li>
<li>Filtering your results</li>
<li>Highlighting</li>
<li>Validating your queries</li>
<li>Sorting data</li>
<li>Query retwrite</li>
</ul>
</li>
<li>4 Extending your index structure
<ul>
<li>Indexing tree-like structures</li>
<li>Indexing data that is not flat</li>
<li>Using nested objects</li>
<li>Using the parent-child relationship</li>
<li>Modifying your index structure with the update api</li>
</ul>
</li>
<li>5 Make your search better
<ul>
<li>An introduction to Apache Lucene scoring</li>
<li>Scripting capabilities of Elasticsearch</li>
<li>Searching content in different languages</li>
<li>Influencing scores qith query boosts</li>
<li>When does index-time boosting make sense?</li>
<li>Words with the same meaning</li>
<li>Understanding the explain information</li>
</ul>
</li>
<li>6 Beyond full text searching
<ul>
<li>Aggregations</li>
<li>Faceting</li>
<li>Using suggesters</li>
<li>Percolator</li>
<li>Handling files</li>
<li>Geo</li>
<li>The scroll API</li>
<li>The terms filter</li>
</ul>
</li>
<li>7 Elasticsearch cluster in detail
<ul>
<li>Node discovery</li>
<li>The gateway and recovery modules</li>
<li>Preparing elasticsearch cluster for high query and indexing throughput</li>
<li>Templates and dynamic types</li>
</ul>
</li>
<li>8 Administrating your cluster
<ul>
<li>The elasticsearch time machine</li>
<li>Monitoring your cluster's state and health</li>
<li>Controlling cluster rebalancing</li>
<li>Controlling the shard and replica allocation</li>
<li>Warming up</li>
<li>Index aliasing and using it to simplify your everyday work</li>
<li>Elasticsearch plugins</li>
<li>The update setting API</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#elasticsearch-in-action" id="elasticsearch-in-action">Elasticsearch in Action</a></h2>
<ul>
<li>1 Introducing Elasticsearch
<ul>
<li>Solving search problesm</li>
<li>Exploring typical Elasticsearch use cases</li>
</ul>
</li>
<li>2 Diving into functionality
<ul>
<li>Understanding the logical layout: documents, types and indices</li>
<li>Understanding the physical layoutL: nodes and shards</li>
<li>Indexing new data</li>
<li>Searching and retrieving data</li>
<li>Configuring elasticsearch</li>
<li>Adding nodes to the cluster</li>
</ul>
</li>
<li>3 Indexing, updating and deleting data
<ul>
<li>Using mappings to define kinds of documents</li>
<li>Core types for defining your own fields in documents</li>
<li>Arrays and multi-fields</li>
<li>Using predefined fields</li>
<li>Updating predefined fields</li>
<li>Updating existing documents</li>
<li>Deleting data</li>
</ul>
</li>
<li>4 Searching your data
<ul>
<li>Structure of a search request</li>
<li>Introducing the query and filter DSL</li>
<li>Combining queries or compound queries</li>
<li>Beyond match and queries</li>
<li>Querying for field existence with filters</li>
</ul>
</li>
<li>5 Analyzing your data
<ul>
<li>What is analysis</li>
<li>Using analyzers for your documents</li>
<li>Analyzing text with the analyze API</li>
<li>Analyzers, tokenizers, and token filters, oh my!</li>
<li>Ngrams, edge ngrams, and shingles</li>
<li>Stemming</li>
</ul>
</li>
<li>6 Searching with relevancy
<ul>
<li>How scoring works in Elasticsearch</li>
<li>Other scoring methods</li>
<li>Boosting</li>
<li>Understanding how a document was scored with explain</li>
<li>Reducing scoring impact with query rescoring</li>
<li>Custom scoring with function_score</li>
<li>Tying it back together</li>
<li>Sorting with scripts</li>
<li>Field data detour</li>
</ul>
</li>
<li>7 Exploring your data with aggregations
<ul>
<li>Understanding the anatomy of an aggregation</li>
<li>Metrics aggregations</li>
<li>Multi-bucket aggregations</li>
<li>Nesting aggregrations</li>
</ul>
</li>
<li>8 Relations among documents
<ul>
<li>Overview of options for defining relationships among documents</li>
<li>Having objects as field values</li>
<li>Nested type: connecting nested documents</li>
<li>Parent-child relationships: connecting separate documents</li>
<li>Denormalizing: using redundant data connections</li>
<li>Application-side joins</li>
</ul>
</li>
<li>9 Scaling out
<ul>
<li>Addind nodes to your elasticsearch cluster</li>
<li>Discovering other Elasticsearch nodes</li>
<li>Removing nodes from a cluster</li>
<li>Upgrading Elasticsearch nodes</li>
<li>Using the _cat API</li>
<li>Scaling strategies</li>
<li>Aliases</li>
<li>Routing</li>
</ul>
</li>
<li>10 Improving performance
<ul>
<li>Grouping requests</li>
<li>Optimizing the handling of Lucene segments</li>
<li>Making the best use of caches</li>
<li>Other performance tradeoffs</li>
</ul>
</li>
<li>11 Administrating your cluster
<ul>
<li>Improving defaults</li>
<li>Allocation awareness</li>
<li>Monitoring for bottlenecks</li>
<li>Backing up your date</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#elasticsearch-cookbook" id="elasticsearch-cookbook">Elasticsearch Cookbook</a></h2>
<ul>
<li>1 Getting started
<ul>
<li>Introduction</li>
<li>Understanding nodes and clusters</li>
<li>Understanding node services</li>
<li>Managing your data</li>
<li>Understanding clusters, replication, sharding</li>
<li>Communication with Elasticsearch</li>
<li>Using the HTTP protocol</li>
<li>Using the native protocol</li>
<li>Using the thrift protocol</li>
</ul>
</li>
<li>2 Downloading and Setting Up
<ul>
<li>Introduction</li>
<li>Downloading and installing Elasticsearch</li>
<li>Setting up networking</li>
<li>Setting up a node</li>
<li>Setting up for linux systems</li>
<li>Setting up different node types</li>
<li>Installing plugins in Elasticsearch</li>
<li>Installing a plugin manually</li>
<li>Removing a plugin</li>
<li>Changing logging settings</li>
</ul>
</li>
<li>3 Managing mapping
<ul>
<li>Introduction</li>
<li>Using explicit mapping creation</li>
<li>Mapping base types</li>
<li>Mapping arrays</li>
<li>Mapping an object</li>
<li>Mapping a document</li>
<li>Using dynamic templates in document mapping</li>
<li>Managing nested objects</li>
<li>Managing a child document</li>
<li>Adding a field with multiple mappings</li>
<li>Mapping a geo point field</li>
<li>Mapping a geo shape field</li>
<li>Mapping an IP field</li>
<li>Mapping an attachment field</li>
<li>Adding metadata to a mapping</li>
<li>Specifying a different analyzer</li>
<li>Mapping a completion suggester</li>
</ul>
</li>
<li>4 Basic operations
<ul>
<li>Introduction</li>
<li>Creating an index</li>
<li>Deleting an index</li>
<li>Opening/closing an index</li>
<li>Putting a mapping in an index</li>
<li>Getting a mapping</li>
<li>Deleting a mapping</li>
<li>Refreshing an index</li>
<li>Flushing an index</li>
<li>Optimizing an index</li>
<li>Checking if an index or type exists</li>
<li>Managing index settings</li>
<li>Using index aliases</li>
<li>Indexing a document</li>
<li>Updating a document</li>
<li>Speeding up atomic operations</li>
<li>Speeding up GET operations</li>
</ul>
</li>
<li>5 Search, Queries, and Filters
<ul>
<li>Introduction</li>
<li>Executing a search</li>
<li>Sorting results</li>
<li>Highlighting results</li>
<li>Executing a scan query</li>
<li>Suggesting a correct query</li>
<li>Counting matched results</li>
<li>Deleting by query</li>
<li>Matching all the documents</li>
<li>Querying/filtering for a single term</li>
<li>Querying/filtering for multiple terms</li>
<li>Using a prefix query/filter</li>
<li>Using a boolean query/filter</li>
<li>Using a range query/filter</li>
<li>Using span queries</li>
<li>Using a match query</li>
<li>Using an ID query/filter</li>
<li>Using a has_child query/filter</li>
<li>Using a top_children query</li>
<li>Using a has_parent query/filter</li>
<li>Using a regexp query/filter</li>
<li>Using a function score query</li>
<li>Using exists and missing filters</li>
<li>Using and/or/not filters</li>
<li>Using a geo bounding box filter</li>
<li>Using a geo polygon filter</li>
<li>Using a geo distance filter</li>
<li>Using a querystring filter</li>
<li>Using a template query</li>
</ul>
</li>
<li>6 Aggregations
<ul>
<li>Introduction</li>
<li>Executing an aggregation</li>
<li>Executing a stats aggregation</li>
<li>Executing the terms aggregation</li>
<li>Executing the range aggregation</li>
<li>Executing the histogram aggregation</li>
<li>Execution the date histogram aggregation</li>
<li>Execution the filter aggregation</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#mastering-elasticsearch" id="mastering-elasticsearch">Mastering Elasticsearch</a></h2>
<ul>
<li>1 Introduction to Elasticsearch
<ul>
<li>Introducing Apache Lucene</li>
<li>Introducing Elasticsearch</li>
</ul>
</li>
<li>2 Power User Query DSL
<ul>
<li>Default Apache Lucene scorings explained</li>
<li>Query rewrite explained</li>
<li>Rescore</li>
<li>Bulk operations</li>
<li>Sorting data</li>
<li>Update API</li>
<li>Using filters to optimize your queries</li>
<li>Filters and scopes in Elasticsearch faceting mechanism</li>
</ul>
</li>
<li>3 Low-level index control
<ul>
<li>Altering apache lucene scoring</li>
<li>Similarity model configuration</li>
<li>Using codecs</li>
<li>NRT, flush, refresh, and transaction log</li>
<li>Looking deeper into data handling</li>
<li>Segment merging under control</li>
</ul>
</li>
<li>4 Index Distribution Architecture
<ul>
<li>Choosing the right amount of shards and replicas</li>
<li>Routing explained</li>
<li>Altering the default shard allocation behaviour</li>
<li>Adjusting shard allocation</li>
<li>Query execution performance</li>
<li>Using our knowledge</li>
</ul>
</li>
<li>5 Elasticsearch Administration
<ul>
<li>Choosing the right directory implementation - the store module</li>
<li>Discovery configuration</li>
<li>Segments statistics</li>
<li>Understaning Elasticsearch caching</li>
</ul>
</li>
<li>6 Fighting with fire
<ul>
<li>Knowing the garbage collector</li>
<li>When it is too much for I/O - throttling explained</li>
<li>Speeding up queries using warmers</li>
<li>Very hot threads</li>
<li>Real-life scenarios</li>
</ul>
</li>
<li>7 Improving the user search experience
<ul>
<li>Correcting user spelling mistakes</li>
<li>Improving search relevance</li>
</ul>
</li>
<li>8 Elasticsearch Java APIs
<ul>
<li>Introducing the Elasticsearch Java API</li>
<li>The code</li>
<li>Connecting to your cluster</li>
<li>Anatomy of the API</li>
<li>CRUD operations</li>
<li>Querying Elasticsearch</li>
<li>Performance multiple actions</li>
<li>Percolator</li>
<li>The explain API</li>
<li>Building JSON queries and documents</li>
<li>The administration API</li>
</ul>
</li>
<li>9 Developing Elasticsearch Plugins
<ul>
<li>Creating the Apache Maven project structure</li>
<li>Creating a custom river plugin</li>
<li>Creating custom analysis plugin</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#elasticsearch-the-definitive-guide" id="elasticsearch-the-definitive-guide">Elasticsearch the Definitive Guide</a></h2>
<ul>
<li>1 Getting started
<ul>
<li>You know, for search</li>
<li>Life inside a cluster</li>
<li>Data in, data out</li>
<li>Distributed document store</li>
<li>Searching - the basic tools</li>
<li>Mapping and analysis</li>
<li>Full-body search</li>
<li>Sorting and relevance</li>
<li>Distributed search execution</li>
<li>Index management</li>
<li>Inside a shard</li>
</ul>
</li>
<li>2 Search in depth
<ul>
<li>Structured search</li>
<li>Full-text search</li>
<li>Multifield search</li>
<li>Proximity matching</li>
<li>Partial matching</li>
<li>Controlling relevance</li>
</ul>
</li>
<li>3 Dealing with human language
<ul>
<li>Getting started with languages</li>
<li>Identifying words</li>
<li>Normalizing tokens</li>
<li>Reducing words to their root form</li>
<li>Stopwords: performance vs precision</li>
<li>Synonyms</li>
<li>Typoes and mispelings</li>
</ul>
</li>
<li>4 Aggregations
<ul>
<li>High-level concepts</li>
<li>Aggregation test drive</li>
<li>Building bar charts</li>
<li>Looking at time</li>
<li>Scoping aggregations</li>
<li>Filtering queries and aggregations</li>
<li>Sorting multivalue buckets</li>
<li>Approximate aggregations</li>
<li>Significant terms</li>
<li>Controlling memory use and latency</li>
</ul>
</li>
<li>5 Geolocation
<ul>
<li>Geo-points</li>
<li>Geohashes</li>
<li>Geo-aggregations</li>
<li>Geo-shapes</li>
</ul>
</li>
<li>6 Modeling your data
<ul>
<li>Handling relationships</li>
<li>Nested objects</li>
<li>Parent-child relationships</li>
<li>Designing for scale</li>
</ul>
</li>
<li>7 Administration, monitoring, deployment
<ul>
<li>Monitoring</li>
<li>Production deployment</li>
<li>Post-deployment</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#elasticsearch-indexing" id="elasticsearch-indexing">Elasticsearch Indexing</a></h2>
<ul>
<li>1 Introduction to efficient searching
<ul>
<li>Getting started</li>
<li>Understanding the document storage strategy</li>
<li>Analysis</li>
</ul>
</li>
<li>2 What is an elasticsearch index
<ul>
<li>Nature of elasticsearch index</li>
<li>Document</li>
</ul>
</li>
<li>3 Basic concepts of mapping
<ul>
<li>Basic concepts and definitions</li>
<li>Types</li>
<li>The relationship between mapping and relevant results</li>
<li>Understanding the schema-less</li>
</ul>
</li>
<li>4 Analysis and analyzers
<ul>
<li>Introducing analysis</li>
<li>Process of analysis</li>
<li>Built-in analyzers</li>
<li>What's text normalization?</li>
<li>ICU analysis plugin</li>
<li>An analyzer plugin</li>
<li>Specifying the analyzer for a field in the mapping</li>
</ul>
</li>
<li>5 Anatomy of an elasticsearch cluster
<ul>
<li>Basic concepts</li>
<li>Node</li>
<li>Shards</li>
<li>Replicas</li>
<li>Explaining the architecture of distribution</li>
<li>Correctly configuring the cluster</li>
<li>Choosing the right amount of shards and replicas</li>
</ul>
</li>
<li>6 Improving indexing performance
<ul>
<li>Configuration</li>
<li>Optimization of mapping definition</li>
<li>Segments and merging policies</li>
<li>Store modules</li>
<li>Bulk API</li>
<li>Notes</li>
</ul>
</li>
<li>7 Snapshot and restore
<ul>
<li>Snapshot repository</li>
<li>Snapshot</li>
<li>Restore</li>
<li>How does the snapshot process work?</li>
</ul>
</li>
<li>8 Improving the user search experience</li>
</ul>
<h2><a class="header" href="#elasticsearch-blueprints" id="elasticsearch-blueprints">Elasticsearch Blueprints</a></h2>
<ul>
<li>1 Google-like web search</li>
<li>2 Building your own e-commerce solutions</li>
<li>3 Relevancy and scoring</li>
<li>4 Managing relational content</li>
<li>5 Analytics using elasticsearch</li>
<li>6 Improving the search experience</li>
<li>7 Spicing up a search using geo</li>
<li>8 Handling time-based data</li>
</ul>
<h2><a class="header" href="#relevant-search-with-applications-for-solr-and-elasticsearch" id="relevant-search-with-applications-for-solr-and-elasticsearch">Relevant Search. With applications for Solr and Elasticsearch</a></h2>
<h2><a class="header" href="#learning-elk-stack" id="learning-elk-stack">Learning ELK Stack</a></h2>
<h2><a class="header" href="#commands" id="commands">Commands</a></h2>
<pre><code class="language-bash">docker pull docker.elastic.co/elasticsearch/elasticsearch:5.5.0
</code></pre>
<pre><code class="language-bash">docker run -p 9200:9200 -e &quot;http.host=0.0.0.0&quot; -e &quot;transport.host=127.0.0.1&quot; docker.elastic.co/elasticsearch/elasticsearch:5.5.0
</code></pre>
<pre><code class="language-bash">curl -u elastic http://127.0.0.1:9200/_cat/health
Enter host password for user 'elastic': changeme
</code></pre>
<pre><code class="language-bash">curl -XPUT -u elastic 'localhost:9200/_xpack/security/user/elastic/_password' -H &quot;Content-Type: application/json&quot; -d '{&quot;password&quot; : &quot;elasticpassword&quot;}'
</code></pre>
<h1><a class="header" href="#git-1" id="git-1">GIT</a></h1>
<pre><code>+---------+  +----------+ +--------+ +------+
|untracked|  |unmodified| |modified| |staged|
+----+----+  +----------+ +----+---+ +---+--+
     |             |edit       |         |
     |add          +-----------&gt;         |
     +-------------&gt;           |stage    |
     |             |           +---------&gt;
     |       remove|           |         |
     &lt;-------------+           |         |
     |             |           |   commit|
     |             &lt;---------------------+
     |             |           |         |
</code></pre>
<pre><code>initializing repo:
    `$ git init`

cloning existing repo:
    `$ git clone &lt;repo url&gt;`

files may be tracked -&gt; in last snapshot
                        {
                            * unmodified
                            * modified
                            * staged
                        }
             untracked -&gt; everything else

tracking new files:
    `$ git add &lt;filename&gt;`

staging modified files:
    `$ git add &lt;filename&gt;`

viewing changes:
    `$ git status`

compare working directory and staging area:
    `$ git diff`

compare staging area and last commit:
    `$ git diff --staged`
    `$ git diff --cached`

committing changes:
    `$ git commit`
    `$ git commit -m &quot;&lt;commit message&gt;`&quot;

skipping the staging area:
    `$ git commit -a`

removing files:
    `$ git rm &lt;filename&gt;`

remove file and keeo copy in working directory:
    `$ git rm --cached &lt;filename&gt;`

moving files:
    `$ git mv &lt;src&gt; &lt;dest&gt;`

viewing history:                `$ git log`
    show diffs:                 `$ git log -p`
    limit output to 2 entries:  `$ git log -2`
    stats for each commit:      `$ git log --stat`
                                `$ git log --pretty={short,full,fuller,oneline}`
    format fields:              `$ git log --graph`
        %H  commit hash
        %h  abbreviated commit hash
        %T  tree hash
        %t  abbreviated tree hash
        %P  parent hashes
        %p  abbreviated parent hashes
        %s  subject
        %an author name
        %ae author email
        %ad author date
        %ar author date, relative
        %cn committer name
        %ce committer email
        %cd committer date
        %cr committer date, relative

limiting log output:
    `-p`                show patch introduced with each commit
    `--stat`            show statistics for files modified in each commit
    `--shortstat`       display only the changed/insertions/deletions in each commit
    `--name-only`       show list of files modified after commit information
    `--name-status`     show list of files affected with A/M/D info
    `--abbrev-commit`   show only first few characters of SHA1
    `--relative-date`   display date in relative format instead of full date
    `--graph`           display ascii graph of the branch/merge history beside the log output
    `--pretty`          show commits in alternative format
    `-&lt;n&gt;`              show &lt;n&gt; last commits
    `--since`           limit commits to those made after a date
    `--after`           limit commits to those made after a date
    `--until`           limit commits to those made before a date
    `--before`          limit commits to those made before a date
    `--author`          show commits in which the author entry matches
    `--committer`
    `--grep`
    `-- &lt;path&gt;
</code></pre>
<h1><a class="header" href="#latex" id="latex">Latex</a></h1>
<h2><a class="header" href="#curso-falappa" id="curso-falappa">Curso Falappa</a></h2>
<h2><a class="header" href="#latex-a-document-preparation-system-2nd-ed" id="latex-a-document-preparation-system-2nd-ed">Latex. A document preparation system (2nd Ed)</a></h2>
<ul>
<li>1 Getting acquainted</li>
<li>2 Getting started</li>
<li>3 Carrying on</li>
<li>4 Moving information around</li>
<li>5 Other document classes</li>
<li>6 Designing it yourself</li>
<li>7 Pictures and colors</li>
<li>8 Errors</li>
<li>A Using MakeIndex</li>
<li>B The bibliography database</li>
<li>C Reference manual</li>
<li>D What's new</li>
<li>E Using plain Tex commands</li>
</ul>
<h2><a class="header" href="#the-not-so-short-introduction-to-latex-2e" id="the-not-so-short-introduction-to-latex-2e">The Not-so-short introduction to Latex 2e</a></h2>
<ul>
<li>1 Things you need to know</li>
<li>2 Typesetting text</li>
<li>3 Typesetting mathematical formulae</li>
<li>4 Specialties</li>
<li>5 Producting mathematical graphics</li>
<li>6 Customising Latex</li>
</ul>
<h2><a class="header" href="#wikibooks---latex" id="wikibooks---latex">Wikibooks - Latex</a></h2>
<ul>
<li>Getting started
<ol>
<li>Introduction</li>
<li>Installation</li>
<li>Installing Extra Packages</li>
<li>Basics</li>
</ol>
</li>
<li>Common Elements
<ol>
<li>Document Structure</li>
<li>Text Formatting</li>
<li>Paragraph Formatting</li>
<li>Colors</li>
<li>Fonts</li>
<li>List Structures</li>
<li>Special Characters</li>
<li>Internationalization</li>
<li>Rotations</li>
<li>Tables</li>
<li>Title Creation</li>
<li>Page Layout</li>
<li>Importing Graphics</li>
<li>Floats, Figures and Captions</li>
<li>Hyperlinks</li>
<li>Labels and Cross-referencing</li>
</ol>
</li>
<li>Mechanics
<ol>
<li>Errors and Warnings</li>
<li>Lengths</li>
<li>Counters</li>
<li>Boxes</li>
<li>Rules and Struts</li>
</ol>
</li>
<li>Technical Texts
<ol>
<li>Mathematics</li>
<li>Advanved Mathematics</li>
<li>Theorems</li>
<li>Chemical Graphics</li>
<li>Algorithms</li>
<li>Source Code Listings</li>
<li>Linguistics</li>
<li>References</li>
<li>External Links</li>
</ol>
</li>
<li>Special Pages
<ol>
<li>Indexing</li>
<li>More Bibliographies</li>
</ol>
</li>
<li>Special Documents
<ol>
<li>Letters</li>
<li>Presentations</li>
<li>Teacher's Corner</li>
<li>Curriculum Vitae</li>
</ol>
</li>
<li>Creating Graphics
<ol>
<li>Introducing Procedural Graphics</li>
<li>MetaPost</li>
<li>Picture</li>
<li>PGF/TikZ</li>
<li>PSTricks</li>
<li>Xy-Pic</li>
<li>Creating 3D Graphics</li>
</ol>
</li>
<li>Programming
<ol>
<li>Macros</li>
<li>Plain Tex</li>
<li>Creating Packages</li>
<li>Themes</li>
</ol>
</li>
<li>Miscellaneous
<ol>
<li>Modular Documents</li>
<li>Collaborative Writing of Latex Documents</li>
<li>Export to Other Formats</li>
</ol>
</li>
<li>Help and Recommendations
<ol>
<li>FAQ</li>
<li>Tips and Tricks</li>
</ol>
</li>
<li>Appendices
<ol>
<li>Authors</li>
<li>Links</li>
<li>Sample Latex Documents</li>
<li>Index</li>
</ol>
</li>
</ul>
<h2><a class="header" href="#math-into-latex" id="math-into-latex">Math into Latex</a></h2>
<ul>
<li>I A short course
<ul>
<li>1 Typing your first article</li>
</ul>
</li>
<li>II Text and math
<ul>
<li>2 Typing text</li>
<li>3 Text environments</li>
<li>4 Typing math</li>
<li>5 Multiline math displays</li>
</ul>
</li>
<li>III Document structure
<ul>
<li>6 Latex documents</li>
<li>7 Standard Latex document classes</li>
<li>8 AMS-Latex documents</li>
</ul>
</li>
<li>IV Customizing
<ul>
<li>9 Customizing Latex</li>
</ul>
</li>
<li>V Long bibligraphies and indexes
<ul>
<li>10 BibTex</li>
<li>11 MakeIndex</li>
</ul>
</li>
<li>VI Appendices
<ul>
<li>A Math symbol tables</li>
<li>B Text symbol tables</li>
<li>C The AMS-Latex sample article</li>
<li>D Sample article with user-defined commands</li>
<li>E Background</li>
<li>F Postscript fonts</li>
<li>G Getting it</li>
<li>H Conversions</li>
<li>I Final word</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#the-latex-graphics-companion" id="the-latex-graphics-companion">The Latex graphics companion</a></h2>
<ul>
<li>1 Graphics with Latex</li>
<li>2 The Latex 2e graphics bundle</li>
<li>3 Working with METAFONT and METAPOST</li>
<li>4 Harnessing PostScript inside Latex: the pstricks package</li>
<li>5 The Xy-pic package</li>
<li>6 Applications in chemistry, physics and engineering</li>
<li>7 Preparing music schores</li>
<li>8 Playing games</li>
<li>9 The world of color</li>
<li>10 Using postscript fonts</li>
<li>11 PostScript drivers and tools</li>
</ul>
<h2><a class="header" href="#using-imported-graphics-in-latex" id="using-imported-graphics-in-latex">Using imported graphics in Latex</a></h2>
<ul>
<li>I Background information
<ul>
<li>1 Introduction</li>
<li>2 Latex terminology</li>
<li>3 Encapsulated postscript</li>
<li>4 How eps files are used by latex</li>
<li>5 PDF graphics</li>
<li>6 Graphics software</li>
</ul>
</li>
<li>II The Latex graphics bundle
<ul>
<li>7 Graphics inclusion</li>
<li>8 Rotating and scaling objects</li>
<li>9 Advanced graphics-inclusion commands</li>
</ul>
</li>
<li>III Using graphics-inclusion commands
<ul>
<li>10 Horizontal spacing and centering</li>
<li>11 Rotation, scaling, alignment</li>
<li>12 Overlaying two imported graphics</li>
<li>13 Using subdirectories</li>
<li>14 Compressed and non-EPS graphics files in dvips</li>
<li>15 The psfrag package</li>
<li>16 Including an eps file multiple times</li>
</ul>
</li>
<li>IV The figure environment
<ul>
<li>17 The figure environment</li>
<li>18 Customizing float placement</li>
<li>19 Customizing the figure environment</li>
<li>20 Customizing captions with the caption package</li>
<li>21 Non-floating figures</li>
<li>22 Marginal figures</li>
<li>23 Wide figures</li>
<li>24 Landscape figures</li>
<li>25 Captions beside figures</li>
<li>26 Figures on odd or even pages</li>
<li>27 Boxed figures</li>
</ul>
</li>
<li>V Complex figures
<ul>
<li>28 Side-by-side graphics</li>
<li>29 Separate minipages for captions</li>
<li>30 Placing a table beside a figure</li>
<li>31 Stacked figures and subfigures</li>
<li>32 The subfic package</li>
<li>33 Continued figures and subfigures</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#the-texbook" id="the-texbook">The TexBook</a></h2>
<ul>
<li>1 The name of the fame</li>
<li>2 Book printing versus ordinary typing</li>
<li>3 Controlling Tex</li>
<li>4 Fonts of type</li>
<li>5 Grouping</li>
<li>6 Running Tex</li>
<li>7 How Tex reads what you type</li>
<li>8 The characters you type</li>
<li>9 Tex's roman fonts</li>
<li>10 Dimensions</li>
<li>11 Boxes</li>
<li>12 Glue</li>
<li>13 Modes</li>
<li>14 How Tex breaks paragraphs into lines</li>
<li>15 How Tex makes lines into pages</li>
<li>16 Typing math formulae</li>
<li>17 More about math</li>
<li>18 Fine points of mathematics typing</li>
<li>19 Displayed equations</li>
<li>20 Definitions (also called macros)</li>
<li>21 Making boxes</li>
<li>22 Alignment</li>
<li>23 Output routines</li>
<li>24 Summary of vertical mode</li>
<li>25 Summary of horizontal mode</li>
<li>26 Summary of math mode</li>
<li>27 Recovery from errors</li>
</ul>
<h2><a class="header" href="#the-metafont-book" id="the-metafont-book">The METAFONT book</a></h2>
<h2><a class="header" href="#learning-metapost-by-doing" id="learning-metapost-by-doing">Learning METAPOST by doing</a></h2>
<ul>
<li>1 Introduction</li>
<li>2 A simple example</li>
<li>3 Basic graphical primitives</li>
<li>4 Style directives</li>
<li>5 Transformations</li>
<li>6 Advanced graphics</li>
<li>7 Control structures</li>
<li>8 Macros</li>
<li>9 More examples</li>
<li>10 Solutions to exercises</li>
<li>11 Appendix</li>
</ul>
<h1><a class="header" href="#rsync" id="rsync">RSync</a></h1>
<p>rsync's speciality lies in its ability to analyse files and only copy the changes made to files rather than all files. This can lead to enormous improvements when copying a directory tree a second time.</p>
<pre><code>rsync [options] source destination
</code></pre>
<pre><code>rsync -a /home/user/dir/ /media/disk/dir/
</code></pre>
<pre><code>rsync -e ssh [-avz] /some/file [ more ... ] host.name:/destination/file
</code></pre>
<pre><code>rsync -ave ssh source.server:/path/to/source /destination/dir
</code></pre>
<h5><a class="header" href="#trailing-slashes" id="trailing-slashes">Trailing slashes</a></h5>
<ul>
<li>
<p><code>/home/user/dir</code>: without the trailing slash, it will copy the directory contents in its entirety</p>
</li>
<li>
<p><code>/home/user/dir/</code>: with the trailing slash, will copy the contents of the directory but won't recreate the directory</p>
</li>
</ul>
<p>If you're trying to replicate a directory structure with rsync, you should omit the trailing slash, for instance, if you're mirroring /var/www on another machine or something like that.</p>
<h5><a class="header" href="#switches" id="switches">Switches</a></h5>
<p><code>-a</code> Archive mode, most likely you should always keep this on. Preserves file permissions and does not follow symlinks.</p>
<p><code>-z</code> Enable compression, this will compress each file as it gets sent over the pipe. This can greatly decrease time depending on what sort files you are copying.</p>
<p><code>-e</code> ssh Uses ssh as the transport, this should always be specified.</p>
<pre><code>-v, --verbose               increase verbosity, lists files being copied
-q, --quiet                 suppress non-error messages
    --no-motd               suppress daemon-mode MOTD (see caveat)
-c, --checksum              skip based on checksum, not mod-time &amp; size
-a, --archive               archive mode; same as -rlptgoD (no -H)
    --no-OPTION             turn off an implied OPTION (e.g. --no-D)
-r, --recursive             recurse into directories
-R, --relative              use relative path names
    --no-implied-dirs       don't send implied dirs with --relative
-b, --backup                make backups (see --suffix &amp; --backup-dir)
    --backup-dir=DIR        make backups into hierarchy based in DIR
    --suffix=SUFFIX         backup suffix (default ~ w/o --backup-dir)
-u, --update                skip files that are newer on the receiver
    --inplace               update destination files in-place
    --append                append data onto shorter files
-d, --dirs                  transfer directories without recursing
-l, --links                 copy symlinks as symlinks
-L, --copy-links            transform symlink into referent file/dir
    --copy-unsafe-links     only &quot;unsafe&quot; symlinks are transformed
    --safe-links            ignore symlinks that point outside the tree
-k, --copy-dirlinks         transform symlink to dir into referent dir
-K, --keep-dirlinks         treat symlinked dir on receiver as dir
-H, --hard-links            preserve hard links
-p, --perms                 preserve permissions
    --executability         preserve executability
    --chmod=CHMOD           affect file and/or directory permissions
-o, --owner                 preserve owner (super-user only)
-g, --group                 preserve group
    --devices               preserve device files (super-user only)
    --specials              preserve special files
-D                          same as --devices --specials
-t, --times                 preserve times
-O, --omit-dir-times        omit directories when preserving times
    --super                 receiver attempts super-user activities
-S, --sparse                handle sparse files efficiently
-n, --dry-run               show what would have been transferred
-W, --whole-file            copy files whole (without rsync algorithm)
-x, --one-file-system       don't cross filesystem boundaries
-B, --block-size=SIZE       force a fixed checksum block-size
-e, --rsh=COMMAND           specify the remote shell to use
    --rsync-path=PROGRAM    specify the rsync to run on remote machine
    --existing              skip creating new files on receiver
    --ignore-existing       skip updating files that exist on receiver
    --remove-source-files   sender removes synchronized files (non-dir)
    --del                   an alias for --delete-during
    --delete                delete extraneous files from dest dirs
    --delete-before         receiver deletes before transfer (default)
    --delete-during         receiver deletes during xfer, not before
    --delete-after          receiver deletes after transfer, not before
    --delete-excluded       also delete excluded files from dest dirs
    --ignore-errors         delete even if there are I/O errors
    --force                 force deletion of dirs even if not empty
    --max-delete=NUM        don't delete more than NUM files
    --max-size=SIZE         don't transfer any file larger than SIZE
    --min-size=SIZE         don't transfer any file smaller than SIZE
    --partial               keep partially transferred files
    --partial-dir=DIR       put a partially transferred file into DIR
    --delay-updates         put all updated files into place at end
-m, --prune-empty-dirs      prune empty directory chains from file-list
    --numeric-ids           don't map uid/gid values by user/group name
    --timeout=TIME          set I/O timeout in seconds
-I, --ignore-times          don't skip files that match size and time
    --size-only             skip files that match in size
    --modify-window=NUM     compare mod-times with reduced accuracy
-T, --temp-dir=DIR          create temporary files in directory DIR
-y, --fuzzy                 find similar file for basis if no dest file
    --compare-dest=DIR      also compare received files relative to DIR
    --copy-dest=DIR         ... and include copies of unchanged files
    --link-dest=DIR         hardlink to files in DIR when unchanged
-z, --compress              compress file data during the transfer
    --compress-level=NUM    explicitly set compression level
-C, --cvs-exclude           auto-ignore files in the same way CVS does
-f, --filter=RULE           add a file-filtering RULE
-F                          same as --filter='dir-merge /.rsync-filter'
                            repeated: --filter='- .rsync-filter'
    --exclude=PATTERN       exclude files matching PATTERN
    --exclude-from=FILE     read exclude patterns from FILE
    --include=PATTERN       don't exclude files matching PATTERN
    --include-from=FILE     read include patterns from FILE
    --files-from=FILE       read list of source-file names from FILE
-0, --from0                 all *from/filter files are delimited by 0s
    --address=ADDRESS       bind address for outgoing socket to daemon
    --port=PORT             specify double-colon alternate port number
    --sockopts=OPTIONS      specify custom TCP options
    --blocking-io           use blocking I/O for the remote shell
    --stats                 give some file-transfer stats
-8, --8-bit-output          leave high-bit chars unescaped in output
-h, --human-readable        output numbers in a human-readable format
    --progress              show progress during transfer
-P                          same as --partial --progress
-i, --itemize-changes       output a change-summary for all updates
    --out-format=FORMAT     output updates using the specified FORMAT
    --log-file=FILE         log what we're doing to the specified FILE
    --log-file-format=FMT   log updates using the specified FMT
    --password-file=FILE    read password from FILE
    --list-only             list the files instead of copying them
    --bwlimit=KBPS          limit I/O bandwidth; KBytes per second
    --write-batch=FILE      write a batched update to FILE
    --only-write-batch=FILE like --write-batch but w/o updating dest
    --read-batch=FILE       read a batched update from FILE
    --protocol=NUM          force an older protocol version to be used
    --checksum-seed=NUM     set block/file checksum seed (advanced)
-4, --ipv4                  prefer IPv4
-6, --ipv6                  prefer IPv6
-E, --extended-attributes   copy extended attributes, resource forks
    --cache                 disable fcntl(F_NOCACHE)
    --version               print version number
(-h) --help                  show this help (see below for -h comment)
</code></pre>
<h5><a class="header" href="#hidden-files" id="hidden-files">Hidden files</a></h5>
<p>rsync will move hidden files without any special options.</p>
<p>If you want to exclude hidden files, you can use the option <code>--exclude=&quot;.*/&quot;</code>
You can also use the <code>--exclude</code> option to prevent copying things like Vim's swap files (<code>.swp</code>) and automatic backups (<code>.bak</code>) created by some programs.</p>
<h5><a class="header" href="#delete-files" id="delete-files">Delete files</a></h5>
<p>If you want to make sure that local files you've deleted since the last time you ran rsync are deleted from the external system as well, you'll want to add the <code>--deleted</code> option, like so:</p>
<pre><code>rsync -avh --delete /home/user/dir/ /media/disk/backup
</code></pre>
<h5><a class="header" href="#dry-runs" id="dry-runs">Dry runs</a></h5>
<p>While you're getting used to rsync, it's probably a good idea to use the --dry-run option with your commands to run through the transfer first, without actually copying or synching files.</p>
<p>##### Commands</p>
<p><em>Backup master to monolith</em></p>
<pre><code>rsync
    --verbose
    --recursive
    --human-readable
    --progress
    --exclude='.DS_Store'
    --exclude='\._*'
    /mnt/DATA1/Backup-2020-06/FOLDER/
    /home/igaray/usb/igarai@gmail.com/FOLDER/
</code></pre>
<h1><a class="header" href="#suckless" id="suckless">SUCKLESS</a></h1>
<h2><a class="header" href="#shell-1" id="shell-1">Shell</a></h2>
<ul>
<li>zsh</li>
<li>tmux</li>
<li>htop</li>
<li>glances</li>
</ul>
<h2><a class="header" href="#file-management" id="file-management">File management</a></h2>
<ul>
<li>mc</li>
<li>ranger</li>
<li>nnn</li>
<li>tmsu</li>
<li>fdupes</li>
<li>ncdu</li>
<li>name-pryer</li>
<li>rsync</li>
</ul>
<h2><a class="header" href="#editing" id="editing">Editing</a></h2>
<ul>
<li>vim</li>
<li>neovim</li>
<li>emacs</li>
<li>kak</li>
<li>sed</li>
<li>awk</li>
</ul>
<h2><a class="header" href="#coding" id="coding">Coding</a></h2>
<ul>
<li>jrnl</li>
<li>cloc</li>
<li>git</li>
<li>tig</li>
<li>jsonpp</li>
<li>jq</li>
<li>grep</li>
<li>ack</li>
<li>ag</li>
<li>ripgrep</li>
<li>gdb</li>
<li>rr</li>
<li>valgrind</li>
</ul>
<h2><a class="header" href="#desktop" id="desktop">Desktop</a></h2>
<ul>
<li>dwm</li>
<li>i3</li>
<li>bspwm</li>
<li>awesome</li>
</ul>
<h2><a class="header" href="#task-management" id="task-management">Task management</a></h2>
<ul>
<li>taskwarrior</li>
<li>timewarrior</li>
<li>vit</li>
<li>tasksh</li>
</ul>
<h2><a class="header" href="#music" id="music">Music</a></h2>
<ul>
<li>mpd</li>
<li>ncmpcpp</li>
</ul>
<h2><a class="header" href="#internet" id="internet">Internet</a></h2>
<ul>
<li>mosh</li>
<li>weechat</li>
<li>rtv</li>
</ul>
<h1><a class="header" href="#binutils--coreutils" id="binutils--coreutils">Binutils &amp; Coreutils</a></h1>
<h2><a class="header" href="#file-utilities" id="file-utilities">File utilities</a></h2>
<ul>
<li>chcon                       change file security context</li>
<li>chgrp                       change file group ownership</li>
<li>chown                       change file ownership</li>
<li>chmod                       change file permissions of a file or a directory</li>
<li>cp                          copy a file or directory</li>
<li>dd                          copy or convert a file</li>
<li>df                          show disk free space on filesystems</li>
<li>dir                         $(ls -C -b)</li>
<li>dircolors                   setup color for ls</li>
<li>install                     copies files and sets attributes</li>
<li>ln                          creates a link to a file</li>
<li>ls                          lists files in a directory</li>
<li>mkdir                       creates a directory</li>
<li>mkfifo                      makes named pipes</li>
<li>mknod                       makes block or character special files</li>
<li>mv                          moves or renames files</li>
<li>rm                          removes (deletes) files</li>
<li>rmdir                       removes empty directories</li>
<li>shred                       overwrites a file to hide its contents</li>
<li>sync                        flushes file system buffers</li>
<li>touch                       changes file timestamps</li>
<li>truncate                    shrink or extend the size of a file</li>
<li>vdir                        $(ls -l -b)</li>
</ul>
<h2><a class="header" href="#text-utilities" id="text-utilities">Text utilities</a></h2>
<ul>
<li>base64                      base64 encode/decode data and print to stdout</li>
<li>cat                         concatenate and print file to stdout</li>
<li>cksum                       checksums and counts the bytes in a file</li>
<li>comm                        compares two sorted files line by line</li>
<li>csplit                      splits a file into sections determined by context lines</li>
<li>cut                         removes sections from each line of files</li>
<li>expand                      converts tabs to spaces</li>
<li>fmt                         simple optimal text formatter</li>
<li>fold                        wraps each input line to fit in specified width</li>
<li>head                        outputs the first part of files</li>
<li>join                        joins lines fo two files on a common field</li>
<li>md5sum                      computes and checks md5 message digest</li>
<li>nl                          numbers lines of files</li>
<li>od                          dumps files in octal and other formats</li>
<li>paste                       merged lines of files</li>
<li>ptx                         produces a permutated index of file contents</li>
<li>pr                          converts text files for printing</li>
<li>sha{1,224,256,384,512}sum   computes and checks SHA message digest</li>
<li>shuf                        generate random permutations</li>
<li>sort                        sort lines of text files</li>
<li>split                       split a file into pieces</li>
<li>sum                         checksums and counts the blocks in a file</li>
<li>tac                         concatenates and prints in reverse</li>
<li>tail                        outputs the last part of files</li>
<li>tr                          translates or deletes characters</li>
<li>tsort                       performs a topological sort</li>
<li>unexpand                    converts spaces to tabs</li>
<li>uniq                        removes duplicate lines from a file</li>
<li>wc                          prints the number of bytes, words and lines in a file</li>
</ul>
<h2><a class="header" href="#shell-utilities" id="shell-utilities">Shell utilities</a></h2>
<ul>
<li>arch                        $(uname -m)</li>
<li>basename                    removes path prefix from filename</li>
<li>chroot                      changes the root directory</li>
<li>date                        prints/sets the system date and time</li>
<li>dirname                     strips non-directory suffic from filename</li>
<li>du                          shows disk usage on filesystems</li>
<li>echo                        displays displays specified line of text</li>
<li>env                         displays and modifies environment variables</li>
<li>expr                        evaluates expressions</li>
<li>factor                      factors numbers</li>
<li>false                       exits unsuccesfully</li>
<li>groups                      prints groups of which the user is a member</li>
<li>hostid                      prints numeric id of current host</li>
<li>id                          print effective uid/gid</li>
<li>link                        create link to file</li>
<li>logname                     print users login name</li>
<li>nice                        modify scheduling priority</li>
<li>nohup                       allow command to conitnue after loggin out</li>
<li>pathchk                     checks whether filenames are valid or portable</li>
<li>pinky                       lightweight version of finger</li>
<li>printenv                    prints environment variables</li>
<li>printf                      prints and formats data</li>
<li>pwd                         prints working directory</li>
<li>readlink                    displays value of symbolic link</li>
<li>runcon                      run command with specified security context</li>
<li>seq                         prints a sequence of numbers</li>
<li>sleep                       delays for a specified amount of time</li>
<li>stat                        return data about an inode</li>
<li>stty                        changes and prints terminal line settings</li>
<li>su                          run a shell or command with substitute uid and gid</li>
<li>tee                         send output to multiple files</li>
<li>test                        evaluates an expression</li>
<li>timeout                     run a command with a time limit</li>
<li>true                        exits successfully</li>
<li>tty                         prints terminal name</li>
<li>uname                       prints system information</li>
<li>unlink                      removes link</li>
<li>uptime                      prints system uptime</li>
<li>users                       prints currently logged in usernames</li>
<li>who                         print logged in users</li>
<li>whoami                      print effective uid</li>
<li>yes                         be repetitively affirmative</li>
</ul>
<h2><a class="header" href="#binary-utilities" id="binary-utilities">Binary utilities</a></h2>
<ul>
<li>as                          assembler</li>
<li>ld                          linker</li>
<li>gprof                       profiler</li>
<li>addr2line                   convert addresses to file and line</li>
<li>ar                          create, modify, and extract from archives</li>
<li>c++filt                     demangling filter for c++ symbols</li>
<li>dlltool                     creation of windows dlls</li>
<li>gold                        alternative assembler</li>
<li>nlmconv                     object file conversion to netware loadable module</li>
<li>nm                          list symbols in object files</li>
<li>objcopy                     copy object files, possibly making changes</li>
<li>objdump                     dump information about object files</li>
<li>ranlib                      generate indexes for archives</li>
<li>readelf                     display content of ELF files</li>
<li>size                        list total and section sizes</li>
<li>strings                     list printable strings</li>
<li>strip                       remove symbols from an object file</li>
<li>windmc                      generate windows message resources</li>
<li>windres                     compiler for windows resources files</li>
</ul>
<p># Vim</p>
<pre><code>Vim command pattern:
* register name (optional)
* repeats (optional)
* operation (eg y, d, etc)
* movement (doubling the operation takes the current line).

Move by context, not position.
Do not search and scroll, do not use your eyes to find text.
If you're not searching, at least jump.
Never park in insert mode, immediately escape after editing.

--------------------------------------------------------------------------------
INVOCATION

vim -o filename1, ...   Open multiple files in horizontally tiled windows.
vim -O filename1, ...   Open multiple files in vertically tiled windows.
vim -p filename1, ...   Open multiple files in separate tabs.

--------------------------------------------------------------------------------
HELP

:help command   Split screen help
Ctrl-J          Follow link
Ctrl-T          Go back

--------------------------------------------------------------------------------
MODES / EDITING

.               Repeat previous command.
&lt;Esc&gt;           Enter command mode.
i a             Enter insert mode before / after the cursor.
I A             Enter insert mode at the beginning / end of the current line.
o O             Enter insert mode in a new line under/above the current line.
r               Replace character under cursor and return to command mode.
R               Enter overtype (replace) mode.
C               Change the rest of the current line.
c               Change (retype) command. Follow with a movement command.
cc              Deletes the current line to register &quot; and enters insert mode.
cw              Deletes the current word to register &quot; and enters insert mode.
c$              Change the rest of the current line.
s               Substitute the character under cursor and enter insert mode.
S               Delete line at cursor and substitute text (same as cc)
:               Enter ex mode.
!               Enter shell filter mode.
Ctrl-o command  Quick command in insert mode
Ctrl-R &quot;        Paste in insert mode
J               Join line with following.

--------------------------------------------------------------------------------
VISUAL MARKING MODES

                You can start in one visual mode and enter another,
                and continue to mark.
                The marked area becomes a context for other commands.
                Use the r command and letter X to change every
                character in the marked area to X.
                Use the marked area for the ex commands.
v               Start visual mode, mark lines, then do command (such as y-yank)
                Enter visual mode, mark character-wise.
                Use to select text.
                Press v again to cancel out the visual marking.
V               Start Linewise visual mode
                Enter visual mode, mark line-wise.
Ctrl+v          Start visual block mode
                Press V again to cancel this mode.
^v              Enter visual mode, mark column-wise.
gv              Re-mark the area last marked.
ggVG            Mark the entire document.
o               Move to other end of marked area
O               Move to Other corner of block
aw              Mark a word
ab              A () block (with braces)
aB              A {} block (with brackets)
ib              Inner () block
iB              Inner {} block
Esc             Exit visual mode

--------------------------------------------------------------------------------
REGISTERS

:registers      List of registers
&quot;+ &quot;*           clipboard register / selection buffer
&quot;               The unnamed or default register.
a-z,A-Z         The lowercase and uppercase letter registers.
+               The system default register (the normal cut/paste one).
_               The black hole, essentially /dev/null,
                use to avoid wiping out the &quot; register.
(examples)
dd              Delete the current line into the default &quot; register.
&quot;add            Delete the current line into register a.
&quot;y$             Yank the current character to the end of the line into
                register y.
&quot;byy            Yank the current line into register b.
&quot;c24dd          Literally: into register c, 24 times delete the current line.

--------------------------------------------------------------------------------
MOVEMENT

  k             Up one character.
h   l           Left / Right one character.
  j             Down one character.

b w             Move backward / forward to the start of the next word.
B W             Move backward / forward to the start of the next
                space-terminated word (ignore punctuation).
                or backward / forward one word if already at start.
e               Move to the end of word, or to next word if already at end.
E               Move to the end of space-terminated word, ignoring punctuation.

0 $             Move to the start /end of the line.

%               Move to matching brace, paren, etc.
{ }             Move to start / end (first empty line) of paragraph.
( )             Move to start of sentence / of next sentence
                (separator is both period and space).
[[ ]]           Move to next / previous function (c/c++/java/python).

H M L           Move to the first line / middle / last line of the screen.
&lt;n&gt;H            Move to line n from start of the screen.
&lt;n&gt;L            Move to line n from bottom of the screen.
^               Move to the first non-whitespace character on the line.

^f              Move forwards one page.
^b              Move backwards one page.

gg G            Go to beginning /end of file.
&lt;n&gt;gg           Go to line n.
&lt;n&gt;G            Go to line n.
:&lt;n&gt;            Go to line n.

&lt;n&gt;%            Go to nth percentage of file.
&lt;n&gt;|            Go to column n of current line.

*               Move to the next instance of word under cursor,
                and highlight all uses.
#               Move to the previous instance of word under cursor.
''              Move to the location of your last edit in the current file.

--------------------------------------------------------------------------------
SCROLLING

Ctrl-E Ctrl-Y   scroll window down / up
zt zz zb        Scroll the cursor to top / middle / bottom of page.

--------------------------------------------------------------------------------
JUMPING WITH THE CURSOR

:changes        changelist
g;              older
g,              newer position in the changelist
:jumps          jumplist
Ctrl-I Ctrl-O   forward / back in jumplist

--------------------------------------------------------------------------------
SEARCHING

/ ?             Search forward / backward, will prompt for a regex pattern.
                Press enter to accept position.
n               Repeat last search.
N               Repeat last search but in the opposite direction.
tx              Move to letter x, stopping just before x.
                Useful for change/delete commands.
fx              Find letter x, stopping on the letter x.
                Useful for change/delete commands.
[i [I           Show first / every line containing word under cursor.
:g/pattern/     Show every line matching the regex pattern.

:&lt;r&gt;s/foo/bar/&lt;a&gt;
                Substitute foo with bar,
                &lt;r&gt; determines the range, can be:
                    nothing (work on the current line only),
                    number (work on the line whose number you give),
                    % (the whole file).
                &lt;a&gt; determines the arguments, can be:
                    g (replace all occurences in the line
                       without only replaces the first occurence in each line)
                    i (ignore case for the search pattern)
                    I (dont ignore case)
                    c (confirm each substitution, you can type
                        y to substitute the current match,
                        a to substitute this and all remaining matches, or
                        q to quit substitution).
(examples)
:452/foo/bar/   Replace the first occurence of foo with bar on line 452.
:s/foo/bar/g    Replace every occurence of foo with bar on the current line.
:%s/foo/bar/g   Replace every occurence of foo with bar in the whole file.
:%s/foo/bar/gi  Same as above, but ignore case.
:%s/foo/bar/gc  Confirm every substitution.
:%s/foo/bar/c   For each line on the file, replace the first occurence of foo
                with bar and confirm every substition.

--------------------------------------------------------------------------------
UNDO/REDO

u               Undo last command.
U               Undo all the latest changes made to the current line.
CTRL-r          Redo.

--------------------------------------------------------------------------------
CUT (DELETE), COPY (YANK), PASTE

x               Delete character under cursor.
xp              Transpose two letter (delete and paste, technically)
X               Delete character before the cursor (same as backspace).
d               Delete selected text.
dd              Delete line and put it into the default register.
:d              Same as above.
y               Yank selected text.
yy              Yank line.
:y              Same as above.
Y               Same as above.
p P             Paste contents of default register after / before cursor.
^r              In insert mode, reads data from a register and pastes
                it, continuing in insert mode.

--------------------------------------------------------------------------------
COMPLETION

^n              In insert mode, complete a word (forward through choice list).
^p              In insert mode, complete a word (backward through choice list).
^x^l            In insert mode, complete a line.
^x^f            File name completion.
^x^k            Dictionary completion. Enable the dictioary by adding the line
                    set dictionary+=/usr/share/dict/words
:ab ab1 ab2     Set abbreviation. After this, while in insert mode, ab1 will be
                expanded into ab2 immediately after typing.
:ab teh the     A common error is fixed automatically.

--------------------------------------------------------------------------------
INDENTING

&lt;               Left-shift  (requires a movement command, works on whole lines).
&gt;               Right-shift (requires a movement command, works on whole lines).
&lt;}              Move a paragraph to the left.
3&gt;&gt;             Shift three lines right.
5&gt;&gt;             Indent 5 lines from line where cursor stands
^T              In insert/overwrite mode, indent.
^D              In insert/overwrite mode, dedent.

--------------------------------------------------------------------------------
CODE REFORMATTING

%!astyle        Restyle the entire file with astyle (a reformatting program).
%!indent        Restyle the entire file with indent (a nice older program).
gqq             Re-wrap the current line (a double-jump).
gqj             Re-wrap the current line and the line following.
gq}             Re-wrap lines from the current line to the end of the paragraph.
:retab          Retabbing converts tab stops to spaces, and ensures correct
                indentation for each.
                Set the tabstop variable to the correct setting, set expandtab,
                and issue :retab command.
                Vim can wrap the text as you type, via the linebreak, textwidth,
                and autoindent settings.
~               Change the case of the character under the cursor.
                Works in visual mode.

--------------------------------------------------------------------------------
CTAGS

!ctags -R *     Run ctags (better to do this in the makefile).
^]              Jump to the definition of the term under the cursor.
^t              Pop the browsing stack, return to the previous location.

--------------------------------------------------------------------------------
VISUAL BLOCKS
    Visual blocks are one of those features that you won't find in a GUI text
    editor.
    They let you mark blocks of text and do editing operations on them.
    To enter visual blocks mode, press Ctrl+v, then use HJKL or arrow keys to
    highlight a block of text.
    Now operate on the first highlighted line as if you were in normal mode,
    and operations will be reflected on other highlighted lines.
    For example, to indent a block of text with &gt; characters (to make it look
    like a text being replied to), highlight the first column of characters in
    visual blocks mode, then press Shift+i to switch to insert mode at the
    beginning of the line.
    Insert a &gt; in the first line and press Ctrl+c.
    A &gt; will be prepended to all other highlighted lines.
    This feature is also useful for commenting blocks of code, by prepending
    lines with // or #.

--------------------------------------------------------------------------------
CODE FOLDING

zf#j            creates a fold from the cursor down # lines.
zf/string       creates a fold from the cursor to string.
zj              moves the cursor to the next fold.
zk              moves the cursor to the previous fold.
zo              opens a fold at the cursor.
zc              To close it back, press zc.
zO              opens all folds at the cursor.
zm              increases the foldlevel by one.
zM              closes all open folds.
zr              decreases the foldlevel by one.
zR              decreases the foldlevel to zero -- all folds will be open.
zd              deletes the fold at the cursor.
zE              deletes all folds.
[z              move to start of open fold.
]z              move to end of open fold.

zf5j            Fold 5 lines.
kvggzf          Fold everything from the beginning up to the current line.
zfa}            To fold a code block marked by braces { },
                move the cursor into the block and press zfa}.

See :help z
    :help fdm

    set foldmethod=marker

    At the beginning of a function fragment, you can type ‘zfap’ to create a
    fold; this should add some {{{ }}} tags around your code in the comment of
    choice for the language you’re coding in.
    You can type ‘zo’ to open a fold, or I can just hit the right arrow key on
    the folded code marker.
    You can type ‘zc’ to close a fold.
    You can type ‘zr’ to open all folds.
    You can type ‘zm’ to close all folds.

--------------------------------------------------------------------------------
MACROS (complex-repeat)

q               Enter macro recording mode by pressing the command q, followed
                by a register into
                which the macro will be stored.
                Any of the alphabetic upper or lower case keys, and any of the
                digits may be used.
                Every keystroke will be recorded into the macro until you press
                the q key again.
@               To replay a macro, use the @ key followed by a register name.
                Once a macro is replayed, the undo key will see that macro as a
                single action.
@@              Vim remembers the macro you just replayed, and can repeat it
                with the double-jump.
                The dot command will also see it as a single action.
                The recorded macros are just text in a register.
                They can be pasted into a document, edited, yanked back into
                the register, etc.
(examples)
qa              Start recording the macro to register a.

--------------------------------------------------------------------------------
SPELL CHECKING

Turn on spellchecking with :set spell and turn off with :set nospell.

]s [s           move to the next / previous mispelled word
zg              add a word to the dictionary
zug             undo the addition of a word to the dictionary
z=              view spelling suggestions for a mispelled word
:help spell

--------------------------------------------------------------------------------
BOOKMARKS

                Vim allows you to set a bookmark con a line, and jump from one
                bookmark to another.
                You can use any letter for a bookmark.
                Lower-case letters set a file-specific bookmark.
                'a in one file will take you to a different place than in
                another file.
                Upper-case letter set global bookmarks.
                'A will take you to the line you marked in the file you marked
                it, it loads the
                marked file in the current window.
mx              Put bookmark x at the current line.
'x              Jump to bookmark x.

--------------------------------------------------------------------------------
FILE MANAGEMENT

:w              Save.
:w filename     Save a copy of the file you are editing as filename.
:wa             Save all windows.
:q              Quit.
:qa             Quit all windows.
:q!             Quit without saving.
:wq             Save and quit.
:x              Save and quit. If no changes were made, Vim exits without
                writing the file.
ZZ              Save changes and quit current window.
:o filename     Open file in current buffer.
:e filename     Open file in new buffer. Tab will autocomplete filenames.
:e!             Reload file from disk discarding changes.
:e#             Return to the previous window.
gf              Goto filename under cursor

--------------------------------------------------------------------------------
BUFFER MANAGEMENT

:buffers        List buffers
:bn :bp         Next / previous buffer.
:bd             Delete a buffer (close a file).

--------------------------------------------------------------------------------
WINDOW MANAGEMENT

:sp filename    Splits window horizontally and loads filename in the new window.
:vs filename    Splits window vertically and loads filename in the new windows.

^Wh ^Wj ^Wl ^Wk Move to window above / below / left / right.
^Wc             Close current window.
^Wo             Close all windows except current window.
^Wf             Place the cursor on a filename, and issue this command while in
                normal mode. The file will be loaded into a new window.
^W+             Increases the size of the current split by one line.
                Try combining this with counts.
^W-             Decreases the size of the current split by one line.
^W_             Maximize the current split.
:ls

--------------------------------------------------------------------------------
TABS

:tabe           Open a file in a new tab.
Ctrl-W T        Move current split window into its own tab.

gt              Go to the next tab.
:tabn
:tabnext
CTRL-PageDown

gT              Go to the previous tab.
:tabp
:tabprev
CTRL-PageUp

Ngt             Go to tab N.
:tabr           Go to the first tab.
:tabl           Go to the last tab.

:tabc           Close tab.
:tabclose

:tabo           Close all tabs except current one.
:tabonly

:tabm &lt;n&gt;       Move tab to position &lt;n&gt;.
:tabmove &lt;n&gt;

--------------------------------------------------------------------------------
VIMRC

:options
:browse options
:browse set

--------------------------------------------------------------------------------
SHELL FILTERING

!!command  Pass current line only through filter.
!}command  Pass area from current lint through end of paragraph through filter.
!Gcommand  Pass are form current line through end of file through filter.
:%!command Pass the entire file through filter.

--------------------------------------------------------------------------------
FILE EXPLORER

Edit a directory.

o               Open file in a horizontal split window.
v               Open file in a vertical split window.
i               Show more info.
s               Sort by column under cursor.
r               Sort in reverse order.
D               Delete file.
d               Make new directory.
&lt;Enter&gt;         Open file in current window.

--------------------------------------------------------------------------------
MISCELANEOUS TRICKS

:g/^#/d                 Delete all lines that begins with #
:g/^$/d                 Delete all lines that are empty and contain no tabs
:g/^\s*$/d              Delete all lines that are empty
:%s/$/{ctrl-V}{CR}/g    Inserts blank line between lines
:%s/{TAB}*$//           Strip tabs at end of line
:g/&lt;pattern&gt;/t$         Copy every line which matches pattern to the end of the
                        file

###############################################################################
VIM MACROS

    :%!column -t

    :%!sort -k1

    Matsumoto  Yukihiro  Ruby   1965  Japan
    Moolenar   Bram      Vim    1961  Netherlands
    Ritchie    Dennis    C      1941  USA
    Stallman   Richard   GNU    1953  USA
    Thompson   Ken       Unix   1943  USA
    Tridgell   Andrew    Samba  1967  Australia
    Wall       Larry     Perl   1954  USA

    suppose we’ve got the task of replacing the fourth column of this table with
    the approximate age of the person, which we can get naturally enough by
    substracting their birth year from the current year.
    This is a little awkward to do in pure ex, so we’ll record a macro for doing
    it on one line.

    03wdei^R=2013-^R&quot;^M^[0j

    0           — Move to the start of the line
    3w          — Skip three words, in this case to the fourth column
    de          — Delete to the end of the word
    i           — Enter insert mode
    ^R=         — Insert the contents of the special = register, which accepts
                  an expression to evaluate
    2012-^R&quot;^M  — Enter the expression 2012-(birth year) and press Enter
                  (literal ^M), which completes the operation, and inserts the
                  result
    ^[          — Leave insert mode
    0           — Return to the start of the line
    j           — Move down a line

    The only thing that’s slightly voodoo (and certainly not vi-compatible) is
    the arithmetic done with the special = register. You can read about that in
    :help @=, if you’re curious.

REPEATING MACROS

    As a first very simple hint, if you’re running a macro several times, don’t
    forget that you can prepend a count to it; in our case, 6@a would have fixed
    up all the remaining lines. To take advantage of this, it’s good practice to
    compose your macros so that they make sense when run multiple times; in the
    example above, note that the end of the macro is moving down onto the next
    line, ready to run the macro again if appropriate.

    Similarly, if you’ve already run a macro once, you can run the same one
    again by just tapping the @ key twice, @@. This repeats the last run macro.
    Again, you can prepend a count to this, @a5@@


    TRUE NATURE OF MACROS
    you needn’t restrict yourself to the single-keystroke vi commands for Vim
    when you compose macros. You can include ex commands as well, for example
    to run a substitution during a macro:

    qb:s/foo/bar/g^Mq
    @b

    all of the operations that you can apply to registers in general work with
    what we normally call macros, with the old standards, delete, yank, and
    paste You can test this with the example macro demonstrated above, by typing
    &quot;ap,
    which will dump the raw text straight into the buffer.
    Also like other registers, it’ll show up in the output of the :registers
    command.

EDITING VIM MACROS IN A BUFFER

    suppose I realise partway through writing it that I made a mistake in
    typing 2011 instead of 2012.
    I finish recording the rest of the macro anyway, and dump the broken
    keystrokes into a new scratch buffer:

    :enew
    &quot;ap

    This gives me the contents of the macro in plain text in the buffer:

    qa03wdei^R=2011-^R&quot;^M^[0jq

    So now all I have to do is change that bad year to 2012, and then yank the
    whole thing back into register a:

    ^&quot;ay$

    Now I can test it directly with @a on the appropriate file, and if it’s
    still wrong, I just jump back to my scratch buffer and keep fixing it up
    until it works.

    One potential snag here is that you have to enter keystrokes like Ctrl+R as
    literal characters, but once you know you can enter any keystroke in Vim
    literally in insert or command mode by prefixing it with Ctrl+V, that isn’t
    really a problem. So to enter a literal Ctrl+R in insert mode, you type
    Ctrl+V, then Ctrl+R.

RUNNING A VIM MACRO ON A SET OF LINES

    It’s occasionally handy to be able to run a macro that you’ve got ready on a
    specific subset of lines of the file, or perhaps just for every line.
    Fortunately, there’s a way to do this, too.

    Using the :normal command, you’re able to run macros from the ex command
    line:

    :normal @a
    All it takes is prefixing this with any sort of range definition to allow
    you to run a macro on any set of lines that you’re able to define.

    Run the macro on each line of the whole buffer:

    :% normal @a
    Between lines 10 and 20:

    :10,20 normal @a
    On the lines in the current visual selection:

    :'&lt;,'&gt; normal @a
    On the lines containing the pattern vim:

    :g/vim/ normal @a
    When you get confident using this, :norm is a nice abbreviation to use.

MOVING A VIM MACRO INTO A FUNCTION

    For really useful macros of your own devising, it’s occasionally handy to
    put it into a function for use in scripts or keystroke mappings.
    Here again the :normal command comes in handy.

    Suppose I wanted to keep the age calculation macro defined above for later
    use on spreadsheets of this kind.
    I’d start by dumping it into a new buffer:

    :enew
    &quot;ap
    The macro appears as raw text:

    03wdei^R=2012-^R&quot;^M^[0j
    I prefix it with a :normal call, and wrap a function definition around it:

    function! CalculateAge()
        normal 03wdei^R=2012-^R&quot;^M^[0j
    endfunction
    Then all I need to do is include that in a file that gets loaded during
    Vim’s startup, possibly just .vimrc. I can call it directly from ex:

    :call CalculateAge()
    But given that I wanted it to be a quick-access macro, maybe it’s better to
    bind it to \a, or whatever your chosen &lt;leader&gt; character is:

    nnoremap &lt;leader&gt;a :call CalculateAge()&lt;CR&gt;
    Saving a Vim macro

    If you want to have a macro always available to you, that is, always loaded
    into the appropriate register at startup, that can be done in your .vimrc
    file with a call to let to fill the register with the literal characters
    required:

    let @a='03wdei^R=2012-^R&quot;^M^[0j'

APPENDING EXTRA KEYSTROKES TO A VIM MACRO

    If you just want to tack extra keystrokes onto an existing macro and don’t
    care to edit it in a Vim buffer, you can do that by recording into it with
    its capital letter equivalent. So, if you wanted to add more keystrokes
    into the register b, start recording with qB, and finish with the usual q.

RECURSIVE VIM MACROS

    If you’re crazy enough to need this, and I never have, there’s an excellent
    Vim Tip for it. But personally, I think if you need recursion in your text
    processing then it’s time to bust out a real programming language and not
    Vimscript to solve your problem.

    If the issue for which you think you need recursion is running a macro on
    every line of a buffer with an arbitrary number of lines, then you don’t
    need recursion; just record a one-line version of the macro and call it
    with :% normal @a to run it on every line.

VIM MACRO GOTCHAS

    Here are a few gotchas which will save you some frustration if you know
    about them ahead of time:

    When you have a hammer, everything starts to look like a nail. Don’t try to
    solve problems with macros when there are better solutions in the ex
    command set, or available in external programs. See the Vim koans page for a
    couple of examples.
    You need to insert keystrokes like Enter as literal Ctrl+M, so that they
    look like ^M. The convenience abbreviations in mappings, like &lt;CR&gt;, simply
    don’t work. You’re likely to find yourself chording Ctrl+V a lot.
    Macros tend to stop, sometimes for apparently no reason and with no warning
    messages, as soon as they hit some sort of error. One particularly annoying
    instance of this is when you’re performing several substitutions in a macro,
    because if it doesn’t find any instances of a pattern it will throw an error
    and stop executing. You can prevent this by adding the e flag to the
    substitution call:

    :s/foo/bar/e

################################################################################
PLUGINS

--------------------------------------------------------------------------------
ctags

With the &quot;:tag&quot; command the cursor will be positioned on the tag.  With the
CTRL-] command, the keyword on which the cursor is standing is used as the
tag.  If the cursor is not on a keyword, the first keyword to the right of the
cursor is used.

The &quot;:tag&quot; command works very well for C programs.  If you see a call to a
function and wonder what that function does, position the cursor inside of the
function name and hit CTRL-].  This will bring you to the function definition.
An easy way back is with the CTRL-T command.  Also read about the tag stack
below.

*:ta* *:tag* *E426* *E429*

:[count]ta[g][!] {ident}
            Jump to the definition of {ident}, using the
            information in the tags file(s).  Put {ident} in the
            tag stack.  See |tag-!| for [!].
            {ident} can be a regexp pattern, see |tag-regexp|.
            When there are several matching tags for {ident}, jump
            to the [count] one.  When [count] is omitted the
            first one is jumped to. See |tag-matchlist| for
            jumping to other matching tags.

&lt;C-LeftMouse&gt;
            *&lt;C-LeftMouse&gt;* *CTRL-]*

CTRL-]      Jump to the definition of the keyword under the
            cursor.  Same as &quot;:tag {ident}&quot;, where {ident} is the
            keyword under or after cursor.
            When there are several matching tags for {ident}, jump
            to the [count] one.  When no [count] is given the
            first one is jumped to. See |tag-matchlist| for
            jumping to other matching tags.
            {Vi: identifier after the cursor}
CTRL+[      Navigate to tag under cursor.

:tag &lt;tag name&gt;
Navigate to named tag.
:pop
Tag jumps are saved on a stack; this command pops the top of the stack and
returns to the previous cursor position.
:tnext
For tags that resolve to multiple source locations, jumps to the next such
location.
:tprev
Idem, but jumps to previous such location.

Now you need to configure taglist.vim, this can be done like this:

let Tlist_Ctags_Cmd = &quot;/usr/bin/ctags&quot;
let Tlist_WinWidth = 50
map &lt;F4&gt; :TlistToggle&lt;cr&gt;

map &lt;F8&gt; :!/usr/bin/ctags -R --c++-kinds=+p --fields=+iaS --extra=+q .&lt;CR&gt;

This builds tags libs for the current working directory (it's super fast).

Once you have build tags, you can browse them using builtin functions.
Here are some examples:

:tag getUser =&gt; Jump to getUser method
:tn (or tnext) =&gt; go to next search result
:tp (or tprev) =&gt; to to previous search result
:ts (or tselect) =&gt; List the current tags
=&gt; Go back to last tag location
+Left click =&gt; Go to definition of a method





1. Navigate to function definition by specifying the function name using :ta
2. Navigating to the function definition from ‘function call’ using Ctrl + ]
3. Returning back again to function call from the definition using Ctrl + t
4. Navigating through a list of function names which has the similar names
:ta /^get

Following vim commands can be used to navigate through relevant functions

:ts – shows the list.
:tn – goes to the next tag in that list.
:tp - goes to the previous tag in that list.
:tf – goes to the function which is in the first of the list.
:tl – goes to the function which is in the last of the list.

1. Open the Tag List Window in Vim using :TlistOpen

# vim mycprogram.c
:TlistOpen

3. Jump to the function definition which is in another source file

When you are going through a function in a source file and would want to go to
the function definition which is in another file, you can do this in two
different methods.

Method 1:
If you had the ctags generated for that file, when the cursor is in the function
call pressing CTRL + ] will take you to the function definition.
And automatically the tag list window will show the tags for that newly opened
file.

Method 2:
Open another file also in the same vim session which will update the tag list
window with the information about that file. Search for that function name in
the tag list window, and by pressing &lt;CR&gt; on that function name in the tag list
window you can go to the function definition..


4. Viewing the prototype/signature of functions or variables.

Press ‘space’ in the function name or in the variable name in the tag list
window to show the prototype (function signature) of it in the VIM status bar
as shown below. In the example below, click on selectDumpableTable function from
the Tag-window and press space-bar, which displays the function signature for
selectDumptableTable function in the bottom Vim Status bar.

5. Viewing the total number of functions or variables in a source code file

press ‘space’ in the tag type in the tag list window, which shows the count of
it. In the example below, when the cursor is at ‘function’ press space, which
will display the total number of functions in the current source code.

C-] - go to definition
C-T - Jump back from the definition.
C-W C-] - Open the definition in a horizontal split

Add these lines in vimrc
map &lt;C-\&gt; :tab split&lt;CR&gt;:exec(&quot;tag &quot;.expand(&quot;&lt;cword&gt;&quot;))&lt;CR&gt;
map &lt;A-]&gt; :vsp &lt;CR&gt;:exec(&quot;tag &quot;.expand(&quot;&lt;cword&gt;&quot;))&lt;CR&gt;

C-\ - Open the definition in a new tab
A-] - Open the definition in a vertical split

After the tags are generated. You can use the following keys to tag into and
tag out of functions:

Ctrl-Left_MouseClick - Go to definition
Ctrl-Right_MouseClick - Jump back from definition



Another useful plugin for C development is cscope Just as Ctags lets you jump
to definitions, Cscope jumps to the calling functions.

If you have cscope in your ~/bin/ directory, add the following to your .vimrc
and use g^] to go to the calling function (see :help cscope).

if has(&quot;cscope&quot;)
    set csprg=~/bin/cscope
    set csto=0
    set cst
    set nocsverb
    &quot; add any database in current directory
    if filereadable(&quot;cscope.out&quot;)
        cs add cscope.out
        &quot; else add database pointed to by environment
    elseif $CSCOPE_DB != &quot;&quot;
        cs add $CSCOPE_DB
    endif
endif

Almost forgot... Just as ctags - you have to generate (and periodically update)
the database. I use the following script

select_files &gt; cscope.files
ctags -L cscope.files
ctags -e -L cscope.files
cscope -ub -i cscope.files

Where 'select_files' is another script that extracts the list of C and header
files from the Makefile. This way I index only the files actually used by the
project.

################################################################################
TIPS

--------------------------------------------------------------------------------
Join all paragraphs in a file,
without deleting the blank lines separating paragraphs

    Make sure the file ends in a blank line.
    :g/^./ .,/^$/-1 join

--------------------------------------------------------------------------------
Character search is near-instant for moving within a line

The f, F, t, T, ;, and , commands make up the suite of character search motions.
When you press f{char}, Vim looks forward from the cursor position for the next
occurrence of {char} on the current line. If it finds a match, the cursor moves
directly there. If no match is found, nothing happens.

If your cursor stopped on a match before the one you were aiming for, press ; to
repeat the search. Keep pressing ; until you hit your mark. If you overshoot,
press , to reverse the search.

--------------------------------------------------------------------------------
Commenting a block of Python code

Alternative 1:
    C-v
    &lt;move around selecting text&gt;
    I
    #
    Esc

    j is cursor down, so he's just selecting down 3 lines while in visual block
    mode.
    Shift+i means insert before the first non-whitespace character on the line,
    but it has a sort of special-case use while in visual mode, in that it will
    insert before the block selection on all lines thereof. # is just inserting
    the # character. Esc ends the visual mode, and also finalizes the insertion
    from shift+i, which also inserts the # in the right place on the remaining
    lines before it finishes.

    To uncomment:
    ctrl+v over the top #
    &lt;move around selecting text&gt;
    x

Alternative 2:
    Mark the block you want to comment, then type
    :s/^/#/
    That replaces the start of each line with a #.
    To uncomment, mark the block again, and do
    :s/.//
    This replaces the first character of each line with nothing.

Alternative 3:
    I put this in my .vimrc

    map ^V^_ a^V^_^V^[
    map ,4 :s/^/\/\//g&lt;CR&gt;
    map ,3 :s/^/##/g&lt;CR&gt;
    map .4 :s/^\/\///g&lt;CR&gt;
    map .3 :s/^##//g&lt;CR&gt;
    &quot; wrapping comments
    map ,* :s/^\(.*\)$/\/\* \1 \*\//&lt;CR&gt;
    map ,( :s/^\(.*\)$/\(\* \1 \*\)/&lt;CR&gt;
    map ,&lt; :s/^\(.*\)$/&lt;!-- \1 --&gt;/&lt;CR&gt;
    map .&lt; :s/^\(.*\)$/&lt;!-- \1 --&gt;/&lt;CR&gt;
    map ,d :s/^\([/(]\*\\|&lt;!--\) \(.*\) \(\*[/)]\\|--&gt;\)$/\2/&lt;CR&gt;

    So that if I want to comment one line, while in command mode I
    type ,3 for ## comments, then to uncomment I type .3
    If I'm on the top line of a bock of code, that is say 7 lines
    deep I type 7,3 which would comment out 7 lines of code.

Alternative 4:
    I used comment.vim. It's very nice as you can select lines and
    toggle commenting on/off.
    Very easy to use. Type &quot;co&quot; in command mode.
    Works on single lines, visual blocks, etc.
    You can also add custom comment tags (see end of .vim file)

--------------------------------------------------------------------------------
Remove unwanted spaces

Alternative 1: Simple commands to remove unwanted whitespace

    In a search,
    \s finds whitespace (a space or a tab),
    \+ finds one or more occurrences.

    :%s/\s\+$//     Delete all trailing whitespace (at the end of each line)
    :%s/^\s\+//     Delete whitespace at the beginning of each line.
    :%le            Same thing (:le = :left = left-align given range):

    With the following mapping you can press F5 to delete all
    trailing whitespace.
    The variable _s is used to save and restore the last search
    pattern register (so next time you press n you will continue your
    last search), and :nohl is used to switch off search highlighting
    (so trailing spaces won't be highlighted while you are typing).
    The e flag is used in the substitute command so no error is shown
    if trailing whitespace is not found.

    :nnoremap &lt;silent&gt; &lt;F5&gt; :let _s=@/&lt;Bar&gt;:%s/\s\+$//e&lt;Bar&gt;:let @/=_s&lt;Bar&gt;:nohl&lt;CR&gt;

Alternative 2: Display or remove unwanted whitespace with a script

    Here is a more elaborate procedure that can display or remove
    unwanted whitespace.
    Here, &quot;unwanted&quot; means any spaces before a tab character, or any
    space or tab at the end of a line.

        function ShowSpaces(...)
          let @/=&quot;\\v(\\s+$)|( +\\ze\\t)&quot;
          let oldhlsearch=&amp;hlsearch
          if !a:0
            let &amp;hlsearch=!&amp;hlsearch
          else
            let &amp;hlsearch=a:1
          end
          return oldhlsearch
        endfunction

        function TrimSpaces() range
          let oldhlsearch=ShowSpaces(1)
          execute a:firstline.&quot;,&quot;.a:lastline.&quot;substitute ///gec&quot;
          let &amp;hlsearch=oldhlsearch
        endfunction

        command -bar -nargs=? ShowSpaces call ShowSpaces(&lt;args&gt;)
        command -bar -nargs=0 -range=% TrimSpaces &lt;line1&gt;,&lt;line2&gt;call TrimSpaces()
        nnoremap &lt;F12&gt;     :ShowSpaces 1&lt;CR&gt;
        nnoremap &lt;S-F12&gt;   m`:TrimSpaces&lt;CR&gt;``
        vnoremap &lt;S-F12&gt;   :TrimSpaces&lt;CR&gt;

Alternative 3: An alternative function simulating manual steps:

    However, this has minor side-effects, such as influencing undo
    history and sometimes changing scroll position.

        function StripTrailingWhitespace()
          if !&amp;binary &amp;&amp; &amp;filetype != 'diff'
            normal mz
            normal Hmy
            %s/\s\+$//e
            normal 'yz&lt;CR&gt;
            normal `z
          endif
        endfunction

Alternative 4: Automatically removing all trailing whitespace

    Just put the following line in your vimrc file.
    Everytime you issue a :w command, Vim will automatically remove
    all trailing whitespace before saving.

    autocmd BufWritePre * :%s/\s\+$//e

    This is a very dangerous autocmd to have! This will *always*
    strip trailing whitespace from *every* file you save.
    Sometimes, trailing whitespace is desired, or even essential!
    For example, if in your .vimrc you have the following:

        set wrap
        set linebreak
        &quot; note trailing space at end of next line
        set showbreak=&gt;\ \ \

    then saving your .vimrc will make it use &quot;&gt;  \&quot; instead of
    &quot;&gt;   &quot; to prepend to wrapped lines!

    Remember you can also specify filetype

        autocmd BufWritePre *.pl :%s/\s\+$//e

    or how about having this operate when you enter the file:

        autocmd BufEnter *.php :%s/\s\+$//e

    And let's get rid of those pesky ^M at the same time

        autocmd BufEnter *.php :%s/[ \t\r]\+$//e

    With a &quot;:call&quot; instead of &quot;:%s&quot; (keep last used search/replace)
    and using FileType:

        autocmd FileType c,cpp,java,php autocmd BufWritePre &lt;buffer&gt; :call setline(1,map(getline(1,&quot;$&quot;),'substitute(v:val,&quot;\\s\\+$&quot;,&quot;&quot;,&quot;&quot;)'))

Comments

********************************************************************************
Here's what I use in my .vimrc:

    &quot; Removes trailing spaces
    function TrimWhiteSpace()
      %s/\s*$//
      ''
    :endfunction

    set list listchars=trail:.,extends:&gt;
    autocmd FileWritePre * :call TrimWhiteSpace()
    autocmd FileAppendPre * :call TrimWhiteSpace()
    autocmd FilterWritePre * :call TrimWhiteSpace()
    autocmd BufWritePre * :call TrimWhiteSpace()

    map &lt;F2&gt; :call TrimWhiteSpace()&lt;CR&gt;
    map! &lt;F2&gt; :call TrimWhiteSpace()&lt;CR&gt;

********************************************************************************
My preferred setting of list and listchars:

    set list listchars=tab:»·,trail:·

Or try

    set list lcs=tab:·⁖,trail:¶

********************************************************************************

There is one occasion where I want to keep my trailing space.
But even in those documents, I want to keep it in only one place, and not every
occurrence.

Here is my substitution pattern:

    s/\(^--\)\@&lt;!\s*$//

This will eliminate all trailing whitespaces except for the one in an email
signature marker (-- ).
In the function in the tip, this expands to:

    execute a:firstline.&quot;,&quot;.a:lastline.&quot;substitute /\\(^--\\)\\@&lt;!\\s*$//ge&quot;

Also, I've found the autocmds to work better like this:

    autocmd FileWritePre * :TrimSpaces
    autocmd FileAppendPre * :TrimSpaces
    autocmd FilterWritePre * :TrimSpaces
    autocmd BufWritePre * :TrimSpaces

(taking advantage of the default range defined in Betram's command definition)

I modified one of the above scripts to let the user know if whitespace was found

    &quot; automatically remove trailing whitespace before write
    function! StripTrailingWhitespace()
      normal mZ
      %s/\s\+$//e
      if line(&quot;'Z&quot;) != line(&quot;.&quot;)
        echo &quot;Stripped whitespace\n&quot;
      endif
      normal `Z
    endfunction
    autocmd BufWritePre *.cpp,*.hpp,*.i :call StripTrailingWhitespace()

--------------------------------------------------------------------------------
Did you know... http://vim.wikia.com/wiki/Did_you_know

May 2010

  @: will repeat a colon (Ex) command (and @@ will repeat again).
  You can use :g/^\s*$/;//-1sort to sort each block of lines in a file.
  It's useful to map . .`[ to repeat the last command and put the cursor at
  start of change.
  You can open a web browser with the URL in the current line.
  With --remote-send you can close a Vim you left open remotely.
  If you're used to Perl regex, you can use Perl compatible regular expressions.
  In insert mode, Ctrl-Y inserts the character above. You can make it insert the
  word above.
  A user-defined command can evaluate :Calc sin(pi/2).
  It's sometimes better to not use the slash delimiter for :s/old/new/.
  You can drag &amp; drop one or more files into gvim.

April 2010

  zz scrolls the current line to the middle of the screen; scrolloff can keep it
  there.
  Vim can do calculations using Python, Perl or bc.
  You can wrap long lines while moving the cursor by screen lines.
  A tricky search can find text that does not match.
  Pressing % jumps to a matching bracket, aof the number column.
  It's easy to change text between lowercase and UPPERCASE.
  The command history allows you to repeat several commands, possibly after
  editing them.

March 2010

  Vim tutorials has videos illustrating simple and advanced topics.
  Use % to jump to the matching bracket, and more.
  Use :lcd %:p:h to change directory to the file in the current window.
  ga shows the ascii value of the current character.
  You can list changes to the current file, even old changsy to count the words
  in a file or block.
  You can even make a frequency table counting the occurrences of each word!

February 2010

  Vim tutorials has videos illustrating simple and advanced topics.
  You can press * to search for the current word.
  Ctrl-A can increment numbers.
  After typing a couple of characters, you can complete a word with
  Ctrl-N or Ctrl-P.
  Vim's help use prefixes like v_ (visual mode) to show the context.ckspace and
  other delete keys work in insert mode.
  The 'number' and 'numberwidth' options control the display of line numbers.
  It's easy to change text between lowercase and UPPERCASE.

January 2010

  Vim tutorials has videos illustrating simple and advanced topics.
  We have an explanation for how :g/^/m0 reverses all lines.
  In a search pattern, \_s matches a space or tab or newline character.
  A script can use a test like &amp;buftype == &quot;quickfix&quot; to check if it is
  operating in the quickfix winduse :nnoremap Y y$.
  A plugin should set its &quot;loaded&quot; variable to show its version, for example
  let g:loaded_dbext = 503.
  We have a short FAQ for new users concerning common issues raised at #vim.
  You can use :cnoremap to map a key to &lt;C-\&gt;e(...)&lt;CR&gt; which will replace the
  command line with the (...) expression.&lt;/CR&gt;

* Save a file you edited in vim without the needed permissions
  :w !sudo tee %

* Spellchecker
  ':set spell' activates vim spellchecker.
  Use ']s' and '[s' to move between mistakes,
  'zg' adds to the dictionary,
  'z=' suggests correctly spelled words

* check my .vimrc http://tiny.cc/qxzktw and here http://tiny.cc/kzzktw for more
</code></pre>
<p># Miscellaneous</p>
<h1><a class="header" href="#systems-performance" id="systems-performance">Systems Performance</a></h1>
<h2><a class="header" href="#avoid-allocations-during-gameplay" id="avoid-allocations-during-gameplay">Avoid allocations during gameplay</a></h2>
<ul>
<li>Keep the things you iterate over as sequentially stored in memory as possible
(arrays better than node structures).</li>
<li>All list operations for things in games should be O(1).</li>
<li>Use spatial databases! (kd trees, quad trees, bins, octrees, bsp trees, etc)</li>
<li>Use a profiler. It's the only way to be sure you optimize the actual code that
takes the most time in you code and in your specific usage scenario.</li>
<li>Rethink the algorithm used at that location. Not the single line of code. Sorting is a simple example. Change bubble sort to something better.</li>
<li>After you have profiled your code and you get a single row that for some strange
reason take up a lot more time than you though it would. You can be quite sure
it's because of cache misses. A link list is a prime example of this. By looping
though it you can get one cache miss to get the next node and another to get the
data. Loop though the list and that's a lot of cache misses that takes many,
many cycles to do. You wont see this until you profile your code though.</li>
</ul>
<h2><a class="header" href="#the-art-of-computer-systems-performance-analysis-techniques-for-experimental-design-measurement-simulation-and-modeling---raj-jain" id="the-art-of-computer-systems-performance-analysis-techniques-for-experimental-design-measurement-simulation-and-modeling---raj-jain">The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling - Raj Jain</a></h2>
<h2><a class="header" href="#system-performance-tuning---mike-loukides" id="system-performance-tuning---mike-loukides">System Performance Tuning - Mike Loukides</a></h2>
<h2><a class="header" href="#computer-systems-performance-evaluation-and-prediction---howard-michel-paul-j-fortier" id="computer-systems-performance-evaluation-and-prediction---howard-michel-paul-j-fortier">Computer Systems Performance Evaluation and Prediction - Howard Michel, Paul J. Fortier</a></h2>
<h2><a class="header" href="#systems-performance---brendan-gregg" id="systems-performance---brendan-gregg">Systems Performance - Brendan Gregg</a></h2>
<p>1 Introduction
1.1 Systems Performance
1.2 Roles
1.3 Activities
1.4 Perspectives
1.5 Performance Is Challenging
1.5.1 Performance Is Subjective
1.5.2 Systems Are Complex
1.5.3 There Can Be Multiple Performance Issues
1.6 Latency
1.7 Dynamic Tracing
1.8 Cloud Computing
1.9 Case Studies
1.9.1 Slow Disks
1.9.2 Software Change
1.9.3 More Reading
2 Methodology
2.1 Terminology
2.2 Models
2.2.1 System under Test
2.2.2 Queueing System
2.3 Concepts
2.3.1 Latency
2.3.2 Time Scales
2.3.3 Trade-offs
2.3.4 Tuning Efforts
2.3.5 Level of Appropriateness
2.3.6 Point-in-Time Recommendations
2.3.7 Load versus Architecture
2.3.8 Scalability
2.3.9 Known-Unknowns
2.3.10 Metrics
2.3.11 Utilization
2.3.12 Saturation
2.3.13 Profiling
2.3.14 Caching
2.4 Perspectives
2.4.1 Resource Analysis
2.4.2 Workload Analysis
2.5 Methodology
2.5.1 Streetlight Anti-Method
2.5.2 Random Change Anti-Method
2.5.3 Blame-Someone-Else Anti-Method
2.5.4 Ad Hoc Checklist Method
2.5.5 Problem Statement
2.5.6 Scientific Method
2.5.7 Diagnosis Cycle
2.5.8 Tools Method
2.5.9 The USE Method
2.5.10 Workload Characterization
2.5.11 Drill-Down Analysis
2.5.12 Latency Analysis
2.5.13 Method R
2.5.14 Event Tracing
2.5.15 Baseline Statistics
2.5.16 Static Performance Tuning
2.5.17 Cache Tuning
2.5.18 Micro-Benchmarking
2.6 Modeling
2.6.1 Enterprise versus Cloud
2.6.2 Visual Identification
2.6.3 Amdahl’s Law of Scalability
2.6.4 Universal Scalability Law
2.6.5 Queueing Theory
2.7 Capacity Planning
2.7.1 Resource Limits
2.7.2 Factor Analysis
2.7.3 Scaling Solutions
2.8 Statistics
2.8.1 Quantifying Performance
2.8.2 Averages
2.8.3 Standard Deviations, Percentiles, Median
2.8.4 Coefficient of Variation
2.8.5 Multimodal Distributions
2.8.6 Outliers
2.9 Monitoring
2.9.1 Time-Based Patterns
2.9.2 Monitoring Products
2.9.3 Summary-since-Boot
2.10 Visualizations
2.10.1 Line Chart
2.10.2 Scatter Plots
2.10.3 Heat Maps
2.10.4 Surface Plot
2.10.5 Visualization Tools
2.11 Exercises
2.12 References
3 Operating Systems
3.1 Terminology
3.2 Background
3.2.1 Kernel
3.2.2 Stacks
3.2.3 Interrupts and Interrupt Threads
3.2.4 Interrupt Priority Level
3.2.5 Processes
3.2.6 System Calls
3.2.7 Virtual Memory
3.2.8 Memory Management
3.2.9 Schedulers
3.2.10 File Systems
3.2.11 Caching
3.2.12 Networking
3.2.13 Device Drivers
3.2.14 Multiprocessor
3.2.15 Preemption
3.2.16 Resource Management
3.2.17 Observability
3.3 Kernels
3.3.1 Unix
3.3.2 Solaris-Based
3.3.3 Linux-Based
3.3.4 Differences
3.4 Exercises
3.5 References
4 Observability Tools
4.1 Tool Types
4.1.1 Counters
4.1.2 Tracing
4.1.3 Profiling
4.1.4 Monitoring (sar)
4.2 Observability Sources
4.2.1 /proc
4.2.2 /sys
4.2.3 kstat
4.2.4 Delay Accounting
4.2.5 Microstate Accounting
4.2.6 Other Observability Sources
4.3 DTrace
4.3.1 Static and Dynamic Tracing
4.3.2 Probes
4.3.3 Providers
4.3.4 Arguments
4.3.5 D Language
4.3.6 Built-in Variables
4.3.7 Actions
4.3.8 Variable Types
4.3.9 One-Liners
4.3.10 Scripting
4.3.11 Overheads
4.3.12 Documentation and Resources
4.4 SystemTap
4.4.1 Probes
4.4.2 Tapsets
4.4.3 Actions and Built-ins
4.4.4 Examples
4.4.5 Overheads
4.4.6 Documentation and Resources
4.5 perf
4.6 Observing Observability
4.7 Exercises
4.8 References
5 Applications
5.1 Application Basics
5.1.1 Objectives
5.1.2 Optimize the Common Case
5.1.3 Observability
5.1.4 Big O Notation
5.2 Application Performance Techniques
5.2.1 Selecting an I/O Size
5.2.2 Caching
5.2.3 Buffering
5.2.4 Polling
5.2.5 Concurrency and Parallelism
5.2.6 Non-Blocking I/O
5.2.7 Processor Binding
5.3 Programming Languages
5.3.1 Compiled Languages
5.3.2 Interpreted Languages
5.3.3 Virtual Machines
5.3.4 Garbage Collection
5.4 Methodology and Analysis
5.4.1 Thread State Analysis
5.4.2 CPU Profiling
5.4.3 Syscall Analysis
5.4.4 I/O Profiling
5.4.5 Workload Characterization
5.4.6 USE Method
5.4.7 Drill-Down Analysis
5.4.8 Lock Analysis
5.4.9 Static Performance Tuning
5.5 Exercises
5.6 References
6 CPUs
6.1 Terminology
6.2 Models
6.2.1 CPU Architecture
6.2.2 CPU Memory Caches
6.2.3 CPU Run Queues
6.3 Concepts
6.3.1 Clock Rate
6.3.2 Instruction
6.3.3 Instruction Pipeline
6.3.4 Instruction Width
6.3.5 CPI, IPC
6.3.6 Utilization
6.3.7 User-Time/Kernel-Time
6.3.8 Saturation
6.3.9 Preemption
6.3.10 Priority Inversion
6.3.11 Multiprocess, Multithreading
6.3.12 Word Size
6.3.13 Compiler Optimization
6.4 Architecture
6.4.1 Hardware
6.4.2 Software
6.5 Methodology
6.5.1 Tools Method
6.5.2 USE Method
6.5.3 Workload Characterization
6.5.4 Profiling
6.5.5 Cycle Analysis
6.5.6 Performance Monitoring
6.5.7 Static Performance Tuning
6.5.8 Priority Tuning
6.5.9 Resource Controls
6.5.10 CPU Binding
6.5.11 Micro-Benchmarking
6.5.12 Scaling
6.6 Analysis
6.6.1 uptime
6.6.2 vmstat
6.6.3 mpstat
6.6.4 sar
6.6.5 ps
6.6.6 top
6.6.7 prstat
6.6.8 pidstat
6.6.9 time, ptime
6.6.10 DTrace
6.6.11 SystemTap
6.6.12 perf
6.6.13 cpustat
6.6.14 Other Tools
6.6.15 Visualizations
6.7 Experimentation
6.7.1 Ad Hoc
6.7.2 SysBench
6.8 Tuning
6.8.1 Compiler Options
6.8.2 Scheduling Priority and Class
6.8.3 Scheduler Options
6.8.4 Process Binding
6.8.5 Exclusive CPU Sets
6.8.6 Resource Controls
6.8.7 Processor Options (BIOS Tuning)
6.9 Exercises
6.10 References
7 Memory
7.1 Terminology
7.2 Concepts
7.2.1 Virtual Memory
7.2.2 Paging
7.2.3 Demand Paging
7.2.4 Overcommit
7.2.5 Swapping
7.2.6 File System Cache Usage
7.2.7 Utilization and Saturation
7.2.8 Allocators
7.2.9 Word Size
7.3 Architecture
7.3.1 Hardware
7.3.2 Software
7.3.3 Process Address Space
7.4 Methodology
7.4.1 Tools Method
7.4.2 USE Method
7.4.3 Characterizing Usage
7.4.4 Cycle Analysis
7.4.5 Performance Monitoring
7.4.6 Leak Detection
7.4.7 Static Performance Tuning
7.4.8 Resource Controls
7.4.9 Micro-Benchmarking
7.5 Analysis
7.5.1 vmstat
7.5.2 sar
7.5.3 slabtop
7.5.4 ::kmastat
7.5.5 ps
7.5.6 top
7.5.7 prstat
7.5.8 pmap
7.5.9 DTrace
7.5.10 SystemTap
7.5.11 Other Tools
7.6 Tuning
7.6.1 Tunable Parameters
7.6.2 Multiple Page Sizes
7.6.3 Allocators
7.6.4 Resource Controls
7.7 Exercises
7.8 References
8 File Systems
8.1 Terminology
8.2 Models
8.2.1 File System Interfaces
8.2.2 File System Cache
8.2.3 Second-Level Cache
8.3 Concepts
8.3.1 File System Latency
8.3.2 Caching
8.3.3 Random versus Sequential I/O
8.3.4 Prefetch
8.3.5 Read-Ahead
8.3.6 Write-Back Caching
8.3.7 Synchronous Writes
8.3.8 Raw and Direct I/O
8.3.9 Non-Blocking I/O
8.3.10 Memory-Mapped Files
8.3.11 Metadata
8.3.12 Logical versus Physical I/O
8.3.13 Operations Are Not Equal
8.3.14 Special File Systems
8.3.15 Access Timestamps
8.3.16 Capacity
8.4 Architecture
8.4.1 File System I/O Stack
8.4.2 VFS
8.4.3 File System Caches
8.4.4 File System Features
8.4.5 File System Types
8.4.6 Volumes and Pools
8.5 Methodology
8.5.1 Disk Analysis
8.5.2 Latency Analysis
8.5.3 Workload Characterization
8.5.4 Performance Monitoring
8.5.5 Event Tracing
8.5.6 Static Performance Tuning
8.5.7 Cache Tuning
8.5.8 Workload Separation
8.5.9 Memory-Based File Systems
8.5.10 Micro-Benchmarking
8.6 Analysis
8.6.1 vfsstat
8.6.2 fsstat
8.6.3 strace, truss
8.6.4 DTrace
8.6.5 SystemTap
8.6.6 LatencyTOP
8.6.7 free
8.6.8 top
8.6.9 vmstat
8.6.10 sar
8.6.11 slabtop
8.6.12 mdb ::kmastat
8.6.13 fcachestat
8.6.14 /proc/meminfo
8.6.15 mdb ::memstat
8.6.16 kstat
8.6.17 Other Tools
8.6.18 Visualizations
8.7 Experimentation
8.7.1 Ad Hoc
8.7.2 Micro-Benchmark Tools
8.7.3 Cache Flushing
8.8 Tuning
8.8.1 Application Calls
8.8.2 ext3
8.8.3 ZFS
8.9 Exercises
8.10 References
9 Disks
9.1 Terminology
9.2 Models
9.2.1 Simple Disk
9.2.2 Caching Disk
9.2.3 Controller
9.3 Concepts
9.3.1 Measuring Time
9.3.2 Time Scales
9.3.3 Caching
9.3.4 Random versus Sequential I/O
9.3.5 Read/Write Ratio
9.3.6 I/O Size
9.3.7 IOPS Are Not Equal
9.3.8 Non-Data-Transfer Disk Commands
9.3.9 Utilization
9.3.10 Saturation
9.3.11 I/O Wait
9.3.12 Synchronous versus Asynchronous
9.3.13 Disk versus Application I/O
9.4 Architecture
9.4.1 Disk Types
9.4.2 Interfaces
9.4.3 Storage Types
9.4.4 Operating System Disk I/O Stack
9.5 Methodology
9.5.1 Tools Method
9.5.2 USE Method
9.5.3 Performance Monitoring
9.5.4 Workload Characterization
9.5.5 Latency Analysis
9.5.6 Event Tracing
9.5.7 Static Performance Tuning
9.5.8 Cache Tuning
9.5.9 Resource Controls
9.5.10 Micro-Benchmarking
9.5.11 Scaling
9.6 Analysis
9.6.1 iostat
9.6.2 sar
9.6.3 pidstat
9.6.4 DTrace
9.6.5 SystemTap
9.6.6 perf
9.6.7 iotop
9.6.8 iosnoop
9.6.9 blktrace
9.6.10 MegaCli
9.6.11 smartctl
9.6.12 Visualizations
9.7 Experimentation
9.7.1 Ad Hoc
9.7.2 Custom Load Generators
9.7.3 Micro-Benchmark Tools
9.7.4 Random Read Example
9.8 Tuning
9.8.1 Operating System Tunables
9.8.2 Disk Device Tunables
9.8.3 Disk Controller Tunables
9.9 Exercises
9.10 References
10 Network
10.1 Terminology
10.2 Models
10.2.1 Network Interface
10.2.2 Controller
10.2.3 Protocol Stack
10.3 Concepts
10.3.1 Networks and Routing
10.3.2 Protocols
10.3.3 Encapsulation
10.3.4 Packet Size
10.3.5 Latency
10.3.6 Buffering
10.3.7 Connection Backlog
10.3.8 Interface Negotiation
10.3.9 Utilization
10.3.10 Local Connections
10.4 Architecture
10.4.1 Protocols
10.4.2 Hardware
10.4.3 Software
10.5 Methodology
10.5.1 Tools Method
10.5.2 USE Method
10.5.3 Workload Characterization
10.5.4 Latency Analysis
10.5.5 Performance Monitoring
10.5.6 Packet Sniffing
10.5.7 TCP Analysis
10.5.8 Drill-Down Analysis
10.5.9 Static Performance Tuning
10.5.10 Resource Controls
10.5.11 Micro-Benchmarking
10.6 Analysis
10.6.1 netstat
10.6.2 sar
10.6.3 ifconfig
10.6.4 ip
10.6.5 nicstat
10.6.6 dladm
10.6.7 ping
10.6.8 traceroute
10.6.9 pathchar
10.6.10 tcpdump
10.6.11 snoop
10.6.12 Wireshark
10.6.13 DTrace
10.6.14 SystemTap
10.6.15 perf
10.6.16 Other Tools
10.7 Experimentation
10.7.1 iperf
10.8 Tuning
10.8.1 Linux
10.8.2 Solaris
10.8.3 Configuration
10.9 Exercises
10.10 References
11 Cloud Computing
11.1 Background
11.1.1 Price/Performance Ratio
11.1.2 Scalable Architecture
11.1.3 Capacity Planning
11.1.4 Storage
11.1.5 Multitenancy
11.2 OS Virtualization
11.2.1 Overhead
11.2.2 Resource Controls
11.2.3 Observability
11.3 Hardware Virtualization
11.3.1 Overhead
11.3.2 Resource Controls
11.3.3 Observability
11.4 Comparisons
11.5 Exercises
11.6 References
12 Benchmarking
12.1 Background
12.1.1 Activities
12.1.2 Effective Benchmarking
12.1.3 Benchmarking Sins
12.2 Benchmarking Types
12.2.1 Micro-Benchmarking
12.2.2 Simulation
12.2.3 Replay
12.2.4 Industry Standards
12.3 Methodology
12.3.1 Passive Benchmarking
12.3.2 Active Benchmarking
12.3.3 CPU Profiling
12.3.4 USE Method
12.3.5 Workload Characterization
12.3.6 Custom Benchmarks
12.3.7 Ramping Load
12.3.8 Sanity Check
12.3.9 Statistical Analysis
12.4 Benchmark Questions
12.5 Exercises
12.6 References
13 Case Study
13.1 Case Study: The Red Whale
13.1.1 Problem Statement
13.1.2 Support
13.1.3 Getting Started
13.1.4 Choose Your Own Adventure
13.1.5 The USE Method
13.1.6 Are We Done?
13.1.7 Take 2
13.1.8 The Basics
13.1.9 Ignoring the Red Whale
13.1.10 Interrogating the Kernel</p>
<h1><a class="header" href="#sql-explain" id="sql-explain">SQL Explain</a></h1>
<h2><a class="header" href="#understanding-explains-output" id="understanding-explains-output">Understanding EXPLAIN’s Output</a></h2>
<p>For every select, subselect or join EXPLAIN will output one row with
information how the data for this part of the query will be retrieved if you
execute the query.</p>
<p>To get real performance data the query caching has been disabled using
<code>SET SESSION query_cache_type = OFF</code></p>
<p>The columns returned by the query are:</p>
<pre><code>  id
    a sequential identifier for each SELECT within the query
    (for when you have nested subqueries)
  select_type
    the type of SELECT query. Possible values are:
      SIMPLE
      – the query is a simple SELECT query without any subqueries or UNIONs
      PRIMARY
      – the SELECT is in the outermost query in a JOIN
      DERIVED
      – the SELECT is part of a subquery within a FROM clause
      SUBQUERY
      – the first SELECT in a subquery
      DEPENDENT SUBQUERY
      – a subquery which is dependent upon on outer query
      UNCACHEABLE SUBQUERY
      – a subquery which is not cacheable
        (there are certain conditions for a query to be cacheable)
      UNION
      – the SELECT is the second or later statement of a UNION
      DEPENDENT UNION
      – the second or later SELECT of a UNION is dependent on an outer query
      UNION RESULT
      – the SELECT is a result of a UNION
  table
    the table referred to by the row
  type
    how MySQL joins the tables used.
    This is one of the most insightful fields in the output because it can
    indicate missing indexes or how the query is written should be reconsidered.
    Possible values are:
      system          - the table has only zero or one row
      const           - the table has only one matching row which is indexed.
                        This is the fastest type of join because the table only
                        has to be read once and the column’s value can be treated
                        as a constant when joining other tables.
      eq_ref          - all parts of an index are used by the join and the index
                        is PRIMARY KEY or UNIQUE NOT NULL.
                        This is the next best possible join type.
      ref             - all of the matching rows of an indexed column are read for each
                        combination of rows from the previous table.
                        This type of join appears for indexed columns compared using =
                        or &lt;=&gt; operators.
      fulltext        - the join uses the table’s FULLTEXT index.
      ref_or_null     - this is the same as ref but also contains rows with a
                        null value for the column.
      index_merge     – the join uses a list of indexes to produce the result set.
                        The key column of EXPLAIN‘s output will contain the keys used.
      unique_subquery – an IN subquery returns only one result from the table and
                        makes use of the primary key.
      index_subquery  – the same as unique_subquery but returns more than one
                        result row.
      range           – an index is used to find matching rows in a specific
                        range, typically when the key column is compared to a
                        constant using operators like BETWEEN, IN, &gt;, &gt;=, etc.
      index           – the entire index tree is scanned to find matching rows.
      all             – the entire table is scanned to find matching rows for
                        the join.
                        This is the worst join type and usually indicates the
                        lack of appropriate indexes on the table.
  possible_keys
    shows the keys that can be used by MySQL to find rows from the table,
    though they may or may not be used in practice.
    In fact, this column can often help in optimizing queries since if the
    column is NULL, it indicates no relevant indexes could be found.
  key
    indicates the actual index used by MySQL.
    key=null means that no key was used to retrieve the data
    This column may contain an index that is not listed in the possible_key column.
    MySQL optimizer always look for an optimal key that can be used for the query.
    While joining many tables, it may figure out some other keys which is not
    listed in possible_key but are more optimal.
    To force MySQL to use or ignore an index listed in the possible_keys column,
    use FORCE INDEX, USE INDEX, or IGNORE INDEX in your query
  key_len
    indicates the length of the index the Query Optimizer chose to use.
    For example, a key_len value of 4 means it requires memory to store four
    characters. Check out MySQL’s data type storage requirements to know more
    about this.
  ref
    Shows the columns or constants that are compared to the index named in the
    key column  to select rows from the table.
    MySQL will either pick a constant value to be compared or a column itself
    based on the query execution plan.
  rows
    lists the number of records that were examined to produce the output.
    In an ideal case rows should be equal with the number of results you expect.
    This Is another important column worth focusing on optimizing queries,
    especially for queries that use JOIN and subqueries.
  Extra
    contains additional information regarding the query execution plan.
    Values such as “Using temporary”, “Using filesort”, etc. in this column may
    indicate a troublesome query.
    For a complete list of possible values and their meaning,
    check out the MySQL documentation.
    http://dev.mysql.com/doc/refman/5.6/en/explain-output.html#explain-extra-information

* EXTRA COLUMN

  * Using Filesort
    Anytime a sort can’t be performed from an index, it’s a filesort.
    It has nothing to do with files. Filesort should be called “sort.”
    If the sort is bigger than the sort buffer, it is performed a bit at a time,
    and then the chunks are merge-sorted to produce the final sorted output.
    There is a lot more to it than this.
    http://s.petrunia.net/blog/?p=24

* GETTING INFORMATION

  use information_schema;
  SELECT * FROM statistics;

  SHOW INDEX FROM mytable FROM mydb;
</code></pre>
<h1><a class="header" href="#climate-modeling" id="climate-modeling">Climate Modeling</a></h1>
<p>With the focus of the world on climate change, researchers have been developing
models with increasingly higher resolution and ever-greater integration of
critical factors such as sea ice and clouds. Key to these modeling efforts has
been the dramatic advance in computer power. This power has also enabled much
longer simulations—from months to centuries. And over the next few decades,
computers are expected to speed up by a factor of a million. One might well ask,
as Dr. David Randall has, &quot;What are we going to do with that next million?&quot; His
answer: &quot;Run global cloud-resolving models,&quot; or GCRMs, that can be used for both
numerical weather prediction and climate simulation. To this end, Dr. Randall
and his team are developing a new global nonhydrostatic dynamical core based on
a geodesic grid and suitable for use with grid spacings ranging from meters to
hundreds of kilometers (figure 3). The geodesic grid has the advantage that all
grid cells on the sphere are very nearly the same size, with the largest cells
only about 5% larger in area than the smallest, thereby avoiding the problem of
computational stability for advection. Moreover, contrary to popular belief, the
geodesic grid does permit researchers to construct schemes of arbitrary higher-
order accuracy; indeed, Dr. Randall's group has already used third-order-
accurate finite-difference schemes. Components of the GCRM are being tested on
the Cray XT4 at NERSC, and a high-resolution kernel of the model has exhibited
good scaling performance on 10,000 processors.</p>
<p>Continued improvement of climate models also requires evaluation of their
parameterizations, for instance for processes driven by subgrid features such as
soil characteristics, vegetation, and land use. Dr. Rao Kotamarthi and his team
of researchers at Argonne National Laboratory (ANL) and the University of
Chicago are exploring the use of &quot;data ensembles&quot; generated through multiple
runs to interpolate sparsely located surface measurements into a uniform spatial
grid, thereby providing estimates of mean values over the entire domain
containing the measurement sites. The method has been used successfully for
interpolating surface sensible heat flux data from 14 sites within the DOE
Atmospheric Radiation Measurement (ARM) program. The researchers next plan to
address other measured parameters, many of which require at least a 10 year time
series—some at one-minute intervals. The computational challenge is enormous:
for example, at the 1 km resolution, there are approximately 100,000
interpolated locations and 99 simulations of the full time series at each
location. To meet this challenge, Kotamarthi and his colleagues plan to use the
Common Component Architecture—a component-based approach, supported by the DOE, in which units of software are encapsulated as components that interact with other components through well-defined interfaces.</p>
<h2><a class="header" href="#groundwater-modeling" id="groundwater-modeling">Groundwater Modeling</a></h2>
<p>One of the most challenging problems in environmental remediation involves
hazardous materials that have leached into the subsurface and may be more widely dispersed by groundwater to sensitive water resource areas such as rivers and lakes. As part of the SciDAC groundwater science application area, researchers
are developing new techniques to simulate radionuclide transport, in particular
uranium, at the DOE Hanford 300 Area in the state of Washington. The task is
complicated by the fact that the Hanford Unit is highly permeable and the
groundwater has the potential of flowing rapidly with very small pressure
gradients in the aquifer. This situation is further aggravated by the rapid
fluctuations in the Columbia River, which produce changes, not only in magnitude
but also in the flow direction. Uranium is leaching very slowly from the Hanford
sediment governed by diffusive mass transfer, at levels that exceed the EPA
maximum permissible concentration, prolonging its presence. Dr. Peter C.
Lichtner is leading a multi-institutional SciDAC team whose members are
developing a multiphase, multicomponent code called PFLOTRAN to simulate the
variably saturated groundwater flow and reactive transport of uranium at the
site. PFLOTRAN is based on a domain decomposition approach in which the
computational problem is divided into subdomains, with one domain assigned to
each processor. The Argonne-developed toolkit PETSc is used as a parallel
framework for solvers and message passing within PFLOTRAN. According to Dr.
Lichtner, &quot;PETSc hides the communication from the user, thus allowing the
application scientist to focus on the science (physics and chemistry in this
case) rather than worry about the solvers and preconditioners needed.&quot; PFLOTRAN
has already been run on a one-billion-node problem—an important proof of concept for petascale computing—and has been demonstrated to scale to 27,580 processor cores on the Jaguar XT3 Cray at Oak Ridge National Laboratory (ORNL).</p>
<h2><a class="header" href="#a-climate-modelling-primer" id="a-climate-modelling-primer">A Climate Modelling Primer</a></h2>
<ul>
<li>1 Climate
<ul>
<li>1.1 The components of climate</li>
<li>1.2 Climate change assessment</li>
<li>1.3 Climate forcings</li>
<li>1.4 Climate feedbacks and sensitivity</li>
<li>1.5 Range of questions for climate modelling</li>
</ul>
</li>
<li>2 A history of and introduction to climate models
<ul>
<li>2.1 Introducing climate modelling</li>
<li>2.2 Types of climate models</li>
<li>2.3 History of climate modelling</li>
<li>2.4 Sensitivity of climate models</li>
<li>2.5 Parameterization climate processes</li>
<li>2.6 Simulation of the full, interacting climate system: one goal of modelling</li>
</ul>
</li>
<li>3 Energy balance models
<ul>
<li>3.1 Balancing the planetary radiation budget</li>
<li>3.2 The structure of energy balance models</li>
<li>3.3 Parameterizing the climate system for energy balance models</li>
<li>3.4 A baic energy balance climate model</li>
<li>3.5 Energy balance models and glacial cycles</li>
<li>3.6 Box models - another form of energy balance models</li>
<li>3.7 Energy balance models: deceptively simple models</li>
</ul>
</li>
<li>4 Computationally efficient models
<ul>
<li>4.1 Why lower complexity?</li>
<li>4.2 One-dimensional radiative-convective models</li>
<li>4.3 Radiation: the driver of climate</li>
<li>4.4 Convective adjustment</li>
<li>4.5 Sensitivity experiments with radiative-convective models</li>
<li>4.6 Development of radiative-convective models</li>
<li>4.7 Two-dimensional statistical dynamical climate models</li>
<li>4.8 Other types of copmutationally efficient models</li>
<li>4.9 Why are some climate modellers flatlanders?</li>
</ul>
</li>
<li>5 General circulation climate models
<ul>
<li>5.1 Three-dimensional models of the climate system</li>
<li>5.2 Atmospheric general circulation models</li>
<li>5.3 Modelling the ocean circulation</li>
<li>5.4 Modelling the cryosphere</li>
<li>5.5 Incorporating vegatation</li>
<li>5.6 Coupling models: towards the AOBGCM</li>
<li>5.7 Using GCMs</li>
</ul>
</li>
<li>6 Evaluation and exploitation of climate models
<ul>
<li>6.1 Evaluation of climate models</li>
<li>6.2 Exploitation of climate model predictions</li>
<li>6.3 Integrated assessment models</li>
<li>6.4 The future of climate modelling</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#do-you-believe-in-magic" id="do-you-believe-in-magic">Do you believe in magic?</a></h1>
<h5><a class="header" href="#black-art-n" id="black-art-n">black art: n.</a></h5>
<blockquote>
<p>[common] A collection of arcane, unpublished, and (by implication) mostly ad-hoc techniques developed for a particular application or systems area (compare black magic). VLSI design and compiler code optimization were (in their beginnings) considered classic examples of black art; as theory developed they became deep magic, and once standard textbooks had been written, became merely heavy wizardry. The huge proliferation of formal and informal channels for spreading around new computer-related technologies during the last twenty years has made both the term black art and what it describes less common than formerly. See also voodoo programming.</p>
</blockquote>
<h5><a class="header" href="#black-magic-n" id="black-magic-n">black magic: n.</a></h5>
<blockquote>
<p>[common] A technique that works, though nobody really understands why. More obscure than voodoo programming, which may be done by cookbook. Compare also black art, deep magic, and magic number (sense 2).</p>
</blockquote>
<h5><a class="header" href="#voodoo-programming-n" id="voodoo-programming-n">voodoo programming: n.</a></h5>
<blockquote>
<p>[from George Bush Sr.'s “voodoo economics”]</p>
<ol>
<li>The use by guess or cookbook of an obscure or hairy system, feature, or algorithm that one does not truly understand. The implication is that the technique may not work, and if it doesn't, one will never know why. Almost synonymous with black magic, except that black magic typically isn't documented and nobody understands it. Compare magic, deep magic, heavy wizardry, rain dance, cargo cult programming, wave a dead chicken, SCSI voodoo.</li>
<li>Things programmers do that they know shouldn't work but they try anyway, and which sometimes actually work, such as recompiling everything.</li>
</ol>
</blockquote>
<h5><a class="header" href="#magic" id="magic">magic</a></h5>
<blockquote>
<ol>
<li>adj. As yet unexplained, or too complicated to explain; compare automagically and (Arthur C.) Clarke's Third Law: “Any sufficiently advanced technology is indistinguishable from magic.” “TTY echoing is controlled by a large number of magic bits.” “This routine magically computes the parity of an 8-bit byte in three instructions.”</li>
<li>adj. Characteristic of something that works although no one really understands why (this is especially called black magic).</li>
<li>n. [Stanford] A feature not generally publicized that allows something otherwise impossible, or a feature formerly in that category but now unveiled.</li>
<li>n. The ultimate goal of all engineering &amp; development, elegance in the extreme; from the first corollary to Clarke's Third Law: “Any technology distinguishable from magic is insufficiently advanced”.</li>
</ol>
</blockquote>
<blockquote>
<p>Parodies playing on these senses of the term abound; some have made their way into serious documentation, as when a MAGIC directive was described in the Control Card Reference for GCOS c.1978. For more about hackish ‘magic’, see Appendix A. Compare black magic, wizardly, deep magic, heavy wizardry.</p>
</blockquote>
<h5><a class="header" href="#wave-a-dead-chicken-v" id="wave-a-dead-chicken-v">wave a dead chicken: v.</a></h5>
<blockquote>
<p>To perform a ritual in the direction of crashed software or hardware that one believes to be futile but is nevertheless necessary so that others are satisfied that an appropriate degree of effort has been expended. “I'll wave a dead chicken over the source code, but I really think we've run into an OS bug.” Compare voodoo programming, rain dance; see also casting the runes.</p>
</blockquote>
<h5><a class="header" href="#deep-magic-n" id="deep-magic-n">deep magic: n.</a></h5>
<blockquote>
<p>[poss. from C. S. Lewis's Narnia books] An awesomely arcane technique central to a program or system, esp. one neither generally published nor available to hackers at large (compare black art); one that could only have been composed by a true wizard. Compiler optimization techniques and many aspects of OS design used to be deep magic; many techniques in cryptography, signal processing, graphics, and AI still are. Compare heavy wizardry. Esp.: found in comments of the form “Deep magic begins here...”. Compare voodoo programming.</p>
</blockquote>
<h5><a class="header" href="#heavy-wizardry-n" id="heavy-wizardry-n">heavy wizardry: n.</a></h5>
<blockquote>
<p>Code or designs that trade on a particularly intimate knowledge or experience of a particular operating system or language or complex application interface. Distinguished from deep magic, which trades more on arcane theoretical knowledge. Writing device drivers is heavy wizardry; so is interfacing to X (sense 2) without a toolkit. Esp.: found in source-code comments of the form “Heavy wizardry begins here”. Compare voodoo programming.</p>
</blockquote>
<h5><a class="header" href="#rain-dance-n" id="rain-dance-n">rain dance: n.</a></h5>
<blockquote>
<ol>
<li>Any ceremonial action taken to correct a hardware problem, with the expectation that nothing will be accomplished. This especially applies to reseating printed circuit boards, reconnecting cables, etc. “I can't boot up the machine. We'll have to wait for Greg to do his rain dance.”</li>
<li>Any arcane sequence of actions performed with computers or software in order to achieve some goal; the term is usually restricted to rituals that include both an incantation or two and physical activity or motion. Compare magic, voodoo programming, black art, cargo cult programming, wave a dead chicken; see also casting the runes.</li>
</ol>
</blockquote>
<h5><a class="header" href="#incantation-n" id="incantation-n">incantation: n.</a></h5>
<blockquote>
<p>Any particularly arbitrary or obscure command that one must mutter at a system to attain a desired result. Not used of passwords or other explicit security features. Especially used of tricks that are so poorly documented that they must be learned from a wizard. “This compiler normally locates initialized data in the data segment, but if you mutter the right incantation they will be forced into text space.”</p>
</blockquote>
<h5><a class="header" href="#wizard-n" id="wizard-n">wizard: n.</a></h5>
<blockquote>
<ol>
<li>Transitively, a person who knows how a complex piece of software or hardware works (that is, who groks it); esp. someone who can find and fix bugs quickly in an emergency. Someone is a hacker if he or she has general hacking ability, but is a wizard with respect to something only if he or she has specific detailed knowledge of that thing. A good hacker could become a wizard for something given the time to study it.</li>
<li>The term ‘wizard’ is also used intransitively of someone who has extremely high-level hacking or problem-solving ability.</li>
<li>A person who is permitted to do things forbidden to ordinary people; one who has wheel privileges on a system.</li>
<li>A Unix expert, esp. a Unix systems programmer. This usage is well enough established that ‘Unix Wizard’ is a recognized job title at some corporations and to most headhunters.
See guru, lord high fixer. See also deep magic, heavy wizardry, incantation, magic, mutter, rain dance, voodoo programming, wave a dead chicken.</li>
</ol>
</blockquote>
<h5><a class="header" href="#guru-n" id="guru-n">guru: n.</a></h5>
<blockquote>
<p>[Unix] An expert. Implies not only wizard skill but also a history of being a knowledge resource for others. Less often, used (with a qualifier) for other experts on other systems, as in VMS guru. See source of all good bits.</p>
</blockquote>
<h5><a class="header" href="#mutter-vt" id="mutter-vt">mutter: vt.</a></h5>
<blockquote>
<p>To quietly enter a command not meant for the ears, eyes, or fingers of ordinary mortals. Often used in “mutter an incantation”. See also wizard.</p>
</blockquote>
<h5><a class="header" href="#wheel-n" id="wheel-n">wheel: n.</a></h5>
<blockquote>
<p>[from slang ‘big wheel’ for a powerful person] A person who has an active wheel bit. “We need to find a wheel to unwedge the hung tape drives.” (See wedged, sense 1.) The traditional name of security group zero in BSD (to which the major system-internal users like root belong) is ‘wheel’. Some vendors have expanded on this usage, modifying Unix so that only members of group ‘wheel’ can go root.</p>
</blockquote>
<h5><a class="header" href="#cargo-cult-programming-n" id="cargo-cult-programming-n">cargo cult programming: n.</a></h5>
<blockquote>
<p>A style of (incompetent) programming dominated by ritual inclusion of code or program structures that serve no real purpose. A cargo cult programmer will usually explain the extra code as a way of working around some bug encountered in the past, but usually neither the bug nor the reason the code apparently avoided the bug was ever fully understood (compare shotgun debugging, voodoo programming).
The term ‘cargo cult’ is a reference to aboriginal religions that grew up in the South Pacific after World War II. The practices of these cults center on building elaborate mockups of airplanes and military style landing strips in the hope of bringing the return of the god-like airplanes that brought such marvelous cargo during the war. Hackish usage probably derives from Richard Feynman's characterization of certain practices as “cargo cult science” in his book Surely You're Joking, Mr. Feynman! (W. W. Norton &amp; Co, New York 1985, ISBN 0-393-01921-7).</p>
</blockquote>
<h5><a class="header" href="#obscure-adj" id="obscure-adj">obscure: adj.</a></h5>
<blockquote>
<p>Used in an exaggeration of its normal meaning, to imply total incomprehensibility. “The reason for that last crash is obscure.” “The find(1) command's syntax is obscure!” The phrase moderately obscure implies that something could be figured out but probably isn't worth the trouble. The construction obscure in the extreme is the preferred emphatic form.</p>
</blockquote>
<h1><a class="header" href="#quotes" id="quotes">Quotes</a></h1>
<blockquote>
<p>Walking on water and developing software from a specification are easy if both
are frozen. -- Edward V Berard</p>
</blockquote>
<blockquote>
<p>Hofstadter's Law: It always takes longer than you expect, even when you take
into account Hofstadter's Law.</p>
</blockquote>
<blockquote>
<p>Debugging is twice as hard as writing the code in the first
place. Therefore, if you write the code as cleverly as possible, you are, by
definition, not smart enough to debug it. -- Brian Kernighan</p>
</blockquote>
<blockquote>
<p>The idea that I can be presented with a problem, set out to logically solve it
with the tools at hand, and wind up with a program that could not be legally
used because someone else followed the same logical steps some years ago and
filed for a patent on it is horrifying. - John Carmack on software patents</p>
</blockquote>
<blockquote>
<p>&quot;Some people, when confronted with a problem, think &quot;I know, I’ll use regular
expressions.&quot; Now they have two problems.&quot; -- Jamie Zawinski</p>
</blockquote>
<blockquote>
<p>&quot;In order to understand recursion, one must first understand recursion.&quot;</p>
</blockquote>
<blockquote>
<p>On two occasions I have been asked [by members of Parliament], 'Pray, Mr.
Babbage, if you put into the machine wrong figures, will the right answers come
out?' I am not able rightly to apprehend the kind of confusion of ideas that
could provoke such a question. -- Charles Babbage</p>
</blockquote>
<blockquote>
<p>If debugging is the process of removing software bugs, then programming must be the process of putting them in. -- Edsger Dijkstra</p>
</blockquote>
<blockquote>
<p>Computer Science is no more about computers than astronomy is about telescopes. -- E. W. Dijkstra</p>
</blockquote>
<blockquote>
<p>Perfection is achieved, not when there is nothing more to add, but when there is
nothing left to take away. -- Antoine de Saint Exupéry</p>
</blockquote>
<blockquote>
<p>Debuggers don't remove bugs. They only show them in slow motion.</p>
</blockquote>
<blockquote>
<p>&quot;The trouble with programmers is that you can never tell what a programmer is
doing until it's too late.&quot; -- Seymour Cray</p>
</blockquote>
<blockquote>
<p>There are two ways of constructing a software design: One way is to make it so
simple that there are obviously no deficiencies, and the other way is to make it
so complicated that there are no obvious deficiencies. The first method is far
more difficult. -- C.A.R. Hoare</p>
</blockquote>
<blockquote>
<p>Beware of bugs in the above code; I have only proved it correct, not tried it. -- Donald Knuth</p>
</blockquote>
<blockquote>
<p>&quot;Weeks of coding can save you hours of planning.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;My definition of an expert in any field is a person who knows enough about
what's really going on to be scared.&quot; -- P. J. Plauger, Computer Language, March
1983</p>
</blockquote>
<blockquote>
<p>&quot;An expert is a man who has made all the mistakes that can be made in a very
narrow field&quot; -- Niels Bohr</p>
</blockquote>
<blockquote>
<p>Programs must be written for people to read, and only incidentally for machines
to execute. -- SICP</p>
</blockquote>
<blockquote>
<p>Any fool can write code that a computer can understand. Good programmers write code that humans can understand.</p>
</blockquote>
<blockquote>
<p>Theory is when you know something, but it doesn't work. Practice is when
something works, but you don't know why. Programmers combine theory and
practice: Nothing works and they don't know why.</p>
</blockquote>
<blockquote>
<p>We better hurry up and start coding, there are going to be a lot of bugs to fix.</p>
</blockquote>
<blockquote>
<p>&quot;Computer science education cannot make anybody an expert programmer any more than studying brushes and pigment can make somebody an expert painter.&quot; -- Eric Raymond</p>
</blockquote>
<blockquote>
<p>The generation of random numbers is too important to be left to chance.
Robert R. Coveyou, Oak Ridge National Laboratory</p>
</blockquote>
<blockquote>
<p>The only &quot;intuitive&quot; interface is the nipple. After that it's all learned. --Bruce Ediger</p>
</blockquote>
<blockquote>
<p>&quot;When art critics get together they talk about Form and Structure and Meaning.
When artists get together they talk about where you can buy cheap turpentine.&quot; 
-- Pablo Picasso</p>
</blockquote>
<blockquote>
<p>A good programmer looks both ways before crossing a one-way street.</p>
</blockquote>
<blockquote>
<p>It is easier to optimize correct code than to correct optimized code.</p>
</blockquote>
<blockquote>
<p>From a bit to a few hundred megabytes, from a microsecond to a half an hour of
computing confronts us with completely baffling ratio of 109! The programmer is
in the unique position that his is the only discipline and profession in which
such a gigantic ratio, which totally baffles our imagination, has to be bridged
by a single technology. He has to be able to think in terms of conceptual
hierarchies that are much deeper than a single mind ever needed to face before.
— E.W. Dijkstra</p>
</blockquote>
<blockquote>
<p>One man's constant is another man's variable.
Functions delay binding: data structures induce binding. Moral: Structure data late in the programming process.
Syntactic sugar causes cancer of the semi-colons.
Every program is a part of some other program and rarely fits.
If a program manipulates a large amount of data, it does so in a small number of ways.
Symmetry is a complexity reducing concept (co-routines include sub-routines); seek it everywhere.
It is easier to write an incorrect program than understand a correct one.
A programming language is low level when its programs require attention to the irrelevant.
It is better to have 100 functions operate on one data structure than 10 functions on 10 data
structures.
Get into a rut early: Do the same processes the same way. Accumulate idioms. Standardize. The only difference (!) between Shakespeare and you was the size of his idiom list - not the size of his vocabulary.
If you have a procedure with 10 parameters, you probably missed some.
Recursion is the root of computation since it trades description for time.
If two people write exactly the same program, each should be put in micro-code and then they
certainly won't be the same.
In the long run every program becomes rococo - then rubble.
Everything should be built top-down, except the first time.
Every program has (at least) two purposes: the one for which it was written and another for which it wasn't.
If a listener nods his head when you're explaining your program, wake him up.
A program without a loop and a structured variable isn't worth writing.
A language that doesn't affect the way you think about programming, is not worth knowing.
Wherever there is modularity there is the potential for misunderstanding: Hiding information
implies a need to check communication.
Optimization hinders evolution.
A good system can't have a weak command language.
To understand a program you must become both the machine and the program.
Perhaps if we wrote programs from childhood on, as adults we'd be able to read them.
One can only display complex information in the mind. Like seeing, movement or flow
or alteration of view is more important than the static picture, no matter how lovely.
There will always be things we wish to say in our programs that in all known languages can only be said poorly.
Once you understand how to write a program get someone else to write it.
Around computers it is difficult to find the correct unit of time to measure progress. Some
cathedrals took a century to complete. Can you imagine the grandeur and scope of a program that would take as long?
For systems, the analogue of a face-lift is to add to the control graph an edge that creates a cycle, not just an additional node.
In programming, everything we do is a special case of something more general - and often we know it too quickly.
Simplicity does not precede complexity, but follows it.
Programmers are not to be measured by their ingenuity and their logic but by the completeness of their case analysis.
The 11th commandment was &quot;Thou Shalt Compute&quot; or &quot;Thou Shalt Not Compute&quot; - I forget which.
The string is a stark data structure and everywhere it is passed there is much duplication of process. It is a perfect vehicle for hiding information.
Everyone can be taught to sculpt: Michelangelo would have had to be taught how not to. So it is with the great programmers.
The use of a program to prove the 4-color theorem will not change mathematics - it merely
demonstrates that the theorem, a challenge for a century, is probably not important to mathematics.
The most important computer is the one that rages in our skulls and ever seeks that satisfactory
external emulator. The standardization of real computers would be a disaster - and so it probably won't happen.
Structured Programming supports the law of the excluded muddle.
Re graphics: A picture is worth 10K words - but only those to describe the picture. Hardly any
sets of 10K words can be adequately described with pictures.
There are two ways to write error-free programs; only the third one works.
Some programming languages manage to absorb change, but withstand progress.
You can measure a programmer's perspective by noting his attitude on the continuing vitality of FORTRAN.
In software systems it is often the early bird that makes the worm.
Sometimes I think the only universal in the computing field is the fetch-execute-cycle.
The goal of computation is the emulation of our synthetic abilities, not the understanding of our
analytic ones.
Like punning, programming is a play on words.
As Will Rogers would have said, &quot;There is no such thing as a free variable.&quot;
The best book on programming for the layman is &quot;Alice in Wonderland&quot;; but that's because it's
the best book on anything for the layman.
Giving up on assembly language was the apple in our Garden of Eden: Languages whose use
squanders machine cycles are sinful. The LISP machine now permits LISP programmers to abandon bra and fig-leaf.
When we understand knowledge-based systems, it will be as before - except our finger-tips will
have been singed.
Bringing computers into the home won't change either one, but may revitalize the corner saloon.
Systems have sub-systems and sub-systems have sub-systems and so on ad infinitum - which is
why we're always starting over.
So many good ideas are never heard from again once they embark in a voyage on the semantic gulf.
Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.
A LISP programmer knows the value of everything, but the cost of nothing.
Software is under a constant tension. Being symbolic it is arbitrarily perfectible; but also it is arbitrarily changeable.
It is easier to change the specification to fit the program than vice versa.
Fools ignore complexity. Pragmatists suffer it. Some can avoid it. Geniuses remove it.
In English every word can be verbed. Would that it were so in our programming languages.
Dana Scott is the Church of the Lattice-Way Saints.
In programming, as in everything else, to be in error is to be reborn.
In computing, invariants are ephemeral.
When we write programs that &quot;learn&quot;, it turns out we do and they don't.
Often it is means that justify ends: Goals advance technique and technique survives even when
goal structures crumble.
Make no mistake about it: Computers process numbers - not symbols. We measure our understanding (and control) by the extent to which we can arithmetize an activity.
Making something variable is easy. Controlling duration of constancy is the trick.
Think of all the psychic energy expended in seeking a fundamental distinction between &quot;algorithm&quot; and &quot;program&quot;.
If we believe in data structures, we must believe in independent (hence simultaneous) processing. For why else would we collect items within a structure? Why do we tolerate languages that give us the one without the other?
In a 5 year period we get one superb programming language. Only we can't control when the
5 year period will begin.
Over the centuries the Indians developed sign language for communicating phenomena of interest. Programmers from different tribes (FORTRAN, LISP, ALGOL, SNOBOL, etc.) could use one that doesn't require them to carry a blackboard on their ponies.
Documentation is like term insurance: It satisfies because almost no one who subscribes to it depends on its benefits.
An adequate bootstrap is a contradiction in terms.
It is not a language's weaknesses but its strengths that control the gradient of its change: Alas, a language never escapes its embryonic sac.
It is possible that software is not like anything else, that it is meant to be discarded: that the whole point is to always see it as soap bubble?
Because of its vitality, the computing field is always in desperate need of new cliches: Banality
soothes our nerves.
It is the user who should parameterize procedures, not their creators.
The cybernetic exchange between man, computer and algorithm is like a game of musical chairs: The frantic search for balance always leaves one of the three standing ill at ease.
If your computer speaks English it was probably made in Japan.
A year spent in artificial intelligence is enough to make one believe in God.
Prolonged contact with the computer turns mathematicians into clerks and vice versa.
In computing, turning the obvious into the useful is a living definition of the word &quot;frustration&quot;.
We are on the verge: Today our program proved Fermat's next-to-last theorem!
What is the difference between a Turing machine and the modern computer? It's the same as that between Hillary's ascent of Everest and the establishment of a Hilton hotel on its peak.
Motto for a research laboratory: What we work on today, others will first think of tomorrow.
Though the Chinese should adore APL, it's FORTRAN they put their money on.
We kid ourselves if we think that the ratio of procedure to data in an active data-base system can be made arbitrarily small or even kept small.
We have the mini and the micro computer. In what semantic niche would the pico computer fall?
It is not the computer's fault that Maxwell's equations are not adequate to design the electric motor.
One does not learn computing by using a hand calculator, but one can forget arithmetic.
Computation has made the tree flower.
The computer reminds one of Lon Chaney - it is the machine of a thousand faces.
The computer is the ultimate polluter. Its feces are indistinguishable from the food it produces.
When someone says &quot;I want a programming language in which I need only say what I wish done,&quot; give him a lollipop.
Interfaces keep things tidy, but don't accelerate growth: Functions do.
Don't have good ideas if you aren't willing to be responsible for them.
Computers don't introduce order anywhere as much as they expose opportunities.
When a professor insists computer science is X but not Y, have compassion for his graduate students.
In computing, the mean time to failure keeps getting shorter.
In man-machine symbiosis, it is man who must adjust: The machines can't.
We will never run out of things to program as long as there is a single program around.
Dealing with failure is easy: Work hard to improve. Success is also easy to handle: You've solved the wrong problem. Work hard to improve.
One can't proceed from the informal to the formal by formal means.
Purely applicative languages are poorly applicable.
The proof of a system's value is its existence.
You can't communicate complexity, only an awareness of it.
It's difficult to extract sense from strings, but they're the only communication coin we can count on.
The debate rages on: Is PL/I Bactrian or Dromedary?
Whenever two programmers meet to criticize their programs, both are silent.
Think of it! With VLSI we can pack 100 ENIACs in 1 sq.cm.
Editing is a rewording activity.
Why did the Roman Empire collapse? What is the Latin for office automation?
Computer Science is embarrassed by the computer.
The only constructive theory connecting neuroscience and psychology will arise from the study of software.
Within a computer natural language is unnatural.
Most people find the concept of programming obvious, but the doing impossible.
You think you know when you learn, are more sure when you can write, even more when you can teach, but certain when you can program.
It goes against the grain of modern education to teach children to program. What fun is there in
making plans, acquiring discipline in organizing thoughts, devoting attention to detail and learning to be self-critical?
If you can imagine a society in which the computer-robot is the only menial, you can imagine
anything.
Programming is an unnatural act.
Adapting old programs to fit new machines usually means adapting new machines to behave like old ones.
In seeking the unattainable, simplicity only gets in the way.
by Alan J. Perlis, Yale University.
This text has been published in SIGPLAN Notices Vol. 17, No. 9, September 1982, pages 7 - 13.</p>
</blockquote>
<h1><a class="header" href="#the-philosophy-of-unix" id="the-philosophy-of-unix">The Philosophy of UNIX</a></h1>
<ul>
<li><strong>Rule of Simplicity</strong>: Developers should design for simplicity by looking for ways to break up program systems into small, straightforward cooperating pieces. This rule aims to discourage developers’ affection for writing “intricate and beautiful complexities” that are in reality bug prone programs.</li>
<li><strong>Rule of Parsimony</strong>: Developers should avoid writing big programs. This rule aims to prevent overinvestment of development time in failed or suboptimal approaches caused by the owners of the program’s reluctance to throw away visibly large pieces of work. Smaller programs are not only easier to optimize and maintain; they are easier to delete when deprecated.</li>
<li><strong>Rule of Transparency</strong>: Developers should design for visibility and discoverability by writing in a way that their thought process can lucidly be seen by future developers working on the project and using input and output formats that make it easy to identify valid input and correct output. This rule aims to reduce debugging time and extend the lifespan of programs.</li>
<li><strong>Rule of Robustness</strong>: Developers should design robust programs by designing for transparency and discoverability, because code that is easy to understand is easier stress test for unexpected conditions that may not be foreseeable in complex programs. This rule aims to help developers build robust, reliable products.</li>
<li>Rule of Representation: Developers should choose to make data more complicated rather than the procedural logic of the program when faced with the choice, because it is easier for humans to understand complex data compared with complex logic. This rule aims to make programs more readable for any developer working on the project, which allows the program to be maintained.</li>
<li><strong>Rule of Least Surprise</strong>: Developers should design programs that build on top of the potentials users' expected knowledge; for example, ‘+’ should always mean addition in a calculator program. This rule aims to encourage developers to build intuitive products that are easy to use.</li>
<li><strong>Rule of Silence</strong>: Developers should design programs so that they do not print unnecessary output. This rule aims to allows other programs and developers to pick out the information they need from a program's output without having to parse verbosity.</li>
<li><strong>Rule of Repair</strong>: Developers should design programs that fail in a manner that is easy to localize and diagnose or in other words “fail noisily”. This rule aims to prevent incorrect output from a program from becoming an input and corrupting the output of other code undetected.</li>
<li><strong>Rule of Economy</strong>: Developers should value developer time over machine time, because machine cycles as of the year 2013 are relatively inexpensive compared to prices in the 1970s. This rule aims to reduce development costs of projects.</li>
<li><strong>Rule of Generation</strong>: Developers should avoid writing code by hand and instead write abstract high-level programs that generate code. This rule aims to reduce humans errors and save time.</li>
<li><strong>Rule of Optimization</strong>: Developers should prototype software before polishing it. This rule aims to prevent developers from spending too much time for marginal gains.</li>
<li><strong>Rule of Diversity</strong>: Developers should design their programs to be flexible and open. This rule aims to make programs flexible, allowing them to be used in other ways than their developers intended.</li>
<li><strong>Rule of Extensibility</strong>: Developers should design for the future by making their protocols extensible, allowing for easy plugins without modification to the program's architecture by other developers, noting the version of the program, and more. This rule aims to extend the lifespan and enhance the utility of the code the developer writes.</li>
</ul>
<h2><a class="header" href="#mike-gancarz-the-unix-philosophy" id="mike-gancarz-the-unix-philosophy">Mike Gancarz: The UNIX Philosophy</a></h2>
<ul>
<li>Small is beautiful.</li>
<li>Make each program do one thing well.</li>
<li>Build a prototype as soon as possible.</li>
<li>Choose portability over efficiency.</li>
<li>Store data in flat text files.</li>
<li>Use software leverage to your advantage.</li>
<li>Use shell scripts to increase leverage and portability.</li>
<li>Avoid captive user interfaces.</li>
<li>Make every program a filter.</li>
</ul>
<h1><a class="header" href="#the-ten-rules-of-a-zen-programmer" id="the-ten-rules-of-a-zen-programmer">The Ten Rules of a Zen Programmer</a></h1>
<p>By Christian Grobmeier</p>
<h2><a class="header" href="#focus" id="focus">Focus</a></h2>
<p>If you have decided to work on a task, do it as well as you can. Don’t start
multiple things at the same time. Do only one thing at one time. You won’t
become faster or better, you’ll just spread yourself too thin. If you work too
much you’ll become exhausted, make more errors and lose time jumping from one
task to another. This is not only about programming; this is a general tip.</p>
<p>Kôdô Sawaki says: if you need to sleep, sleep. Don’t plan your software when you
are trying to sleep. Just sleep. If you code, code. Don’t daydream—code. If you
are so tired that you cannot program, sleep. Even known multitaskers like
Stephan Uhrenbacher have decided to work singlethreaded. I had a similar
experience to Stephan, when I finally wrote Time &amp; Bill, a time tracking tool.
My goal was to track my time so easily that I could do it even for small tasks
like a phone call. Now I can create a few stopwatches at the beginning of the
day and track my time with only one click. In the beginning it was a disaster:
sometimes I just worked a few minutes on a task until I moved on to the next
one. Now I am better. Similar to the Pomodoro technique I plan a few time slots
and concentrate on them. No chatting, no sleeping, no checking out a great new
game in the Appstore.</p>
<h2><a class="header" href="#keep-your-mind-clear" id="keep-your-mind-clear">Keep Your Mind Clear</a></h2>
<p>Before you work on your software, you need to clean up your mind. Throw away
everything in your mind for the time being. If you have trouble with something,
don’t let it influence you. In most cases that trouble will go away. If the
trouble is so much that you can’t let it go, don’t work. Try to clean things up.
But when you start working, let the outer world melt away.</p>
<p>Something exciting on the mailing list? Leave it there. You can follow the
exciting stuff later. Shutdown what fills your mind with shit: close Twitter,
Facebook, your emails. You should even mute your phone and leave it in your
pocket. You could say it is similar to item 1, focus. But there is one more
restriction: don’t use these tools before work or at lunch. They connect you
with the outer world and bring up some new trouble or things which require you
attention.</p>
<p>Think like this: at most times your mind is pretty clear when you wake up at the
morning. If it is not, doing some sports helps (I do long-distance running). If
you feel clean and refreshed, go to work and work as well as you can. When you
leave your work then you can fill up your mind with clutter. You’ll see it is
not so much fun if you have a full working day behind you. Twitter and Co. are
consuming much of your energy. Don’t think it just takes a minute. It doesn’t.</p>
<p>You know it’s true.</p>
<h2><a class="header" href="#beginners-mind" id="beginners-mind">Beginner’s Mind</a></h2>
<p>Remember the days when you were a beginner or if you are still a beginner, hold
on to that feeling. You have never learned enough. If you are already an expert,
think of yourself as though you were a beginner every day. Always try to see
technologies from a beginner’s mind. You can accept corrections to your software
better and leave the standard path if you need to more easily. There are some
good ideas even from people who don’t have your experience. Was there ever a
software built twice the same way? Even if you copy software it is somehow
different.</p>
<h2><a class="header" href="#no-ego" id="no-ego">No Ego</a></h2>
<p>Some programmers have a huge problem: their own ego. But there is no time for
developing an ego. There is no time for being a rockstar.</p>
<p>Who is it who decides your quality as programmer? You? No. Others? Probably. But
can you really compare apples and bananas? No. You are an individual. You cannot
compare your whole self with another human being. You can only compare a few
facets.</p>
<p>A skill is nothing you can be proud of. You are good at Java? Cool. Someone else
is not as good as you, but better at bowling. Is Java more important than
bowling? It depends on the situation. You probably earn more money with Java,
but the other guy might have more fun in life because of his bowling friends.</p>
<p>Can you really be proud that you are a geek? Programmers with ego don’t learn.
Learn from everybody, from the experienced and from the noobs at the same time.</p>
<p>Kôdô Sawaki once said: “You are not important.”</p>
<p>Think about it.</p>
<h2><a class="header" href="#there-is-no-career-goal" id="there-is-no-career-goal">There Is No Career Goal</a></h2>
<p>If you want to gain something and don’t care about your life “now”, you have
already lost the game. Just act as well as you can, without looking at the goal
you might reach after a long time.</p>
<p>Working for twenty years to become the partner of a company? Why aren’t you
working as hard as possible just because it is fun? Hard work can be fun. “A day
without work is a day without food” is a Zen saying.</p>
<p>There is no need to start being happy after twenty years. You can be happy right
now, even if you aren’t a partner or don’t drive a Porsche. Things change too
easily. You can get sick. You can get fired. You can burn out (if you follow all
these items I guess the likeliness is low).</p>
<p>Unless these bad things happen, just work as well as you can and have fun doing
it. No reason to look at the gains of your colleagues. No reason to think about
the cool new position which you didn’t get.</p>
<p>After all, you will achieve something. You’ll end up with nice memories, maybe a
good position—and twenty excellent years. Every day is a good day.</p>
<p>If you ever come to the point where you think that working at your company is no
fun at all you must leave immediately. NEVER stay at a company which takes away
the happiness in your life. Of course, this is only possible in rich countries,
where people have the choice to go away. But if you are living in such an good
environment, do it. Go away without regret. You have no time to waste, you could
be dead tomorrow.</p>
<p>When you have no career goal, going away is easy.</p>
<h2><a class="header" href="#shut-up" id="shut-up">Shut Up</a></h2>
<p>If you don’t have anything to say, don’t waste the time of your colleagues. This
doesn’t make you look wimpy. Every day you work you need to try not to get on
someone else’s nerves. Imagine if everybody would try this—what a great working
place would that be? Sometimes it is not possible. Try hard, you will like it.</p>
<p>If you don’t develop an ego it is pretty easy to shut up and care only for the
things you can talk about. Don’t mix up your ego with your “experience” and
always remember: you are a beginner. If somebody has a good idea, support the
idea.</p>
<h2><a class="header" href="#mindfulness-care-awareness" id="mindfulness-care-awareness">Mindfulness. Care. Awareness.</a></h2>
<p>Yes, you are working. But at the same time you are living and breathing. Even
when you have some hard times at work you need to listen to the signs of your
body. You need to learn about the things which are good for you. This includes
everything, including basic things like food. You need to care for yourself and
for everything in your environment—because after all, the water you drink is the
water which runs in the river. You are living only for yourself. You live alone
and you’ll die alone. The world goes on even without you.</p>
<p>Avoid working in situations you don’t like. Avoid working for free if it means
you will have no fun and keeps you away from your bed. Let go what doesn’t make
you happy. Do you think people only work for free in theory? Consider the people
doing Open Source in their free time. If you have subscribed to some project’s
mailing list you probably know what conflict there is (sometimes). If you don’t
have fun with it, stop doing it. I know a bunch of people who work in an Open
Source environment they don’t like. Again with Time &amp; Bill I tracked the time I
spent in Open Source projects and was surprised how much time I lost
there—especially on projects I didn’t like so much.</p>
<p>Keeping this in mind, some people think they are only happy when they have free
time and can spend the evening with an Xbox and some beer. While this is a good
idea from time to time, it is not necessary that every moment in your life is
“fun”. If you can avoid situations you don’t like, avoid them. But sometimes
there is need to do something really shitty. For example, manually copy/pasting
stuff from your manager’s Excel spreadsheet into phpmyadmin. This can take you
days, and it is really boring. It is no fun, but sometimes you need to do such
stuff. You cannot always quit your job when you get a boring task. Zen Monks do
not shy from their work either. They get up at 3am (sometimes earlier, sometimes
later, depends on the convent) and start meditation and work (they even consider
work meditation practice). They have stuff to do like cleaning the toilets. Or
working in the garden. Or as a Tenzo, they cook. They do it with all the care
they can muster. Whatever they do, they do it without suffering and they are (or
should be) happy, because every second, even the moments where they are cleaning
toilets, is a second of their life.</p>
<p>That being said: stop whining if you need to copy/paste Excel. Just do it. Don’t
waste your energy with such things; they will pass. Become the best Excel
copy/paster out there instead.</p>
<p>If you suffer a heart attack, people will probably say: “Uh yes, he really was a
hard worker—he even worked for me for free at night”. Nobody can guide you to
the other world. This last step is taken by us alone. You cannot exchange
anything in this world. Not even a fart. So it is up to you to take care, every
second. If you die, you die. But when you live, you live. There is no time to
waste.</p>
<p>“Care” is a huge word in Zen Buddhism (and I think in every form of Buddhism). I
cannot express everything which needs to be said. it is difficult to understand
the different meanings of “care”. You are probably better off with the word
“awareness”. You must be aware of what you do, in every second of your life. You
must be mindful in your life. Otherwise you waste it. But, of course, it is up
to you to do so, if you like.</p>
<h2><a class="header" href="#there-is-no-boss" id="there-is-no-boss">There Is No Boss</a></h2>
<p>Yes, there is somebody who pays you. There is somebody who tells you what needs
to be done. And he can fire you. But this is no reason to give up your own life
or to become sick of your work. Finally, your boss has no control over you. It
can even be doubted that you have control over you—but don’t go down this path.</p>
<p>Back to your boss: he can make your life worse if you allow him to do so. But
there is a way out. Say “No” if you need to do something which makes you sick or
is against your ethics. What will happen? Worst case scenario he will fire you.
So what? If you live in Western nations and if you are a coder (which is very
likely if you are reading this) you’ll get another job.</p>
<p>I don’t mean say “No” to tasks like copying CSV Data to HTML. I am speaking of
eighty-hour weeks and feeling your body break down. Or feeling that your kids
need some attention too. Or if you are forced to fire people just because your
boss doesn’t like them. Or if you are a consultant and get the job to develop
software for nuclear plants (some might say it is perfectly fine to work for
nuclear power companies— it is against my ethics and serves as an example) or
for tanks. You can say “No”.</p>
<h2><a class="header" href="#do-something-else" id="do-something-else">Do Something Else</a></h2>
<p>A programmer is more than a programmer. You should do something which has
nothing to do with computers. In your free time, go sailing, fishing, diving. Do
meditation, martial arts. Play Shakuhachi. Whatever you do, do it with all the
power you have left. Like you do in your work time. Do it seriously. A hobby is
not just a hobby, it’s an expression of who you are. Don’t let anybody fool you,
when they say hobbies are not important. Nowadays we can afford having hobbies.
I have recorded several CDs and wrote fantasy books (the latter one unpublished,
I must practice more). These things have made me the person I am now, and
finally they have led me to Zen and this book. These days I practice Zen
Shakuhachi. It is a very important aspect of my daily life.</p>
<h2><a class="header" href="#there-is-nothing-special" id="there-is-nothing-special">There Is Nothing Special</a></h2>
<p>A flower is beauty. But it’s just a beautiful flower—nothing more. There is
nothing special about it. You are a human who can program. Maybe you are good.
There is nothing special about you. You are of the same stuff as I am and all
the others on this planet.</p>
<p>You need to go to the toilet and you need to eat. Of course you need to sleep.
After (hopefully) a long time you will die and everything you have created will
be lost. Even pyramids get lost, after a long time. Do you know the names of the
people who built them? If you do, is it important that you know? It’s not.
Pyramids are there, or they aren’t. Nothing special.</p>
<p>Same goes for your software. The bank is earning money with your software. After
you leave, nobody remembers you. There is nothing wrong about that. It is the
flow of time. Nothing you should be worried about it. If you are following the
first nine rules, you’ll see that this last project was a good and fun project.
Now it’s simply time to go on and concentrate on something else.</p>
<p>If your company closes because of financial problems, no problem. Life will go
on. There is no real need for an Xbox, a car, or something else. Most people on
this planet live in deepest poverty. They don’t care for an Xbox because they
would be glad to get some food or even water.</p>
<p>So… why exactly are you special? Because you had the luck to be born in a
Western country? Because you can code? No, there is nothing special about it.
You can let go of your ego and live freely. Enjoy the colors and the smell of
flowers. Don’t be too sad when the winter arrives and don’t be too happy when
spring comes back. It is just a flow. Keep it in mind when somebody denies your
application. Because no company is so special that you need to be worried about
the job.</p>
<h1><a class="header" href="#the-zen-of-python" id="the-zen-of-python">The Zen of Python</a></h1>
<ul>
<li>Beautiful is better than ugly.</li>
<li>Explicit is better than implicit.</li>
<li>Simple is better than complex.</li>
<li>Complex is better than complicated.</li>
<li>Flat is better than nested.</li>
<li>Sparse is better than dense.</li>
<li>Readability counts.</li>
<li>Special cases aren't special enough to break the rules.</li>
<li>Although practicality beats purity.</li>
<li>Errors should never pass silently.</li>
<li>Unless explicitly silenced.</li>
<li>In the face of ambiguity, refuse the temptation to guess.</li>
<li>There should be one-- and preferably only one --obvious way to do it.</li>
<li>Although that way may not be obvious at first unless you're Dutch.</li>
<li>Now is better than never.</li>
<li>Although never is often better than <em>right</em> now.</li>
<li>If the implementation is hard to explain, it's a bad idea.</li>
<li>If the implementation is easy to explain, it may be a good idea.</li>
<li>Namespaces are one honking great idea -- let's do more of those!</li>
</ul>
<h1><a class="header" href="#euskera" id="euskera">Euskera</a></h1>
<h1><a class="header" href="#habe" id="habe">HABE</a></h1>
<p><strong>HEOC</strong>: <strong>H</strong>elduen <strong>E</strong>uskalduntzearen <strong>O</strong>inarrizko <strong>C</strong>urriculuma</p>
<blockquote>
<ul>
<li>Plan de estudios básico para estudios vascos de adultos
<ul>
<li><em>helduen</em>: adulto</li>
<li><em>euskalduntzearen</em>: adquisición del idioma vasco</li>
<li><em>oinarrizko</em>: basico</li>
</ul>
</li>
</ul>
</blockquote>
<table><thead><tr><th>Helduen Euskalduntzearen Mailak</th><th> Niveles de estudios vascos en adultos</th></tr></thead><tbody>
<tr><td> <strong>Oinarrizko erabiltzailea</strong></td><td> <strong>Usuario básico</strong></td></tr>
<tr><td>A1: Hasierako erabiltzailea</td><td>A1: Usuario inicial</td></tr>
<tr><td>A2: Oinarrizko erabiltzailea</td><td>A2: Usuario básico</td></tr>
<tr><td><strong>Erabiltzailea aurreratua</strong></td><td><strong>Usuario avanzado</strong></td></tr>
<tr><td>B1: Erabiltzaile independentea</td><td>B1: Usuario independiente             </td></tr>
<tr><td>B2: Erabiltzaile aurreratua</td><td>B2: Usuario avanzado                  </td></tr>
<tr><td><strong>Erabiltzaile aditua</strong></td><td><strong>Usuario experto</strong></td></tr>
<tr><td>C1: Erabiltzaile gaitua</td><td>C1: Usuario habilitado                </td></tr>
<tr><td>C2: Erabiltzaile aditua</td><td>C2: Usuario experto                   </td></tr>
</tbody></table>
<h2><a class="header" href="#oinarrizko-lerruna-a1--a2-oinarrizko-erabiltzailea" id="oinarrizko-lerruna-a1--a2-oinarrizko-erabiltzailea">Oinarrizko lerruna (A1 + A2): Oinarrizko erabiltzailea</a></h2>
<p>Oinarrizko lerrun honen xedea honako hau da: ikasleak eguneroko gaiei buruzko euskarazko testu laburrak ulertzea, eta ahoz zein idatziz —baina gehienbat ahoz— euskara elkarreraginean erabiltzea, labur eta sinple, baina egoki eta eraginkor.</p>
<blockquote>
<p>El objetivo de este escalafón básico es que los estudiantes comprendan textos breves en euskera sobre temas cotidianos y utilicen el euskera oralmente y por escrito, pero principalmente oralmente, en euskera interactivo, corto y simple, pero apropiado y efectivo.</p>
</blockquote>
<h2><a class="header" href="#lerrun-aurreratua-b1--b2-erabiltzaile-aurreratua" id="lerrun-aurreratua-b1--b2-erabiltzaile-aurreratua">Lerrun aurreratua (B1 + B2): Erabiltzaile aurreratua</a></h2>
<p>Lerrun aurreratuaren xedea honako hau da: ikasleak ohiko testuinguru, gai eta egoera ezagunetan instrukzioak, kontaketa laburrak eta azalpen-testuak ulertzea, eta, ahoz zein idatziz, euskara zehaztasunez eta eraginkortasunez erabiltzea.</p>
<blockquote>
<p>El objetivo del escalafon avanzado es que los estudiantes comprendan instrucciones, cuentos y textos explicativos en contextos, temas y situaciones familiares, y que utilicen el euskera con precisión y eficacia, tanto oralmente como por escrito.</p>
</blockquote>
<p>Xede ere izango da ikasleak elkarreraginean, bere lan-esparruko gaiei buruz, alderdi esanguratsuak eta xehetasunak bereiziz, deskribapenak egitea eta azalpenak eta iritziak eraginkortasunez ematea.</p>
<blockquote>
<p>El objetivo también será que los estudiantes interactúen, describan los aspectos y detalles relevantes, hagan descripciones efectivas y proporcionen explicaciones y opiniones.</p>
</blockquote>
<h2><a class="header" href="#adituaren-lerruna-c1--c2-erabiltzaile-aditua" id="adituaren-lerruna-c1--c2-erabiltzaile-aditua">Adituaren lerruna (C1 + C2): Erabiltzaile aditua</a></h2>
<p>Adituaren lerrunaren xedea honako hau da: eremu profesional, publiko zein pertsonalean ikasleak era guztietako informazioa euskaraz trukatzeko gai izatea era landu eta jantzian, ahoz zein idatziz, gaia, solaskidearen jarrera edota euren arteko harreman maila zeinahi delarik, hizkuntza-adierazleak estrategikoki erabiliz eta hizkeraren maila denotatiboa eta konnotatiboa bereiziz.</p>
<blockquote>
<p>El objetivo del escalafón de expertos es permitir a los estudiantes en las esferas profesional, pública y personal intercambiar todo tipo de información en euskera en la práctica y vestimenta, oralmente o por escrito, el tema, la actitud del interlocutor o su nivel de relación, utilizando indicadores estratégicos de idioma y nivel de idioma. distinguiendo entre denotativo y connotativo.</p>
</blockquote>
<h2><a class="header" href="#galderak" id="galderak">Galderak</a></h2>
<h3><a class="header" href="#1-zer-berrikuntza-dakar-heocak" id="1-zer-berrikuntza-dakar-heocak">1. Zer berrikuntza dakar HEOCak?</a></h3>
<blockquote>
<p>¿Qué innovación trae HEOC?</p>
</blockquote>
<p>Ikaslea euskararen erabiltzaile izatea du helburu nagusi; horretako, ikaslearen autonomia eta erabilera-estrategiak sustatzeko proposamenak egiten ditu.</p>
<blockquote>
<p>El objetivo principal del alumno es ser un usuario de euskera; propone promover la autonomía del alumno y utilizar estrategias.</p>
</blockquote>
<p>Ikasprozesua sei mailatan zedarritzen da eta hamaika azpimailatan egituratzen.</p>
<blockquote>
<p>El proceso de aprendizaje se divide en seis niveles y se estructura en once subcategorías.</p>
</blockquote>
<h3><a class="header" href="#2-nola-jakin-dezaket-zein-den-nire-maila-edo-azpimaila" id="2-nola-jakin-dezaket-zein-den-nire-maila-edo-azpimaila">2. Nola jakin dezaket zein den nire maila edo azpimaila?</a></h3>
<blockquote>
<p>¿Cómo sé cuál es mi rango o subnivel?</p>
</blockquote>
<p>Euskaltegian izena ematen duzunean, trebetasun guztietan duzun gaitasun komunikatiboa aztertuko du irakasleak, azterketa diagnostiko baten bidez:</p>
<ul>
<li>Zer eta zenbat ulertzen duzun entzutean eta irakurtzean.</li>
<li>Zer egiteko gai zaren idaztean eta hitz egitean.</li>
</ul>
<blockquote>
<p>Cuando te registres en el centro de estudios, el profesor analizará tu competencia comunicativa en todas las habilidades, a través de un examen de diagnóstico:</p>
<ul>
<li>Qué y cuánto entiendes al escuchar y leer.</li>
<li>Lo que puedes hacer al escribir y hablar.</li>
</ul>
</blockquote>
<p>Hizkuntza-maila zein den ongi zehazteko, lau trebetasunetan duzun gaitasun komunikatiboa hartuko da oinarri;
horren arabera finkatuko baitzazu abiapuntua (zein maila edo azpimailatan hasiko zaren) eta helburua (zein maila edo azpimailatan) lortu behar duzun.</p>
<blockquote>
<p>Para determinar el nivel de dominio del idioma, se basará su competencia comunicativa en las cuatro habilidades;
dependiendo de cuál establezca el punto de partida (qué nivel o subnivel comenzará) y la meta (qué nivel o subnivel) debe alcanzar.</p>
</blockquote>
<h3><a class="header" href="#3-zeren-arabera-zehaztuko-zait-helburu-maila" id="3-zeren-arabera-zehaztuko-zait-helburu-maila">3. Zeren arabera zehaztuko zait helburu-maila?</a></h3>
<blockquote>
<p>¿Cuál es el nivel objetivo para mí?</p>
</blockquote>
<p>Zure abiapuntua kontuan hartuz, ikastaroaren ezaugarri eta baldintzen arabera zehaztuko zaizu, betiere, helbururik lorgarrienaren bila.</p>
<blockquote>
<p>Dependiendo de su punto de partida, estará determinado por las características y condiciones del curso, siempre y cuando busque el objetivo más alcanzable.</p>
</blockquote>
<p>Azpimailak ere helburu izan daitezke. Abiapuntua zein duzun ikusita, dituzun aukera eta ikastaroaren ezaugarrien arabera, zehaztuko zaizu helburua.</p>
<blockquote>
<p>Los subniveles tambien pueden ser objetivos. Dependiendo de su punto de partida, opciones y características del curso, se determinará su objetivo.</p>
</blockquote>
<h3><a class="header" href="#4-zer-dira-ikastereduak" id="4-zer-dira-ikastereduak">4. Zer dira ikastereduak?</a></h3>
<blockquote>
<p>¿Qué se les enseña?</p>
</blockquote>
<p>HEOCak hiru ikasteredu aurreikusten ditu:</p>
<ul>
<li>Aurrez aurrekoa, taldean irakaslearekin.</li>
<li>Autoikaskuntza: ordenagailuz egiten diren ikastaroak.</li>
<li>Jardun bikoa: aurrez aurreko jardunak eta autoikaskuntza, elkarren osagarri.</li>
</ul>
<blockquote>
<p>El HEOC prevé tres cursos:</p>
<ul>
<li>Anteriormente, con el profesor en el grupo.</li>
<li>Autoestudio: cursos basados en computadora.</li>
<li>Doble acción: actividades presenciales y autoinstrucción, complementarias entre sí.</li>
</ul>
</blockquote>
<h3><a class="header" href="#5-nola-uztartu-orain-arteko-eta-oraingo-ikasbidea" id="5-nola-uztartu-orain-arteko-eta-oraingo-ikasbidea">5. Nola uztartu orain arteko eta oraingo ikasbidea?</a></h3>
<blockquote>
<ul>
<li>uztartu: combinar</li>
<li>orain arteko: hasta aqui</li>
<li>ikasbidea: metodo de aprendizaje</li>
<li>oraingo ikasbidea: metodo de aprendizaje actual</li>
</ul>
</blockquote>
<table><thead><tr><th>Mailak</th><th>Azpimailak</th><th>Urratsa</th></tr></thead><tbody>
<tr><td>A1 maila</td><td>A1</td><td>+/- 1-2</td></tr>
<tr><td>A2 maila</td><td>A2.1</td><td>+/- 2-3</td></tr>
<tr><td>A2 maila</td><td>A2.2</td><td>+/- 3-4</td></tr>
<tr><td>B1 maila</td><td>B1.1</td><td>+/- 4-5</td></tr>
<tr><td>B1 maila</td><td>B1.2</td><td>+/- 6</td></tr>
<tr><td>B2 maila</td><td>B2.1</td><td>+/- 7-8</td></tr>
<tr><td>B2 maila</td><td>B2.2</td><td>+/- 9</td></tr>
<tr><td>C1 maila</td><td>C1.1</td><td>+/- 10-11</td></tr>
<tr><td>C1 maila</td><td>C1.2</td><td>+/- 12</td></tr>
<tr><td>C2 maila</td><td>C2.1</td><td></td></tr>
<tr><td>C2 maila</td><td>C2.2</td><td></td></tr>
</tbody></table>
<p>Oharra: urratsen sailkapena hizkuntza-edukien araberakoa zen, eta egungo maila eta azpimailen sailkapena, berriz, gaitasunn komunikatiboaren araberakoa.</p>
<blockquote>
<p>Nota: La clasificación de los pasos depende del contenido del idioma, y del nivel actual y la clasificación de los subtipos, en función de la competencia comunicativa.</p>
</blockquote>
<h1><a class="header" href="#a1-hasierako-erabiltzailea" id="a1-hasierako-erabiltzailea">A1: Hasierako erabiltzailea</a></h1>
<blockquote>
<p>A1: Usuario inicial</p>
</blockquote>
<p>Gai da eguneroko harremanetan eta aurrez aurreko testuinguru ezagunetan beharrezkoak diren hitzak eta esapide sinpleak ulertzeko eta erabiltzeko, baita berehalako premiei lotutako galderei erantzuteko ere (bere buruaren eta besteren aurkezpena, eta ezagutzen duen jendeari, haien helbideei eta gauzei buruzko oinarrizko informazioa).</p>
<blockquote>
<p>Al finalizar este nivel, el alumno sera capaz de comprender y utilizar palabras y expresiones sencillas en sus relaciones cotidianas, en contextos que le sean conocidos, haciendo frente a situaciones relacionadas con necesidades inmediatas (presentarse a si mismo y a otros, indicar su direccion, ofrecer informacion basica sobre objetos y personas conocidas).</p>
</blockquote>
<p>A1 Hasierako erabiltzailearen maila lortzeko, 125 irakastorduko prozesua aurreikusten da, betiere ikaslearen abiapuntua kontuan izanik.
Horiez gain, ikasleak bakarlanean eta erabilera askean beste 75 ikastordu jardun beharra aurreikusten da.</p>
<blockquote>
<p>Para alcanzar el nivel de usuario inicial A1, se planifica un proceso de 125 horas lectivas, dependiendo del punto de partida del alumno.
Además, se anticipa que los estudiantes deberán practicar otras 75 horas de trabajo en solitario y uso gratuito.</p>
</blockquote>
<h2><a class="header" href="#entzumena" id="entzumena">Entzumena</a></h2>
<blockquote>
<p>Comprension oral</p>
</blockquote>
<blockquote>
<p>En sus relaciones diarias, el alumno es capaz de identificar el tema y la intencion comunicativa de textos orales breves, de comprender palabras y expresiones en conversaciones presenciales o de formular hipotesis sobre el contenido, siempre y cuando el interlocutor le hable de forma clara y pausada en un registro estandar. Del mismo modo, es capaz de comprender preguntas, informaciones y observaciones relacionadas con necesidades inmediatas, siempre y cuando sean acompañadas de pausas, gestos o imagenes.</p>
</blockquote>
<h2><a class="header" href="#expresion-oral" id="expresion-oral">Expresion oral</a></h2>
<blockquote>
<p>En las interacciones presenciales, el alumno es capaz de dar respuesta a sus necesidades comunicativas basicas y de participar de forma breve pero adecuada e inteligible. Para ese fin, utiliza palabras y expresiones basicas, incluyendo pausas, gestos y reformulaciones._</p>
</blockquote>
<h2><a class="header" href="#comprension-lectora" id="comprension-lectora">Comprension lectora</a></h2>
<blockquote>
<p>El alumno es capaz de identificar el tema y la intencion comunicativa de textos breves que se utilizan a menudo en las relaciones cotidianas, de comprender palabras y expresiones simples y de reconocer informacion previsible. Para estos fines, hara uso del contexto de dichos textos (mensajes cortos, notas simples, listados y carteles) y de las imagenes que los acompañen.</p>
</blockquote>
<h2><a class="header" href="#expresion-escrita" id="expresion-escrita">Expresion escrita</a></h2>
<blockquote>
<p>El alumno es capaz de escribir mensajes y textos breves (listados, impresos, notas breves, postales), que resulten adecuados al contexto, siguiendo muy de cerca los modelos prefijados. Tiene un control muy limitado de los recursos.</p>
</blockquote>
<h1><a class="header" href="#a2-oinarrizko-erabiltzailea" id="a2-oinarrizko-erabiltzailea">A2: Oinarrizko erabiltzailea</a></h1>
<blockquote>
<p>Usuario inicial</p>
</blockquote>
<p>Gai da egoera ezagunetan kideekin (lagun, sinde, lankide, etab.) aurrez aurreko elkarreraginean gauzen eta pertsonen deskribapenak eta azalpen errazak egiteko eta ulertzeko, baldin eta bere esperientzia-esparruarekin loturiko gaiei buruzko informazio-truke erraza eta zuzena eskatzen badute: bere buruari eta familiari buruzko oinarrizko informazioa, eta erosketei, intereseko lekuei, lanbideei eta abarri buruzkoa.</p>
<blockquote>
<p>Es capaz de hacer descripciones y explicaciones simples de cosas y personas en una interacción cara a cara con miembros (amigos, familiares, colegas, etc.) en situaciones familiares,
si requieren un intercambio fácil y directo de información sobre asuntos relacionados con su campo de experiencia:
información básica sobre él y su familia, y sobre compras, lugares de interés, profesiones, etc.</p>
</blockquote>
<p>A2 Oinarrizko erabiltzailearen maila lortzeko, 200 irakastorduko prozesua aurreikusten da, baldin eta A1 mailatik abiatuta baldin bada.
Horiez gain, ikasleak bakarlanean eta erabilera askean beste 100 ordu jardun beharra aurreikusten da.</p>
<blockquote>
<p>Para alcanzar el Nivel de Usuario Básico A2, se prevé un proceso de enseñanza de 200 horas, comenzando desde el nivel A1.
Además, se anticipa que los estudiantes deberán trabajar solos y por otras 100 horas en uso gratuito.</p>
</blockquote>
<h2><a class="header" href="#entzumena-1" id="entzumena-1">Entzumena</a></h2>
<blockquote>
<p>Comprension oral</p>
</blockquote>
<p>Eguneroko egoera ezagunetan, maila bereko solaskideen arteko elkarrizketak eta jarraibideak ulertzeko gai izango da, baita gai ezagunei buruzko azalpenak ulertzeko ere (familia, erosketak, bizitokia, lanbidea, eguraldia, ...), baldin eta informazio zuzena, argia eta poliki ahoskatua bada.</p>
<blockquote>
<p>En situaciones cotidianas populares,
podrá comprender conversaciones y pautas entre interlocutores del mismo nivel,
así como comprender explicaciones de temas familiares (familia, compras, lugar de residencia, profesión, clima, etc.),
proporcionar información correcta,
si es claro y se pronuncia lentamente.</p>
</blockquote>
<h2><a class="header" href="#mintzamena" id="mintzamena">Mintzamena</a></h2>
<blockquote>
<p>Expresion oral</p>
</blockquote>
<p>Egoera ezagunetan, kideekin (lagun, senide eta abarrekin) elkarreraginean, gai izango da informazio-truke erraz eta arruntetan moldatzeko, gauzen eta pertsonen deskribapenak egiteko, eta ekintza eta egitarauei buruzko azalpen errazak eta iritziak emateko.</p>
<blockquote>
<p>En situaciones familiares, la interacción con los miembros (amigos, familiares, etc.) podrá adaptarse a intercambios de información fáciles y comunes, hacer descripciones de cosas y personas, y proporcionar explicaciones y opiniones simples sobre acciones y programas.</p>
</blockquote>
<h2><a class="header" href="#irakurmena" id="irakurmena">Irakurmena</a></h2>
<blockquote>
<p>Comprension escrita</p>
</blockquote>
<p>Eguneroko bizitzarekin lotuko testu labur eta errazetan gai izango da, egoera, testuinguru, formatu eta ezagutza orokorream oinarrituz, komunikazio-asmoa, gaia, ideia nagusiak eta xehetasun adierazgarriak atzemateko.
Gai izango da edukiari buruzko hipotesiak eratzeko eta aurrekis daitezkeen zehaztasunak baieztatzeko; horretarako, zenbaitetan, irudiak lagungarri izango zaizkio.</p>
<blockquote>
<p>Ser capaz de relacionarse con la vida cotidiana en textos cortos y simples, basados ​​en la situación, el contexto, el formato y el conocimiento general, para capturar la intención comunicativa, el tema, las ideas principales y los detalles expresivos.
Podrá formular hipótesis sobre el contenido y confirmar detalles predecibles; esto a veces será ayudado por imágenes.</p>
</blockquote>
<h2><a class="header" href="#idazmena" id="idazmena">Idazmena</a></h2>
<blockquote>
<p>Expresion escrita</p>
</blockquote>
<p>Lagunei, senideei, ikaskideei edo lankideei postalak nahiz ohar eta mezu laburrak, izandako esperientzien kontakizun laburrak eta personen deskribapenak idazteko gai izango da, betiere emandako ereduei jarraiki.</p>
<blockquote>
<p>Él / ella podrá escribir postales a amigos, familiares, compañeros de clase o colegas, así como notas cortas y mensajes, historias cortas sobre sus experiencias y descripciones de personas, de acuerdo con los modelos proporcionados.</p>
</blockquote>
<h1><a class="header" href="#b1-erabiltzaile-independentua" id="b1-erabiltzaile-independentua">B1: Erabiltzaile independentua</a></h1>
<p>Gai da eguneroko testuinguru ezagunetan eta maila bereko solaskideekin elkarrizketak izateko, gai orokorra eta ohikoa izan eta xedea informazioa trukatzea denean.</p>
<blockquote>
<p>Es capaz de mantener conversaciones en contextos cotidianos familiares y con interlocutores del mismo nivel, cuando el tema es general y común y el propósito es intercambiar información.</p>
</blockquote>
<p>Era berean, gai da lagunei, senideei, eta ikaskideei edo lankideei instrukzioak emateko, pertsonak eta objektuak labur deskribatzeko eta gertaeren kontaketa laburrak egiteko.</p>
<blockquote>
<p>También puede dar instrucciones a amigos, parientes y compañeros de clase o colegas, para describir brevemente personas y objetos, y para dar breves relatos de los eventos.</p>
</blockquote>
<p>Gai da, baita ere, bere iritziak labur-labur emateko ete bere asmoak azaltzeko.</p>
<blockquote>
<p>También puede dar sus opiniones brevemente y explicar sus intenciones.</p>
</blockquote>
<p>B1 Erabiltzaile independentearen maila lortzeko, 250 irakastorduko prozesua aurreikusten da, baldin eta A2 mailatik abiatuta baldin bada.
Horiez gain, ikasleak bakarlanean eta erabilera askean beste 150 ikastordu jardun beharra aurreikusten da.</p>
<blockquote>
<p>Para alcanzar el nivel de usuario independiente B1, se prevé un proceso de enseñanza de 250 horas, comenzando desde el nivel A2.
Además, se anticipa que los estudiantes deberán tomar otras 150 horas de trabajo en solitario y uso gratuito.</p>
</blockquote>
<h2><a class="header" href="#entzumena-2" id="entzumena-2">Entzumena</a></h2>
<blockquote>
<p>Comprension oral</p>
</blockquote>
<p>Testuinguru ezagunetan (eskola, aisia, lana...) eta erregistro estandarrean egindako gertaeren kontaketak, azalpenak, deskribapenak, instrukzioak eta elkarrizketak ulertzeko gai izango da, baldin eta gaiak orokorrak badira eta xedea informazioa trukatzea bada.</p>
<blockquote>
<p>Podrá comprender la narración, explicación, descripción, instrucción y entrevista de eventos en contextos familiares (escuela, ocio, trabajo ...) y en el registro estándar, siempre que los temas sean generales y el propósito sea intercambiar información.</p>
</blockquote>
<p>Horrez gain, komunikazio-asmoa atsemango du, ideia nagusiak jasoko ditu eta, zenbait testuingurutan, baita ñabardunak ere (zaratarik eza, abiadura normala, ahoskera garbia, erredundantzia, ikusizko lagungarriak...), betiere azalpenan bat izateko aukera badu.</p>
<blockquote>
<p>Además, él / ella podrá comunicarse, recibir las ideas principales y, en algunos contextos, incluso matices (sin ruido, velocidad normal, pronunciación limpia, redundancia, ayudas visuales ...), siempre que tenga la oportunidad de estar presente en la explicación.</p>
</blockquote>
<h2><a class="header" href="#mintzamena-1" id="mintzamena-1">Mintzamena</a></h2>
<blockquote>
<p>Expresion oral</p>
</blockquote>
<p>Maila bereko solaskideekin elkarrizketak ezateko gai izango da, betiere egoera ezaguna eta gaia orokorra eta arrunta denean, xedea izanik gai konkretu edota abstaktuei buruzko informazioa trukatzea.</p>
<blockquote>
<p>Podrá conversar con interlocutores del mismo nivel, siempre que la situación sea familiar y el tema sea general y común, con el objetivo de intercambiar información sobre temas específicos o abstractos.</p>
</blockquote>
<p>Era berean, gai da instrukzioak emateko, pertsonak eta objektuak labur deskribatezko, gertaeren eta bizipenen kontaketa laburrak egiteko eta bere iritzia labur baina eraginkor adierazteko.</p>
<blockquote>
<p>También puede dar instrucciones, describir brevemente personas y objetos, breves relatos de eventos y experiencias, y expresar su opinión de manera breve pero efectiva.</p>
</blockquote>
<h2><a class="header" href="#irakurmena-1" id="irakurmena-1">Irakurmena</a></h2>
<blockquote>
<p>Comprension escrita</p>
</blockquote>
<p>Ongi egituratutako testu argietan (kronikak, artikulu laburrak, deskribapenak eta argibideak), gai izango da komunikazio-asmoa, gaia, ideia bagusiak, xehetasun adierazgarrienak, diskurtsoaren haria eta ondorioak atzemateko eta ulertzeko, betiere gaiak orokorrak eta ohikoak badira.</p>
<blockquote>
<p>En textos claros bien estructurados (crónicas, artículos cortos, descripciones e instrucciones), podrán comprender y comprender la intención comunicativa, el tema, las ideas principales, los detalles más expresivos, el hilo conductor y las conclusiones, siempre que los temas sean generales y comunes.</p>
</blockquote>
<h2><a class="header" href="#idazmena-1" id="idazmena-1">Idazmena</a></h2>
<blockquote>
<p>Expresion escrita</p>
</blockquote>
<p>Eguneroko testuinguru ezagunetan esperientziak deskribatzeko, gertaerak kontatzeko eta azalpenak emateko gai izango da, baldin eta gaia orokorra eta arrunta bada.</p>
<blockquote>
<p>Podrá describir experiencias, contar eventos y dar explicaciones en contextos cotidianos familiares, siempre que el tema sea general y común.</p>
</blockquote>
<h1><a class="header" href="#b2-erabiltzaile-aurreratua" id="b2-erabiltzaile-aurreratua">B2: Erabiltzaile aurreratua</a></h1>
<p>Gai da, gai orokor nahiz abstraktuei buruz aurrez aurre duen solaskideen zein komunikabideetako esatarien testu gehienak ulertzeko, eta ongi bereiziko ditu ideia nagusiak eta bigarren mailakoak.
Gai da lagun eta lankideekin, baita jatorrizko hiztunekin ere, ohiko elkarreraginean jarriz, iritzia eskatuz, bere ikuspegia defendatuz, etab.</p>
<p>Ohiko gai eta egoera ezagunetan adierazpen argiak egingo ditu.</p>
<p>Bere lan-esparruko hainbat gairi buruzko deskribapenak eta azalpenak ere emango ditu alderdi esanguratsuak eta xehetasunak bereiziz, eta bere iritzia ere eraginkortasunez emango du.</p>
<p>B2 Erabiltzaile aurreratuaren maila lortzeko, 350 irakastorduko prozesua aurreikusten da, baldin eta B1 mailatik abiatuta baldin bada. Horiez gain, ikasleak bakarlanean eta erabilera askean beste 250 ikastordu jardun beharra aurreikusten da.</p>
<h2><a class="header" href="#entzumena-3" id="entzumena-3">Entzumena</a></h2>
<h2><a class="header" href="#mintzamena-2" id="mintzamena-2">Mintzamena</a></h2>
<h2><a class="header" href="#irakurmena-2" id="irakurmena-2">Irakurmena</a></h2>
<h2><a class="header" href="#idazmena-2" id="idazmena-2">Idazmena</a></h2>
<h1><a class="header" href="#c1-erabiltzaile-gaitua" id="c1-erabiltzaile-gaitua">C1: Erabiltzaile gaitua</a></h1>
<p>Gai da lagunarteko, lan-esparruko eta komunikabideetako edozein testu (elkarrizketak, eztabaidak, azalpenak) ulertzeko; baita inguruko herri-hizkeran sortutakoak ere. Eta gai da, era berean, lagunarteko elkarreraginean, lan-esparruan eta komunikabideetan ideiak eta iritziak jariotasunez eta eraginkortasunez adierazteko. Ongi egituratutako eta osatutako testu argiak eta zehatzak idazteko gai da, ideia nagusiak eta osagarriak bereiziz, eta, oro har, xedea lortzeko estrategia egokiak aukeratuz. Era berean, bere ikuspuntua luze eta zabal adierazteko gai da, ideia osagarriak eta adibide egokiak emanez.</p>
<p>C1 Erabiltzaile gaituaren maila lortzeko, 400 irakastorduko prozesua aurreikusten da, baldin eta B2 mailatik abiatuta baldin bada. Horiez gain, ikasleak bakarlanean eta erabilera askean beste 350 ikastordu jardun beharra aurreikusten da.</p>
<h2><a class="header" href="#entzumena-4" id="entzumena-4">Entzumena</a></h2>
<h2><a class="header" href="#mintzamena-3" id="mintzamena-3">Mintzamena</a></h2>
<h2><a class="header" href="#irakurmena-3" id="irakurmena-3">Irakurmena</a></h2>
<h2><a class="header" href="#idazmena-3" id="idazmena-3">Idazmena</a></h2>
<h1><a class="header" href="#c2-erabiltzaile-aditua" id="c2-erabiltzaile-aditua">C2: Erabiltzaile aditua</a></h1>
<p>Gai da norbere espezialitateko nahiz gai orokorretako testuak ulertzeko, eta egoerari egokituz, zuzen eta zehatz, arrakastaz ekoizteko. Gai da, jariotasun handiz eta zehaztasunez, gauzak adierazteko, baita konplexutasun handiko egoeretan esanahiaren ñabardura txikiak bereizteko ere.</p>
<p>Maila honetan matrikulatu ahal izateko, C1 mailaren agiria edo baliokidea izan beharko du ikaslegaiak. C2 Erabiltzaile adituaren maila lortzeko, 200 irakastorduko prozesua aurreikusten da. Horiez gain, bakarlanean eta bere espezialitateari dagokion proiektua garatzen eta lantzen ikasleak beste 500 ikastordu jardun beharra aurreikusten da.</p>
<h2><a class="header" href="#entzumena-5" id="entzumena-5">Entzumena</a></h2>
<h2><a class="header" href="#mintzamena-4" id="mintzamena-4">Mintzamena</a></h2>
<h2><a class="header" href="#irakurmena-4" id="irakurmena-4">Irakurmena</a></h2>
<h2><a class="header" href="#idazmena-4" id="idazmena-4">Idazmena</a></h2>
<h1><a class="header" href="#studying-languages-and-linguistics" id="studying-languages-and-linguistics">Studying Languages and Linguistics</a></h1>
<ul>
<li>sintagma nominal
<ul>
<li>numero
<ul>
<li>singular</li>
<li>plural</li>
<li>indeterminado</li>
</ul>
</li>
<li>nombres</li>
<li>pronombres
<ul>
<li>personales</li>
<li>personales intensivos</li>
<li>demostrativos</li>
<li>demostrativos intensivos</li>
<li>indeterminados</li>
</ul>
</li>
<li>adjetivos</li>
</ul>
</li>
<li>casos</li>
<li>verbos
<ul>
<li>tipo
<ul>
<li>sinteticos</li>
<li>perifrasticos</li>
</ul>
</li>
<li>transitividad
<ul>
<li>intransitivos</li>
<li>transitivos</li>
</ul>
</li>
<li>formas</li>
<li>tiempos verbales</li>
</ul>
</li>
<li>adverbios</li>
<li>modos</li>
<li>condicionales</li>
<li>comparativos</li>
<li>superlativos</li>
</ul>
<h1><a class="header" href="#euskarako-hiztegi-txikia" id="euskarako-hiztegi-txikia">Euskarako Hiztegi Txikia</a></h1>
<h2><a class="header" href="#hiztegia-zertarako--para-que-un-diccionario" id="hiztegia-zertarako--para-que-un-diccionario">Hiztegia Zertarako? / Para que un diccionario?</a></h2>
<p>Hiztegi txiki honetan euskarazko hainbat oinarrizko hitz eta esaldi aurkituko dituzu guregana hurbiltzen zarenean lagungarri izan ditzakezunak.
Baliagarria izango zaizu zenbait egoeratan.
Erabilzera gonbidatzen zaitugu.</p>
<p>En este pequeño diccionario encontrarás palabras y frases elementales en euskera que te serán de gran ayuda cuando te acerques a conocernos.
Te será muy util en diversas situaciones.
Por ello, te animamos a usarlo.</p>
<h2><a class="header" href="#agurrak--saludos" id="agurrak--saludos">Agurrak / Saludos</a></h2>
<table><thead><tr><th>Agurrak</th><th>Saludos</th></tr></thead><tbody>
<tr><td>Ni Miren naiz</td><td>Me llamo Miren</td></tr>
<tr><td>Kaixo, zer moduz?</td><td>Hola, que tal?</td></tr>
<tr><td>Ni oso ondo, etz zu?</td><td>Yo muy bien, y usted?</td></tr>
<tr><td>Oso ondo, eskerrik asko</td><td>Muy bien, muchas gracias</td></tr>
<tr><td>Egun on</td><td>Buenos dias</td></tr>
<tr><td>Arratsalde on</td><td>Buenas tardes</td></tr>
<tr><td>Gabon</td><td>Buenas noches</td></tr>
<tr><td>Kaixo</td><td>Hola!</td></tr>
<tr><td>Agur</td><td>Adios</td></tr>
<tr><td>Bihar arte</td><td>Hasta mañana</td></tr>
<tr><td>Gero arte</td><td>Hasta luego</td></tr>
<tr><td>Ongi etorri</td><td>Bienvenidos</td></tr>
<tr><td>Mesedez</td><td>Por favor</td></tr>
<tr><td>Barkatu</td><td>Perdon</td></tr>
<tr><td>Eskerrik asko</td><td>Muchas gracias</td></tr>
<tr><td>Ez horregatik</td><td>De nada</td></tr>
<tr><td>Bai</td><td>Si</td></tr>
<tr><td>Ez</td><td>No</td></tr>
<tr><td>On egin</td><td>Buen provecho</td></tr>
<tr><td>Ondo ibili</td><td>Que lo pases bien</td></tr>
<tr><td>Zer da hau?</td><td>Que es esto?</td></tr>
<tr><td>Zenbat da?</td><td>Cuanto es?</td></tr>
</tbody></table>
<h2><a class="header" href="#lexuak--lugares" id="lexuak--lugares">Lexuak | Lugares</a></h2>
<table><thead><tr><th>Lexuak</th><th>Lugares</th></tr></thead><tbody>
<tr><td>Egun on, non dago turismo bulegoa?</td><td>Buenos dias, donde esta la oficina de turismo?</td></tr>
<tr><td>Zuzen</td><td>Derecho</td></tr>
<tr><td>Ezkerra</td><td>A la izquierda</td></tr>
<tr><td>Eskuinera</td><td>A la derecha</td></tr>
<tr><td>Goian</td><td>Arriba</td></tr>
<tr><td>Behean</td><td>Abajo</td></tr>
<tr><td>Azpian</td><td>Debajo</td></tr>
<tr><td>Gainean</td><td>Encima</td></tr>
<tr><td>Gertu</td><td>Cerca</td></tr>
<tr><td>Urrun</td><td>Lejos</td></tr>
<tr><td>Hemen</td><td>Aqui</td></tr>
<tr><td>Han</td><td>Alli</td></tr>
<tr><td>Turismo bulegoa</td><td>Oficina de turismo</td></tr>
<tr><td>Udaletxea</td><td>Ayuntamiento</td></tr>
<tr><td>Banketxea</td><td>Banco</td></tr>
<tr><td>Liburu denda</td><td>Libreria</td></tr>
<tr><td>Liburutegia</td><td>Biblioteca</td></tr>
<tr><td>Erakusketa</td><td>Exposicion</td></tr>
<tr><td>Antzokia</td><td>Teatro</td></tr>
<tr><td>Zinema</td><td>Cine</td></tr>
<tr><td>Museoa</td><td>Museo</td></tr>
<tr><td>Jolas parkea</td><td>Parque de atracciones</td></tr>
<tr><td>Lorategia</td><td>Jardin</td></tr>
<tr><td>Parkea</td><td>Parque</td></tr>
<tr><td>Botika</td><td>Farmacia</td></tr>
<tr><td>Autobus geltokia</td><td>Estacion de autobus</td></tr>
<tr><td>Tren geltokia</td><td>Estacion de tren</td></tr>
<tr><td>Posta bulegoa</td><td>Correo</td></tr>
<tr><td>Ospitalea</td><td>Hospital</td></tr>
<tr><td>Eliza (Katedrala, Basilika)</td><td>Iglesia</td></tr>
<tr><td>Hotela</td><td>Hotel</td></tr>
<tr><td>Aterpetxea</td><td>Albergue</td></tr>
<tr><td>Landa turismoa</td><td>Agroturismo</td></tr>
<tr><td>Kanpina</td><td>Camping</td></tr>
<tr><td>Aparkalekua</td><td>Aparcamiento</td></tr>
<tr><td>Plaza</td><td>Plaza</td></tr>
<tr><td>Kalea</td><td>Calle</td></tr>
<tr><td>Auzoa</td><td>Barrio</td></tr>
<tr><td>Hondartza</td><td>Playa</td></tr>
<tr><td>Kiroldegia</td><td>Polideportivo</td></tr>
<tr><td>Igerlikua</td><td>Piscina</td></tr>
<tr><td>Dantzalekua</td><td>Discoteca</td></tr>
<tr><td>Kaia</td><td>Puerto</td></tr>
<tr><td>Taberna</td><td>Bar</td></tr>
<tr><td>Jatetxea</td><td>Restaurante</td></tr>
<tr><td>Azoka</td><td>Mercado</td></tr>
<tr><td>Ertzaintza</td><td>Policia Autonoma</td></tr>
<tr><td>Udaltzaingoa</td><td>Policia Municipal</td></tr>
<tr><td>Garajea</td><td>Garaje</td></tr>
<tr><td>Helbidea</td><td>Direccion</td></tr>
</tbody></table>
<h2><a class="header" href="#hotelean-tabernean-jatetxean--en-el-hotel-en-el-bar-en-el-restaurante" id="hotelean-tabernean-jatetxean--en-el-hotel-en-el-bar-en-el-restaurante">Hotelean, Tabernean, Jatetxean / En el hotel, en el bar, en el restaurante</a></h2>
<table><thead><tr><th>Hotelean, Tabernean, Jatetxean</th><th>En el hotel, en el bar, en el restaurante</th></tr></thead><tbody>
<tr><td>Egun on, gela bat nahi dut</td><td>Buenos dias, queria una habitacion.</td></tr>
<tr><td>Gela</td><td>Habitacion</td></tr>
<tr><td>Gela bikoitza</td><td>Habitacion doble</td></tr>
<tr><td>Ohea</td><td>Cama</td></tr>
<tr><td>Komuna</td><td>Servicio</td></tr>
<tr><td>Bainugela</td><td>Baño</td></tr>
<tr><td>Giltza</td><td>Llave</td></tr>
<tr><td>Maindireak</td><td>Sabanas</td></tr>
<tr><td>Estalkia</td><td>Manta</td></tr>
<tr><td>Eskuoihala</td><td>Toalla</td></tr>
<tr><td>Gosaria</td><td>Desayuno</td></tr>
<tr><td>Bazkaria</td><td>Almuerzo</td></tr>
<tr><td>Afaria</td><td>Cena</td></tr>
<tr><td>Berogailua</td><td>Calefaccion</td></tr>
<tr><td>Aire girotua</td><td>Aire acondicionado</td></tr>
<tr><td>Prezioa</td><td>Precio</td></tr>
<tr><td>Txartela</td><td>Tarjeta</td></tr>
<tr><td>Taberna</td><td>Bar</td></tr>
<tr><td>Jatetxea</td><td>Restaurante</td></tr>
<tr><td>Jangela</td><td>Comedor</td></tr>
<tr><td>Sagardotegia</td><td>Sidreria</td></tr>
<tr><td>Kafea</td><td>Cafe</td></tr>
<tr><td>Esnea</td><td>Leche</td></tr>
<tr><td>Kafesnea</td><td>CAfe con leche</td></tr>
<tr><td>Ardoa</td><td>Vino</td></tr>
<tr><td>Ardo beltza</td><td>Vino tinto</td></tr>
<tr><td>Ardo zuria</td><td>Vino blanco</td></tr>
<tr><td>Ardo gorria</td><td>Vino rosado</td></tr>
<tr><td>Garagardoa</td><td>Cerveza</td></tr>
<tr><td>Sagardoa</td><td>Sidra</td></tr>
<tr><td>Txakolina</td><td>Chacoli</td></tr>
<tr><td>Patxarana</td><td>Pacharan</td></tr>
<tr><td>Ura</td><td>Agua</td></tr>
<tr><td>Ogitartekoa</td><td>Bocadillo</td></tr>
<tr><td>Plater konbinatua</td><td>Plato combinado</td></tr>
<tr><td>Eguneko menua</td><td>Menu del dia</td></tr>
<tr><td>Karta</td><td>Carta</td></tr>
<tr><td>Janaurrekoa</td><td>Aperitivo</td></tr>
<tr><td>Pintxoa (ogi gainekoa)</td><td>Pincho (sobre pan)</td></tr>
<tr><td>Lehen platera</td><td>Primer plato</td></tr>
<tr><td>Bigarrenn platera</td><td>Segundo plato</td></tr>
<tr><td>Postrea (azken burua)</td><td>Postre</td></tr>
<tr><td>Janaria</td><td>Comida</td></tr>
<tr><td>Edaria</td><td>Bebida</td></tr>
<tr><td>Gozoa</td><td>Dulce</td></tr>
<tr><td>Gazia (geza, motela, gatzgabea)</td><td>Salado (no salado, soso, sin sal)</td></tr>
<tr><td>Mikatza</td><td>Amargo</td></tr>
<tr><td>Eskupekoa</td><td>Propina</td></tr>
<tr><td>Zerbitzaria</td><td>Camarero(a)</td></tr>
<tr><td>Sukaldaria</td><td>Cocinero(a)</td></tr>
<tr><td>Haragia</td><td>Carne</td></tr>
<tr><td>Arraina</td><td>Pescado</td></tr>
<tr><td>Kontua mesedez</td><td>La cuenta por favor</td></tr>
<tr><td>Merke</td><td>Barato</td></tr>
<tr><td>Garesti</td><td>Caro</td></tr>
</tbody></table>
<h2><a class="header" href="#egunak-hilabateak--dias-meses" id="egunak-hilabateak--dias-meses">Egunak, Hilabateak / Dias, Meses</a></h2>
<table><thead><tr><th>Egunak, Hilabateak</th><th>Dias, Meses</th></tr></thead><tbody>
<tr><td>Astelehena</td><td>Lunes</td></tr>
<tr><td>Asteartea</td><td>Martes</td></tr>
<tr><td>Asteazkena</td><td>Miercoles</td></tr>
<tr><td>Osteguna</td><td>Jueves</td></tr>
<tr><td>Ostirala</td><td>Viernes</td></tr>
<tr><td>Larunbata</td><td>Sabado</td></tr>
<tr><td>Igandea</td><td>Domingo</td></tr>
<tr><td>Atzo</td><td>Ayer</td></tr>
<tr><td>Gaur</td><td>Hoy</td></tr>
<tr><td>Bihar</td><td>Mañana</td></tr>
<tr><td>Goiza</td><td>Mañana</td></tr>
<tr><td>Arratsaldea</td><td>Tarde</td></tr>
<tr><td>Gaua</td><td>Noche</td></tr>
<tr><td>Urtarrilla</td><td>Enero</td></tr>
<tr><td>Otsaila</td><td>Febrero</td></tr>
<tr><td>Martxoa</td><td>Marzo</td></tr>
<tr><td>Apirila</td><td>Abril</td></tr>
<tr><td>Maiatza</td><td>Mayo</td></tr>
<tr><td>Ekaina</td><td>Junio</td></tr>
<tr><td>Uztaila</td><td>Julio</td></tr>
<tr><td>Abuztua</td><td>Agosto</td></tr>
<tr><td>Iraila</td><td>Septiembre</td></tr>
<tr><td>Urria</td><td>Octubre</td></tr>
<tr><td>Azaroa</td><td>Noviembre</td></tr>
<tr><td>Abendua</td><td>Diciembre</td></tr>
<tr><td>Eguna</td><td>Dia</td></tr>
<tr><td>Astea</td><td>Semana</td></tr>
<tr><td>Hilabetea</td><td>Mes</td></tr>
<tr><td>Urtea</td><td>Año</td></tr>
<tr><td>Uda</td><td>Verano</td></tr>
<tr><td>Udazkena</td><td>Otoño</td></tr>
<tr><td>Negua</td><td>Invierno</td></tr>
<tr><td>Udaberria</td><td>Primavera</td></tr>
<tr><td>Aste Santua</td><td>Semana Santa</td></tr>
<tr><td>Gabonak</td><td>Navidad</td></tr>
<tr><td>Jaieguna</td><td>Dia festivo</td></tr>
</tbody></table>
<h2><a class="header" href="#numeros" id="numeros">Numeros</a></h2>
<table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td>1</td><td>Bat</td></tr>
<tr><td>2</td><td>Bi</td></tr>
<tr><td>3</td><td>Hiru</td></tr>
<tr><td>4</td><td>Lau</td></tr>
<tr><td>5</td><td>Bost</td></tr>
<tr><td>6</td><td>Sei</td></tr>
<tr><td>7</td><td>Zazpi</td></tr>
<tr><td>8</td><td>Zortzi</td></tr>
<tr><td>9</td><td>Bederatzi</td></tr>
<tr><td>10</td><td>Hamar</td></tr>
<tr><td>11</td><td>Hamaika</td></tr>
<tr><td>12</td><td>Hamabi</td></tr>
<tr><td>13</td><td>Hamahiru</td></tr>
<tr><td>14</td><td>Hamalau</td></tr>
<tr><td>15</td><td>Hamabost</td></tr>
<tr><td>16</td><td>Hamasei</td></tr>
<tr><td>17</td><td>Hamazazpi</td></tr>
<tr><td>18</td><td>Hamazortzi</td></tr>
<tr><td>19</td><td>Hemeretzi</td></tr>
<tr><td>20</td><td>Hogei</td></tr>
<tr><td>30</td><td>Hogeita hamar</td></tr>
<tr><td>40</td><td>Berrogei</td></tr>
<tr><td>50</td><td>Berrogeita hamar</td></tr>
<tr><td>60</td><td>Hirurogei</td></tr>
<tr><td>70</td><td>hirurogeita hamar</td></tr>
<tr><td>80</td><td>Laurogei</td></tr>
<tr><td>90</td><td>Laurogeita hamar</td></tr>
<tr><td>100</td><td>Ehun</td></tr>
<tr><td>200</td><td>Berrehun</td></tr>
<tr><td>300</td><td>Hiruehun</td></tr>
<tr><td>400</td><td>Laurehun</td></tr>
<tr><td>500</td><td>Bostehun</td></tr>
<tr><td>600</td><td>Seiehun</td></tr>
<tr><td>700</td><td>Zazpiehun</td></tr>
<tr><td>800</td><td>Zortziehun</td></tr>
<tr><td>900</td><td>Bederatziehun</td></tr>
<tr><td>1000</td><td>Mila</td></tr>
<tr><td>2000</td><td>Bi mila</td></tr>
<tr><td>3000</td><td>Hiru mila</td></tr>
</tbody></table>
<h2><a class="header" href="#euskara-europako-hizkuntza-zaharrena--el-euskera-la-lengua-mas-antigua-de-europa" id="euskara-europako-hizkuntza-zaharrena--el-euskera-la-lengua-mas-antigua-de-europa">Euskara europako hizkuntza zaharrena / El Euskera, la lengua mas antigua de Europa</a></h2>
<p>Euskara Europako hizkuntza zaharrenetako da.
Duela 3000 urte hizkuntza ez indoeuroparrak zituen alboan.
Migrazio mugimenduen eraginez, hizkuntza hauek desagertzen joan ziren pixkanaka eta Kristo aurretiko lehen milurterako hizkuntza indoeuroparrak (germaniarrak, erromantzeak, eslaviarrak, ...) nagusi ziren ia Europa osoan.
Euskara, baina, ez zen desagertu eta gaur egun arte bizirik iraun du.
Hizkuntza aurreindoeuroparra dugu beraz, ahaiderik ez duen edo aurkitu ez zaion hizkuntza bakarrenetakoa.</p>
<p>El euskera es una de las lenguas mas antiguas de europa.
Durante 3000 años convivio junto a otras lenguas no-indoeuropeas.
Como consecuencia de los movimientos migratorios, estas lenguas fueron desapareciendo paulatinamente, y ya en el año mil antes de Cristo, las lenguas indoeuropeas se impusieron practicamente en toda europa.
El euskera, sin embargo, no desaparecio, y sobrevivio hasta nuestros dias.
Se trata, por consiguiente, de una lengua preindoeuropea, una de las pocas lenguas no emparentadas o a la que no se le ha encontrado relacion con otras.</p>
<h2><a class="header" href="#euskal-hitzunak--vascoparlantes" id="euskal-hitzunak--vascoparlantes">Euskal hitzunak / Vascoparlantes</a></h2>
<p>Gaur egun euskaraz gutxi gorabehera 900000 lagunek hitz egiten dute eta beste 626000 inguruk ulertu egiten dute.
Euskal hiztunak edo elebidunak bi estatu (Frantzia eta Espaina) eta hiru administrazio-lurralderen artean daude banatuta: Euskal Autonomia Erkidegoa (Gipuzkoa, Bizkaia eta Araba), Nafarroako Foru Komunitatea (Nafarroa Garaia) etc Frantziako Atlantiar Piriniotako Departamentua (Lapurdi, Behe Nafarroa eta Zuberoa).
Izan ere, hizkuntzen Europa ez dator bat estatuen Europarekin.
Hizkuntzen garapena eta hedadura epe luzeko prozesuen ondorio dira eta politikaren eraginez sortzen diren egoera edo egituratze desberdinak gainditu egiten dituzte.
Donostian, Euskal Autonomia Erkidego osoan bezalaxe, bi hizkuntza ofizial daude: euskara eta gaztelania.
Azken urteetan bilakaera garrantzitsua eman da elebidun kopuruan eta etorkizunean gorakada hau areagotza aurreikusten da, haurrak eta gazteak baitira azken urteetan euskara gehien bereganatu dutenak.
Gipuzkoa da elebidun kopuru handiena duen lurraldea, gipuzkoarren % 53,25 euskal hiztuna da eta beste %28,60k ulertu egiten du.
Donostia, berriz, Gipuzkoan elebidun kopuru handiena duen udalerria da: 72.071 donostiarrek euskaraz dakite (%40,58) eta beste laurden pasatxo batek ulertu egiten du (%26,6).</p>
<p>Actualmente, alrededor de 900000 personas hablan euskera y aproximadamente 626000 personas lo entienden.
Los y las vascoparlantes o bilingües se hallan dividido(a)s administrativamente en dos estados (Francia y España) y tres territorios: la Comunidad Autonoma Vasca (Gipuzkoa, Bizkaia y Araba), la Comunidad Foral de Navarra (Nafarroa Garaia), y el Departamento de los Pirineos Atlanticos Franceses (Lapurdi, Behe Nafarroa, y Zuberoa).
De hecho, la europa de las lenguas no se corresponde con la europa de los estados.
El desarrollo y la extension de los idiomas son consecuencia de procesos de larga duracion, y a menudo superan las diferentes estructuras o situaciones creadas por razones politicas.
En Donostia-San Sebastian, al igual que el resto de la Comunidad Autonoma Vasca, existen dos idiomas oficiales: el euskera y el castellano.
Durante estos ultimos años ha aumentado notablemente el numero de bilingües, y esta previsto que en el futuro se intensifique dicho crecimiento, puesto que son los niños, niñas y jovenes quienes en mayor medida han asumido como lengua el euskera.
Gipuzkoa es el territorio con mayor numero de bilingües, asi, un 53.25% de los/las gipuzkoanos/as son vascoparlantes, y otr 28.60% lo entiende.
Dentro de Gipuzkoa, Donostia-San Sebastian es el municipio con mayor numero de bilingües: 72071 donostiarras saben euskera (40.58%) y algo mas de una cuarta parte lo entiende (26.6%).</p>
<h1><a class="header" href="#nire-apunteak" id="nire-apunteak">Nire Apunteak</a></h1>
<h1><a class="header" href="#lexiko-vocabulario" id="lexiko-vocabulario">Lexiko (Vocabulario)</a></h1>
<h2><a class="header" href="#personas" id="personas">Personas</a></h2>
<table><thead><tr><th>Masculinos</th><th>Femeninos</th></tr></thead><tbody>
<tr><td>Iñaki</td><td>Ainhoa</td></tr>
<tr><td>Koldo</td><td>Uxue</td></tr>
<tr><td>Gorka</td><td>Maite</td></tr>
</tbody></table>
<h2><a class="header" href="#sustantivos" id="sustantivos">Sustantivos</a></h2>
<h3><a class="header" href="#comida" id="comida">Comida</a></h3>
<ul>
<li>
<p>Fruta</p>
<ul>
<li>Banana: banana</li>
<li>Manzana: sagar</li>
<li>Naranja: laranja</li>
<li>Mandarina: mandarina</li>
<li>Limon: limoi, zitroin</li>
<li>Pera: udare, madari</li>
<li>Durazno:</li>
<li>Ciruela: aran, okaran</li>
<li>Frutilla: marrubi, arrega</li>
<li>Cereza: gerezi</li>
<li>Mora: masusta</li>
<li>Frambuesa: mugurdi, masustia gorri, martxuka gorri</li>
<li>Tomate: tomate</li>
</ul>
</li>
<li>
<p>Verdura</p>
<ul>
<li>Papa: patata</li>
<li>Batata: batata</li>
<li>Zapallo:</li>
<li>Cebolla: tipula</li>
<li>Cebolla de verdeo:</li>
<li>Lechuga: uraza, letxuga</li>
<li>Acelga: zerba</li>
<li>Espinaca: ziazerba, espinaka, espinagre</li>
<li>Rucula: errukula</li>
</ul>
</li>
<li>
<p>Carne</p>
<ul>
<li>Bife: xerra</li>
<li>Pescado: arrain</li>
<li>Filet: xerra</li>
<li>Pollo: oilo</li>
<li>Pechuga: bularki</li>
</ul>
</li>
<li>
<p>Cereales</p>
<ul>
<li>Pan: ogi</li>
<li>Trigo: gari</li>
<li>Avena: olo</li>
<li>Cebada: garagar</li>
<li>Centeno: zikirio, zekale</li>
</ul>
</li>
<li>
<p>Lacteos</p>
<ul>
<li>Vaca: behia</li>
<li>Leche: esne</li>
<li>Crema: esne-gain, krema</li>
<li>Manteca: gurin</li>
<li>Queso: gazta</li>
</ul>
</li>
<li>
<p>Hierbas</p>
<ul>
<li>Oregano: loragino</li>
<li>Perejil: perrexil</li>
<li>Laurel: ereinotz, erramu</li>
<li>Tomillo: ezkai, xarbot, elar, erle-belar</li>
</ul>
</li>
<li>
<p>Especias</p>
<ul>
<li>Canela: kanela</li>
<li>Jengibre: jengibre</li>
<li>Clavo de olor:</li>
<li>Pimienta negra: piperbeltz beltz</li>
<li>Pimienta blanca: piperbeltz zuri</li>
<li>Anis: anis-belar</li>
<li>Aji:</li>
<li>Pimenton: piperrauts</li>
<li>Curcuma:</li>
</ul>
</li>
<li>
<p>Condimentos</p>
<ul>
<li>Sal: gatz</li>
<li>Azucar: azukre</li>
</ul>
</li>
<li>
<p>Euskalerriko Itsas Abereak  (peces)</p>
<ul>
<li>Aguja, saltón = Akula</li>
<li>Almeja = Almeja</li>
<li>Anchoa, bocarta = Bokarta, albokartia, antxua</li>
<li>Anguila, martina = Aingira</li>
<li>Arenque = Sardin igarra</li>
<li>Babosa = Itsas bare</li>
<li>Bacalao, abadejo = Bakalloa</li>
<li>Balano = Itsas-ezkur</li>
<li>Breca, alitán = Momarra, lamotia</li>
<li>Caballito de mar = itxas zaldia</li>
<li>Cangrejo = Kamarroa, txangurroa, amarrete</li>
<li>Capatón = Lizarra</li>
<li>Carpa = Zamo</li>
<li>Castañola, palometa = Papalardu, lanpua</li>
<li>Cazón, mozuela = Tolla, katuarraia</li>
<li>Centollo = Armiarma, txangurro</li>
<li>Cherna = Meru</li>
<li>Chicharro = Txitxarro</li>
<li>Chucho, rata = Tramana</li>
<li>Cigala, maganto = Zigala, amarratza</li>
<li>Congrio = Kongrioa, itsas aingira</li>
<li>Coquina, tellina = Tellina, txirla</li>
<li>Corcón, albura = Korrokoi</li>
<li>Dabeta, alisa = Korkoi, dabeta</li>
<li>Esturión, sollo = Gaizkata</li>
<li>Faneca, capellán = Palenka, paneka</li>
<li>Garrabota, boquidulce = Kardia</li>
<li>Golayo, colayo = Pinpiñua, itxugia</li>
<li>Lacha, sardina = Kalaka, kokuta</li>
<li>Lamprea marina = Lanparda, lanpardi</li>
<li>Langosta = Otarraina</li>
<li>Langostino = Otarraintxoa</li>
<li>Lija = Pikua, katea</li>
<li>Madrilla, boga = Loina</li>
<li>Marrajo, tiburón = Itsas-otso, tintoleta</li>
<li>Mejillón = Muskullu</li>
<li>Merillo, serrano = Karraspio</li>
<li>Merlán sarreta = Letxera</li>
<li>Merluza, pescadilla = Legatza, legazkume</li>
<li>Mero de roca, cherna = Kabra</li>
<li>Mielga, ferrón = Melga</li>
<li>Morena, murena = Aingira, itsas-suge</li>
<li>Nécora, andarico = Txamarra</li>
<li>Palometa blanca = Lanpua, lintxa</li>
<li>Paparda, aguja = Balaon</li>
<li>Percebe = Lanperna</li>
<li>Peregrino, tiburón, ballena = Kolayua</li>
<li>Pez ángel, angelote = Aingeru goardakoa</li>
<li>Pez luna = Atalua, ilargi arraia</li>
<li>Pez martillo = Maillu arrain</li>
<li>Pez pero, pintaroja, toll = Katuarraya, moratxa</li>
<li>Pez plata = Abixui</li>
<li>Pez volador = Ega-arrain, txoriarrain</li>
<li>Pez zorra, rabosa = Itsas-azari</li>
<li>Pota, volador, lora = Egatxubia, kalmarra</li>
<li>Pulpo común = Amarrete, olagarroa</li>
<li>Quisquilla, camarón = Izkira</li>
<li>Rata de mar = Itsaskatua</li>
<li>Rata, ratón = Fosforua</li>
<li>Raya = Aluba</li>
<li>Raya = Anai zabala, gastaka</li>
<li>Salmón común = Izokia, ixokia</li>
<li>Salmonete, barbarín = Barbariña, izokia semea</li>
<li>San Martín, pez de San Pedro = Mutxu martin, martiña</li>
<li>Sardina, parrocha = Txardiña, parritxa</li>
<li>Tenca = Zaparda</li>
<li>Tremielga, vaca, torjedo = Eskuikari, ikaraiua</li>
<li>Trucha = Amuarraya, arraukari, amorroia</li>
</ul>
</li>
<li>
<p>Hegaztiak  (aves)</p>
<ul>
<li>Abubilla = Argi oilar</li>
<li>Agachadiza común = Istingor arrunta</li>
<li>Alca común = Pottorro</li>
<li>Anade real = Basahate</li>
<li>Andarríos chico = Kuliska txiki</li>
<li>Ansar común = Antzara</li>
<li>Ave fría = Hegabera</li>
<li>Buitre = Sai arre</li>
<li>Carbonero = Kaskabeltz</li>
<li>Chocha-perdiz = Oilagorra</li>
<li>Chochín = Txepetx</li>
<li>Chorlitos = Txirriak</li>
<li>Chovas = Belantxingak</li>
<li>Cigüeña común = Amiamoko zuria</li>
<li>Codorniz = Galeper</li>
<li>Cogujada común = Hegatxabal ttonttordun</li>
<li>Cuco = Kuku</li>
<li>Cuervo = Bele</li>
<li>Estorninos = Araba zozoak</li>
<li>Ganso = Antzarra</li>
<li>Gaviota = Kaio, antxeta</li>
<li>Golondrina = Enara</li>
<li>Gorrión = Txolarre, lapur-txori</li>
<li>Grulla = Kurrilloa</li>
<li>Halcón = Belatzandi</li>
<li>Halcón abejero = Sapelats liztorjale</li>
<li>Jilguero = Karnaba</li>
<li>Lechuza = Hontza</li>
<li>Martín pescador = Martin arrantzale</li>
<li>Milano negro = Miru beltz</li>
<li>Mirlo = Zozoa</li>
<li>Mochuelo = Mozolo</li>
<li>Paloma torcaz = Pagauso</li>
<li>Perdiz roja = Eper gorri</li>
<li>Petirrojo = Txantxangorri</li>
<li>Polla de agua = Uroilo</li>
<li>Ruiseñor = Urretxindor, errusinol</li>
<li>Ruiseñor bastardo = Errekatxindor</li>
<li>Tórtola = Usapal</li>
<li>Urraca = Mika</li>
<li>Vencejo = Sorbeltz arrunt</li>
<li>Verderón = Txorru</li>
<li>Zorzal = Birigarro</li>
</ul>
</li>
<li>
<p>Zuhaitzak (árboles)</p>
<ul>
<li>Abedul = Urki</li>
<li>Acebo = Gorosti</li>
<li>Aliso = Haltz</li>
<li>Arce = Astigar</li>
<li>Avellano = Urritz</li>
<li>Boj = Ezpel</li>
<li>Castaño = Gaztain</li>
<li>Cerezo = Gereziondo</li>
<li>Chopo = Makal</li>
<li>Ciruelo = Aranondoa</li>
<li>Encina = Arte</li>
<li>Enebro = Epuru</li>
<li>Espino blanco = Elorri</li>
<li>Fresno = Lizar</li>
<li>Haya = Pago</li>
<li>Higuera = Pikondo</li>
<li>Laurel = Erenoitz</li>
<li>Madroño = Urbi</li>
<li>Manzano = Sagarrondo</li>
<li>Níspero = Mizpirondo</li>
<li>Nogal = Intxaurrondo</li>
<li>Olmo = Zumar</li>
<li>Peral = Udarondo, madariondo</li>
<li>Pino = Pinu</li>
<li>Plátano = Albo</li>
<li>Roble = Haritz</li>
<li>Sauce = Sarats</li>
<li>Sauco = Intsusa</li>
<li>Tejo = Hagin</li>
<li>Tilo = Ezki</li>
</ul>
</li>
</ul>
<p>Oilasko-bularkiak erosi ditut</p>
<blockquote>
<p>He comprado pechugas de pollo</p>
</blockquote>
<h3><a class="header" href="#vajilla" id="vajilla">Vajilla</a></h3>
<ul>
<li>Plato: plater</li>
<li>Vaso: edalontzi, baso</li>
<li>Cuchillo: aizto, ganibet, labana</li>
<li>Tenedor: sardexka, tenedore</li>
<li>Cuchara: koilara</li>
</ul>
<h3><a class="header" href="#muebles" id="muebles">Muebles</a></h3>
<ul>
<li>Mesa: mahai</li>
<li>Silla: aulki</li>
<li>Sillon: besaulki</li>
<li>Sofa: sofa</li>
<li>Cama: ohe, ohatze</li>
<li>Ropero: arropategi, jantzitegi</li>
<li>Biblioteca: liburutegi</li>
<li>Estanteria: apalategi</li>
</ul>
<h2><a class="header" href="#herramientas" id="herramientas">Herramientas</a></h2>
<ul>
<li>Martillo</li>
<li>Pinza</li>
<li>Hacha</li>
<li>Sierra</li>
</ul>
<h2><a class="header" href="#lugares" id="lugares">Lugares</a></h2>
<ul>
<li>Casa</li>
<li>Cocina</li>
</ul>
<h2><a class="header" href="#adjetivos" id="adjetivos">Adjetivos</a></h2>
<table><thead><tr><th>Euskera</th><th>Castellano</th></tr></thead><tbody>
<tr><td>berri</td><td>nuevo</td></tr>
<tr><td>gaxte</td><td>joven</td></tr>
<tr><td>zahar</td><td>viejo</td></tr>
<tr><td>polit</td><td>bonito</td></tr>
<tr><td>itsusi</td><td>feo</td></tr>
<tr><td>handi</td><td>grande</td></tr>
<tr><td>txiki</td><td>chico</td></tr>
<tr><td>zabal</td><td>ancho</td></tr>
<tr><td>estu</td><td>angosto</td></tr>
<tr><td>luze</td><td>largo</td></tr>
<tr><td>labur</td><td>corto</td></tr>
<tr><td>altu</td><td>alto</td></tr>
<tr><td>baxu</td><td>bajo</td></tr>
<tr><td>langile</td><td>trabajador</td></tr>
<tr><td>alfer</td><td>vago</td></tr>
<tr><td>garbi</td><td>limpio</td></tr>
<tr><td>zikin</td><td>sucio</td></tr>
<tr><td>alai</td><td>alegre</td></tr>
<tr><td>triste</td><td>triste</td></tr>
<tr><td>atsegin</td><td>agradable</td></tr>
<tr><td>jator</td><td>macanudo</td></tr>
<tr><td>lasai</td><td>tranquilo</td></tr>
<tr><td>urdin</td><td>nervioso</td></tr>
<tr><td>ilehori</td><td>rubio</td></tr>
<tr><td>ilegorri</td><td>pelirrojo</td></tr>
<tr><td>beltzaran</td><td>morocho</td></tr>
<tr><td>burusoil</td><td>pelado</td></tr>
</tbody></table>
<h3><a class="header" href="#sabores" id="sabores">Sabores</a></h3>
<ul>
<li>Salado: gazi</li>
<li>Dulce: gozo, goxo</li>
<li>Picante: min, pikante</li>
<li>Amargo: mingots, mikatz, mingar, karmin</li>
</ul>
<h3><a class="header" href="#caracteristicas-fisicas" id="caracteristicas-fisicas">Caracteristicas fisicas</a></h3>
<ul>
<li>Grande:</li>
<li>Chico:</li>
<li>Largo:</li>
<li>Corto:</li>
<li>Fino:</li>
<li>Grueso:</li>
<li>Ancho:</li>
<li>Delgado:</li>
<li>Gordo:</li>
</ul>
<h3><a class="header" href="#colores" id="colores">Colores</a></h3>
<ul>
<li>Rojo;</li>
<li>Naranja:</li>
<li>Amarillo:</li>
<li>Verde:</li>
<li>Azul:</li>
<li>Violeta:</li>
<li>Marron:</li>
<li>Negro:</li>
<li>Blanco:</li>
<li>Gris:</li>
</ul>
<h2><a class="header" href="#verbos" id="verbos">Verbos</a></h2>
<ul>
<li>Ir:</li>
<li>Venir:</li>
<li>Llevar:</li>
<li>Traer:</li>
<li>Levantar:</li>
<li>Apoyar:</li>
<li>Caminar:</li>
<li>Correr:</li>
<li>Dormir:</li>
<li>Despertar:</li>
<li>Comer:</li>
<li>Beber:</li>
<li>Leer:</li>
<li>Escribir:</li>
<li>Estudiar:</li>
</ul>
<h2><a class="header" href="#adverbios-de-lugar" id="adverbios-de-lugar">Adverbios de lugar</a></h2>
<ul>
<li>Sobre / arriba de</li>
<li>Debajo</li>
<li>Al lado</li>
<li>Delante</li>
<li>Detras</li>
</ul>
<h2><a class="header" href="#partes-del-cuerpo" id="partes-del-cuerpo">Partes del cuerpo</a></h2>
<ul>
<li>Cabeza:</li>
<li>Pelo: ile</li>
<li>Cara: aurpegi</li>
<li>Ojos: begi</li>
<li>Nariz: sudurra</li>
<li>Labios: ezpain</li>
<li>Orejas:</li>
<li>Hombros:</li>
<li>Brazos:</li>
<li>Manos:</li>
<li>Dedos:</li>
<li>Pecho:</li>
<li>Espalda:</li>
<li>Cintura:</li>
<li>Falda:</li>
<li>Piernas:</li>
<li>Pies:</li>
</ul>
<h1><a class="header" href="#izen-sintagma" id="izen-sintagma">Izen Sintagma</a></h1>
<h1><a class="header" href="#nombres" id="nombres">Nombres</a></h1>
<p>Los sustantivos o nombres en euskera no tienen genero pero si numero, y tambien son objeto de declinaciones.</p>
<ul>
<li>Gizon: hombre</li>
<li>Etxe: casa</li>
<li>Zaldi: caballo</li>
</ul>
<p>Declinaciones:</p>
<ul>
<li>Ume_: niño/a</li>
<li>Ume<strong>a</strong>: el/la niño/a</li>
<li>Ume<strong>ak</strong>: los/las niños/as</li>
<li>Ume<strong>ari</strong>: al niño/a</li>
<li>Ume<strong>arentzat</strong>: para el/la niño/a</li>
<li>Ume<strong>arekin</strong>: con el/la niño/a</li>
</ul>
<p>Las diferentes declinaciones corresponden a los distintos <a href="euskera/kasuak.html">casos</a>.
El caso <a href="euskera/kasu_nor.html">nor</a> es el caso basico.</p>
<p>Los numeros son tres: singular, plural, e indeterminado, llamado <em>mugagabea</em>.</p>
<ul>
<li>etxe: casa (indeterminado)</li>
<li>etxe<strong>a</strong>: la casa (singular)</li>
<li>etxe<strong>ak</strong>: las casas (plural)</li>
</ul>
<h1><a class="header" href="#pronombres" id="pronombres">Pronombres</a></h1>
<h1><a class="header" href="#pronombres-personales" id="pronombres-personales">Pronombres personales</a></h1>
<h1><a class="header" href="#pronombres-personales-intensivos" id="pronombres-personales-intensivos">Pronombres personales intensivos</a></h1>
<h1><a class="header" href="#pronombres-demostrativos" id="pronombres-demostrativos">Pronombres demostrativos</a></h1>
<h1><a class="header" href="#pronombres-demostrativos-intensivos" id="pronombres-demostrativos-intensivos">Pronombres demostrativos intensivos</a></h1>
<h1><a class="header" href="#pronombres-indeterminados" id="pronombres-indeterminados">Pronombres indeterminados</a></h1>
<h1><a class="header" href="#adjektiboak" id="adjektiboak">Adjektiboak</a></h1>
<ul>
<li>adjetivo calificativo: adjektibo kalifikatzaile</li>
<li>adjetivo demostrativo: adjektibo erakusle</li>
<li>adjetivo determinativo: adjektibo determinatzaile</li>
<li>adjetivo exclamativo: harridurazko adjektibo</li>
<li>adjetivo indefinido: adjektibo mugagabe</li>
<li>adjetivo interrogativo: galderazko adjektibo</li>
<li>adjetivo numeral: zenbakizko adjektibo</li>
<li>adjetivo posesivo: edutezko adjektibo, adjektibo posesibo</li>
<li>adjetivo referencial: adjektibo erreferentzial</li>
</ul>
<h2><a class="header" href="#nolakoa-da" id="nolakoa-da">Nolakoa da?</a></h2>
<h1><a class="header" href="#kasuak" id="kasuak">Kasuak</a></h1>
<table><thead><tr><th>Caso</th><th>Castellano</th></tr></thead><tbody>
<tr><td>Nor / Nork</td><td>Quien?</td></tr>
<tr><td>Nori</td><td>A quien?</td></tr>
<tr><td>Noren</td><td>De quien?</td></tr>
<tr><td>Norentzat</td><td>Para quien?</td></tr>
<tr><td>Norekin</td><td>Con quien?</td></tr>
<tr><td>Non</td><td>Donde?</td></tr>
<tr><td>Nongo</td><td>De donde? (provenienica)</td></tr>
<tr><td>Nora</td><td>A donde?</td></tr>
<tr><td>Nondik</td><td>De donde?</td></tr>
<tr><td>Noraino</td><td>Hasta donde?</td></tr>
<tr><td>Norantz</td><td>Hacia donde? (sentido)</td></tr>
<tr><td>Zer / Zerk</td><td>Que?</td></tr>
<tr><td>Zein</td><td>Cual?</td></tr>
<tr><td>Zertara</td><td>A que?</td></tr>
<tr><td>Zertarako</td><td>Para que?</td></tr>
</tbody></table>
<h1><a class="header" href="#kasu-nor" id="kasu-nor">Kasu: Nor</a></h1>
<h1><a class="header" href="#kasu-partitiboa" id="kasu-partitiboa">Kasu: Partitiboa</a></h1>
<h1><a class="header" href="#kasu-non" id="kasu-non">Kasu: Non</a></h1>
<h1><a class="header" href="#kasu-nork" id="kasu-nork">Kasu: Nork</a></h1>
<table><thead><tr><th></th><th>Nor</th><th>Nork</th></tr></thead><tbody>
<tr><td>Singular</td><td>hau</td><td>honek</td></tr>
<tr><td></td><td>hori</td><td>horrek</td></tr>
<tr><td></td><td>hura</td><td>hark</td></tr>
<tr><td>Plural</td><td>hauek</td><td>haiek</td></tr>
<tr><td></td><td>horiek</td><td>haiek</td></tr>
<tr><td></td><td>haiek</td><td>haiek</td></tr>
</tbody></table>
<p>Nombres 'comunes': en nork singular, si termina en vocal se le agrega <code>-ak</code>.
En nork singular, si termina en consonante se le agrega <code>-ak</code>.
En nork plural se le agrega <code>-ek</code>.</p>
<p>Nombres 'propios': <code>-(e)k</code>.</p>
<p>Nork plural</p>
<ul>
<li>dut   -&gt; d<strong>IT</strong>ut</li>
<li>duzu  -&gt; d<strong>IT</strong>uzu</li>
<li>du    -&gt; d<strong>IT</strong>u</li>
<li>dugu  -&gt; d<strong>IT</strong>ugu</li>
<li>duzue -&gt; d<strong>IT</strong>uzue</li>
<li>dute  -&gt; d<strong>IT</strong>uzte</li>
</ul>
<h1><a class="header" href="#kasu-nori" id="kasu-nori">Kasu: Nori</a></h1>
<h1><a class="header" href="#kasu-noren" id="kasu-noren">Kasu: Noren</a></h1>
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Sustantivo comun singular</td><td>-aren</td><td>Mutilaren</td></tr>
<tr><td>Sustantivo comun plural</td><td>-en</td><td>Mutilen</td></tr>
<tr><td>Sustantivo propio</td><td>-(r)en</td><td>Martinen</td></tr>
<tr><td></td><td></td><td>Iñakiren</td></tr>
</tbody></table>
<table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td>Singular</td><td>Nire</td></tr>
<tr><td></td><td>Zure</td></tr>
<tr><td></td><td>Honen</td></tr>
<tr><td></td><td>Horren</td></tr>
<tr><td></td><td>Haren</td></tr>
<tr><td></td><td>Bere</td></tr>
<tr><td>Plural</td><td>Gure</td></tr>
<tr><td></td><td>Zuen</td></tr>
<tr><td></td><td>Hauen</td></tr>
<tr><td></td><td>Horien</td></tr>
<tr><td></td><td>Haien</td></tr>
</tbody></table>
<table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td>Nire ordenagailua txikia da.</td><td>Mi computadora es chiquita.</td></tr>
</tbody></table>
<pre><code>sustantivo comun  singular AREN  mutilaren
sustantivo comun  plural   EN    mutilen
sustantivo propio          (R)EN martinen
</code></pre>
<pre><code>Singular NIRE
         ZURE
         HONEN
         HORREN
         HAREN
         BERE

Plural   GURE
         ZUEN
         HAUEN
         HORIEN
         HARIEN
</code></pre>
<p>e.g.</p>
<ul>
<li>Nire ordenagailua, txoria da</li>
<li>Nirea grisa (da)</li>
</ul>
<h1><a class="header" href="#kasu-norentzat" id="kasu-norentzat">Kasu: Norentzat</a></h1>
<h1><a class="header" href="#kasu-norekin" id="kasu-norekin">Kasu: Norekin</a></h1>
<h1><a class="header" href="#kasu-norengatik" id="kasu-norengatik">Kasu: Norengatik</a></h1>
<h1><a class="header" href="#kasu-norengan" id="kasu-norengan">Kasu: Norengan</a></h1>
<h1><a class="header" href="#kasu-norengandik" id="kasu-norengandik">Kasu: Norengandik</a></h1>
<h1><a class="header" href="#kasu-norengana" id="kasu-norengana">Kasu: Norengana</a></h1>
<h1><a class="header" href="#kasu-norenganaino" id="kasu-norenganaino">Kasu: Norenganaino</a></h1>
<h1><a class="header" href="#kasua-norenganantz" id="kasua-norenganantz">Kasua Norenganantz</a></h1>
<h1><a class="header" href="#kasu-nora" id="kasu-nora">Kasu: Nora</a></h1>
<h1><a class="header" href="#kasu-noraino" id="kasu-noraino">Kasu: Noraino</a></h1>
<h1><a class="header" href="#kasu-norantz" id="kasu-norantz">Kasu: Norantz</a></h1>
<h1><a class="header" href="#kasu-norako" id="kasu-norako">Kasu: Norako</a></h1>
<h1><a class="header" href="#kasu-nondik" id="kasu-nondik">Kasu: Nondik</a></h1>
<h1><a class="header" href="#kasu-nongo" id="kasu-nongo">Kasu: Nongo</a></h1>
<p>Observese que el nombre del caso termina en <code>-goa</code> y el sufjio que le
corresponde es <code>-goa</code> si el nombre del lugar termina en consonante y <code>-koa</code> si
termina en vocal.</p>
<table><thead><tr><th>Adibide</th><th>Ejemplos</th></tr></thead><tbody>
<tr><td>Ni Bahia Blancakoa naiz.</td><td>Yo soy de Bahia Blanca.</td></tr>
<tr><td>Zu Bahia Blancakoa zara.</td><td>Vos sos de Bahia Blanca.</td></tr>
<tr><td>Hau Bahia Blancakoa da.</td><td>Eso es de Bahia Blanca.</td></tr>
<tr><td>Hori Bahia Blancakoa da.</td><td>Esto es de Bahia Blanca.</td></tr>
<tr><td>Hura Bahia Blancakoa da.</td><td>Aquello es de Bahia Blanca.</td></tr>
<tr><td>Gu Bahia Blancakoa gara.</td><td>Nosotros somos de Bahia Blanca.</td></tr>
<tr><td>Zuek Bahia Blancakoa zarete.</td><td>Ustedes son de Bahia Blanca.</td></tr>
<tr><td>Hauek Bahia Blancakoa dira.</td><td>Esos son de Bahia Blanca.</td></tr>
<tr><td>Horiek Bahia Blancakoa dira.</td><td>Estos son de Bahia Blanca.</td></tr>
<tr><td>Haiek Bahia Blancakoa dira.</td><td>Aquellos son de Bahia Blanca.</td></tr>
<tr><td>Nongoa zara zu?</td><td>De donde sos vos?</td></tr>
<tr><td>Ni Bahia Blancakoa naiz.</td><td>Yo soy de Bahia Blanca.</td></tr>
<tr><td>Nongoa dira zure gurasoak?</td><td>De donde son vuestros padres?</td></tr>
<tr><td>Nire aita Olavarriakoa da eta nire ama Trelewgoa da.</td><td>Mi padre es de Olavarria y mi madre es de Trelew.</td></tr>
<tr><td>J. L. Borges Palermokoa da.</td><td>J. L. Borges es de Palermo.</td></tr>
<tr><td>Saramago Portugalgoa da.</td><td>Saramago es de Portugal.</td></tr>
<tr><td>Haiek Veronakoak dira.</td><td>Aquellos son de Verona.</td></tr>
</tbody></table>
<ul>
<li>gurasoak: padres</li>
</ul>
<h1><a class="header" href="#kasu-nortzat" id="kasu-nortzat">Kasu: Nortzat</a></h1>
<h1><a class="header" href="#kasu-zerezzertaz" id="kasu-zerezzertaz">Kasu: Zerez/Zertaz</a></h1>
<h1><a class="header" href="#kasu-zerezko" id="kasu-zerezko">Kasu: Zerezko</a></h1>
<h1><a class="header" href="#aditzak" id="aditzak">Aditzak</a></h1>
<h1><a class="header" href="#aditz-laguntzaileak" id="aditz-laguntzaileak">Aditz Laguntzaileak</a></h1>
<h2><a class="header" href="#intransitivos" id="intransitivos">Intransitivos</a></h2>
<h3><a class="header" href="#izan" id="izan">Izan</a></h3>
<p>En castellano, &quot;ser&quot; o &quot;estar&quot;.</p>
<table><thead><tr><th></th><th>Nor</th><th>Aditza</th><th>Castellano</th></tr></thead><tbody>
<tr><td><strong>Singular</strong></td><td>Ni</td><td>naiz</td><td>Yo soy</td></tr>
<tr><td></td><td>Zu</td><td>zara</td><td>Vos sos</td></tr>
<tr><td></td><td>Hau</td><td>da</td><td>Eso es</td></tr>
<tr><td></td><td>Hori</td><td>da</td><td>Esto es</td></tr>
<tr><td></td><td>Hauek</td><td>da</td><td>Aquello es</td></tr>
<tr><td><strong>Plural</strong></td><td>Gu</td><td>gara</td><td>Nosotros somos</td></tr>
<tr><td></td><td>Zuek</td><td>zarete</td><td>Vosotros sois</td></tr>
<tr><td></td><td>Hauek</td><td>dira</td><td>Esos son</td></tr>
<tr><td></td><td>Horiek</td><td>dira</td><td>Estos son</td></tr>
<tr><td></td><td>Haiek</td><td>dira</td><td>Aquellos son</td></tr>
</tbody></table>
<h2><a class="header" href="#transitivos" id="transitivos">Transitivos</a></h2>
<h3><a class="header" href="#ukan" id="ukan">Ukan</a></h3>
<p>En castellano, &quot;tener&quot;.</p>
<p>El 'hark' es la conjugacion solo correspondiente al 'hau'.
El 'haiek' en cambio es la conjugacion correspondiente a 'hauek', 'horiek', y
'haiek'.
Estas conjugaciones verbales solo son para singulares (dut, duzu, gu, dugu, ...).
Para plurales el verbo se conjuga de manera distinta.
Notese que en general la conjugacion del verbo para la primera persona termina
en 't', y para la tercera no tiene nada.</p>
<table><thead><tr><th>Nor</th><th>Aditza</th></tr></thead><tbody>
<tr><td>Nik</td><td>dut</td></tr>
<tr><td>Zuk</td><td>duzu</td></tr>
<tr><td>Honek</td><td>du</td></tr>
<tr><td>Horrek</td><td>du</td></tr>
<tr><td>Hark</td><td>du</td></tr>
<tr><td>Guk</td><td>dugu</td></tr>
<tr><td>Zuk</td><td>duzue</td></tr>
<tr><td>Hauek</td><td>dute</td></tr>
<tr><td>Horiek</td><td>dute</td></tr>
<tr><td>Haiek</td><td>dute</td></tr>
</tbody></table>
<ul>
<li></li>
</ul>
<table><thead><tr><th>Adibideak</th></tr></thead><tbody>
<tr><td>Nik autoa dut.</td></tr>
<tr><td>Zuk liburua duzu.</td></tr>
<tr><td>Honek irratia du.</td></tr>
<tr><td>Horrek irratia du.</td></tr>
<tr><td>Hark irratia du.</td></tr>
<tr><td>Guk txakur bat dugu.</td></tr>
<tr><td>Zuek ordenagailu berria duzue.</td></tr>
<tr><td>Hauek hiztegia dute.</td></tr>
<tr><td>Horiek hiztegia dute.</td></tr>
<tr><td>Haiek hiztegia dute.</td></tr>
</tbody></table>
<h1><a class="header" href="#aditz-bereziak" id="aditz-bereziak">Aditz Bereziak</a></h1>
<h2><a class="header" href="#balio" id="balio">Balio</a></h2>
<table><thead><tr><th></th></tr></thead><tbody>
<tr><td>Zenbat balio du sagar honek?</td></tr>
<tr><td>Sagar honek bi euro balio ditu.</td></tr>
<tr><td>Zerk balio ditu bi euro?</td></tr>
<tr><td>Sagar honek balio ditu bi euro.</td></tr>
<tr><td>Zenbat balio du izozkigilea horrek?</td></tr>
<tr><td>Izozkigilea horrek 1849 peso balio ditu.</td></tr>
<tr><td>Zenbat balio dituzte fideoak honek?</td></tr>
<tr><td>Fideoak honek hire peso balio ditu.</td></tr>
<tr><td>Zenbat balio du txokolate honek?</td></tr>
<tr><td>Txokolate honek 3.79 peso balio ditu.</td></tr>
<tr><td>Zenbat balio du hortzetako eskuilak horiek?</td></tr>
<tr><td>Hortzetako eskuilak horiek 2.59 peso balio ditu.</td></tr>
</tbody></table>
<h2><a class="header" href="#nahi" id="nahi">Nahi</a></h2>
<h2><a class="header" href="#behar" id="behar">Behar</a></h2>
<h1><a class="header" href="#aditz-trinkoak" id="aditz-trinkoak">Aditz Trinkoak</a></h1>
<h1><a class="header" href="#nominalizazioa" id="nominalizazioa">Nominalizazioa</a></h1>
<h1><a class="header" href="#baldintzak-condicionales" id="baldintzak-condicionales">Baldintzak (Condicionales)</a></h1>
<h1><a class="header" href="#mind" id="mind">Mind</a></h1>
<h1><a class="header" href="#buddhism" id="buddhism">Buddhism</a></h1>
<h1><a class="header" href="#body" id="body">Body</a></h1>
<h1><a class="header" href="#society" id="society">Society</a></h1>
<h1><a class="header" href="#sustainable-economics" id="sustainable-economics">Sustainable Economics</a></h1>
<p>Harald Welzer's career as a critic of growth began with a few simple reflections. Just how progressive is it, he asked himself, when millions of hectares of land are used elsewhere in the world so that we keep down the cost of meat? How modern is it when producing a kilogram of salmon in a supposedly sustainable way requires feeding the fish five to six kilograms (11 to 13 pounds) of other types of fish?</p>
<p>If everyone used up as much space and resources as we do, says the 54-year-old Berlin-based social psychologist, we would need three earths. In Welzer's eyes, this can hardly be called progress.</p>
<p>All of this made Welzer so angry that he wrote a book critical of equating this sort of progress with growth. The ruling class of economists, who he characterizes as &quot;disdainers of reality&quot; and &quot;proponents of a world essentially limited by consumption,&quot; is responsible for compulsively tying these two concepts together, he argues. His treatise, &quot;Selbst denken&quot; (&quot;Thinking for Ourselves&quot;), is a manual for phasing out the &quot;totalitarian consumerism&quot; that gives people desires that, until recently, they didn't even suspect they would ever have.</p>
<p>Until a few months ago, Welzer specialized in studying the psyche of Nazi criminals. He has also written about climate wars. His current bestseller, &quot;Selbst denken,&quot; has now made him the figurehead of a movement that radically questions the growth model of the Western economy.</p>
<p>Welzer was also recently named a professor in transformation design at the University of Flensburg, in northern Germany. When a local journalist asked him what transformation design is, he replied: &quot;We don't exactly know yet ourselves.&quot; But the goal of the discipline, he added, is to counter the &quot;systematic scam&quot; created by an industry that produces things that break unnecessarily or are hardly capable of being repaired. Welzer wants to &quot;design corridors&quot; in which companies would be given time to transform faceless, no-name products into durable products with an origin and a history.</p>
<p>Economists have largely disregarded the environmental consequences of growth. For them, the key benchmark of prosperity is gross domestic product (GDP), the sum of all products and services produced in a given country. However, GDP does not factor in the overexploitation of resources, the destruction of biological diversity, air pollution, noise, the expansion of impervious surfaces known as soil sealing, and the poisoning of groundwater.</p>
<p>But for many people, a wealth model built on chronic growth is no longer a desirable goal. They are deciding to opt out of this model by establishing &quot;repair cafés&quot; or &quot;transition towns,&quot; communities that try to run things differently at the local level. But doubts about the growth dogma are even beginning to creep into politics. For instance, German Finance Minister Wolfgang Schäuble, a member of Chancellor Angela Merkel's center-right Christian Democratic Union (CDU), recently argued that Western countries should &quot;espouse limiting economic growth&quot; at home.</p>
<p>But can there be prosperity without growth and growth without environmental damage? How can jobs be preserved in a stagnating or even a shrinking economy? How can a government service its debts in such an economy, especially as the population shrinks?</p>
<h2><a class="header" href="#the-culture-of-enough" id="the-culture-of-enough">The 'Culture of Enough'</a></h2>
<p>The German parliamentary commission on growth, prosperity and quality of life spent two years trying to find answers to these questions. Two weeks ago, the commission presented its 1,000-page final report. In the end, it was as far removed from a consensus as it was at the beginning.</p>
<p>Faith in never-ending growth has long had its critics. But many found warnings like those coming from the Club of Rome, especially in its study on the &quot;Limits of Growth,&quot; to be too alarmist. Nevertheless, the financial crisis has brought renewed misgivings about the system. One of the first to point the way to an alternative was British economist Tim Jackson. In his 2009 book &quot;Prosperity Without Growth,&quot; he outlined a &quot;coherent ecological macroeconomics&quot; based on a &quot;fixed&quot; economy with strict upper limits on emissions and resources.</p>
<p>Many in the British political world have viewed Jackson, an expert with the UK's Sustainable Development Commission, as a bit of an oddball. Hostile government tax officials wondered whether Jackson was proposing that we all go back to living in caves. A professor at the University of Surrey, near London, Jackson had had the audacity to paint capitalism as a faulty system, as a gluttony machine that constantly needs new supplies of people prepared to resolutely continue consuming goods and services.</p>
<p>And when consumers lose their taste for new things, Jackson argues, our system has plenty of shrewd advertisers, marketers and investors to persuade us &quot;to spend money we don't have on things that we don't need to create impressions that won't last on people we don't care about.&quot; Jackson's book, already translated into 15 languages, became a bestseller in the new &quot;culture of enough.&quot;</p>
<p>&quot;It's time to change the channel&quot;, says Welzer, the German growth critic. He is giving a talk in a large lecture hall at the University of Flensburg, and the room is so full that even most of the steps along the side are occupied.</p>
<p>&quot;We apply the old recipes, which is typical for societies that come under stress&quot;, he says. They recognize that resources are dwindling, and yet they intensify their exploitation and accelerate their own demise. He sees no better example of this than the way we treat our resources. Peak oil? Let's drill deeper! Natural gas bottlenecks? Let's use chemicals to pump it out of the earth! Cash-strapped financial markets? Let's flood them!</p>
<p>According to Niko Paech, a 52-year-old economics professor in the northern German city of Oldenburg, we continue to apply these remedies until GDP is back on track, even in the midst of a crisis. But, he adds, treating GDP as a measure of the prosperity of modern societies is downplaying the problem and is &quot;a measure of environmental destruction.&quot;</p>
<p>Paech advocates a shrinking economy and preaches a new frugality. He has been wearing his striped brown sport coat for 25 years, and no matter where he is invited, he always takes his bike or the train. In fact, he has only flown once in his life.</p>
<p>Paech attacks what he calls our &quot;autistic faith in progress.&quot; He is not interested in criticizing a few greedy executives for destroying a supposedly good system. For Paech, the system itself is broken, and instead of repairing it, he wants to rebuild it from the ground up. He no longer believes in reconciliation between the environment and the economy, and in the notion that a level of prosperity achieved through credit can simply be continued through green growth. And unlike many members of the environmentalist Green Party, Paech adds, he is &quot;extremely conservative.&quot;</p>
<p>His message is simple: that we should be giving up and sharing some of our wealth. The labor market he envisions is full of thriving repair and maintenance shops. He wants to see our society become more civilized with less: less material, less energy, less waste and less pollution. He also believes that resources should be managed more effectively. We should produce the kind of clothing, he argues, that can be handed down from one generation to the next instead of throwing things away after wearing them just a few times.</p>
<p>The post-growth theorist explained to a perplexed journalist for the website of Bild, Germany's top-selling tabloid newspaper, that Germans are not role models when it comes to environmental protection because they have merely outsourced their dirty production. For Paech, wealth that can no longer be stabilized without growth is merely &quot;the result of comprehensive environmental depredation.&quot;</p>
<p>The most important argument against growth skeptics like Paech is technology. Influential US economist Julian Simon, for example, predicted that technological advancements could bring us 7 billion more years of growth. The hope is that better and more environmentally friendly products will essentially eliminate the limits on growth. For example, the PR strategists of the Initiative for a New Social Market Economy (INSM), a German umbrella lobbying group supported by free-market-inclined politicians of all stripes, use the slogan &quot;Less CO2 needs more growth.&quot;</p>
<p>But disconnecting growth from more consumption and environmental degradation is still just a dream. According to a study by the parliamentary commission on growth, prosperity and quality of life, which summarizes the current state of research in the field, growth with declining absolute resource consumption currently exists &quot;as good as nowhere&quot; in the world.</p>
<p>There are now alternative methods to measure growth, such as the National Prosperity Index developed by Hans Diefenbacher, an economist in the western German city of Heidelberg. He simply treats the negative impacts of economic activity as a reduction in our welfare. So far, his work has been largely ignored. But now even the divided parliamentary growth commission referred to his model in its final report, in which it recommended a new way of measuring growth, using an indicator called &quot;W3.&quot; This method would not only provide information on wealth, but also on social matters, economic participation and the environment.</p>
<h2><a class="header" href="#leading-a-subversive-double-existence" id="leading-a-subversive-double-existence">Leading 'A Subversive Double Existence'</a></h2>
<p>But can an economy without growth truly exist? The question gives rise to great skepticism, as it does on an evening in the back room of a bar in the northern German city-state of Bremen. Niko Paech is talking to members of the Catholic Guild of St. Ansgar, a group of highly educated retirees who are relentless in their questioning.</p>
<p>How can you pay for our social systems when people are working 20-hour weeks, they ask? But we already can't pay for those structures today, Paech replies. In his system for the future, he explains, people would lead a sort of &quot;subversive double existence.&quot; They would share and recycle, thereby outsmarting an industry geared toward nonstop renewal. People would only work 20 hours a week, but they would also have 20 hours of &quot;market-free&quot; time to provide for themselves.</p>
<p>But such slimmed-down jobs would hardly be enough for many people, says an older man. He hears that a lot, says Paech, especially when he speaks at union functions, where he is routinely grilled by his audience. Besides, says the economist, all the hype about jobs in our supposed knowledge society is in fact questionable. &quot;What exactly are we doing?&quot; he asks. &quot;As we anxiously invoke competitiveness, we train younger and younger delegators with touchscreens to manage the dirty work, forcing Indians to whom the work is being outsourced halfway around the world to work extra hours so that we'll continue to be flooded with consumer goods.&quot; By now, some of his listeners are nodding in agreement.</p>
<p>Paech recently spoke at an event sponsored by Volkswagen, the German automotive giant. &quot;I was in the lion's den, being showered with malice,&quot; he says. At a certain point, he asked what the workers did during the economic crisis, when so many saw their hours reduced under the Kurzarbeit program, the &quot;short-time work&quot;program that the German government used during the crisis to avoid layoffs by encouraging companies to reduce workers' hours while making up for some of the workers' lost salaries and benefits itself. &quot;We worked in the garden, did things in the neighborhood and fixed things,&quot; they told Paech.</p>
<h1><a class="header" href="#ur-fascism---umberto-eco-june-22-1995-issue" id="ur-fascism---umberto-eco-june-22-1995-issue">Ur-Fascism - Umberto Eco June 22, 1995 Issue</a></h1>
<h2><a class="header" href="#fascism-checklist" id="fascism-checklist">Fascism Checklist</a></h2>
<ol>
<li><input disabled="" type="checkbox"/>
cult of tradition (return to a golden age)</li>
<li><input disabled="" type="checkbox"/>
rejection of modernism</li>
<li><input disabled="" type="checkbox"/>
irrationalism (action before discourse)</li>
<li><input disabled="" type="checkbox"/>
no analytical criticism (disagreement is treason)</li>
<li><input disabled="" type="checkbox"/>
no diversity (appeal against intruders)</li>
<li><input disabled="" type="checkbox"/>
derives from individual or social frustration</li>
<li><input disabled="" type="checkbox"/>
nationalistic (to people who feel deprived of a clear social identity, ur-fascism says that their only privilege is the most common one, to be born in the same country)</li>
<li><input disabled="" type="checkbox"/>
followers must feel humiliated by the ostentatious wealth and force of their enemies</li>
<li><input disabled="" type="checkbox"/>
there is no struggle for life but, rather, life is lived for struggle (pacifism is trafficking with the enemy)</li>
<li><input disabled="" type="checkbox"/>
hierarchy, elitism is a typical aspect of any reactionary ideology, insofar as it is fundamentally aristocratic, and aristocratic and militaristic elitism cruelly implies contempt for the weak</li>
<li><input disabled="" type="checkbox"/>
cult of heroism (everybody is educated to become a hero, in every mythology the hero is an exceptional being, but in ur-fascist ideology, heroism is the norm)</li>
<li><input disabled="" type="checkbox"/>
machismo (since both permanent war and heroism are difficult games to play, the Ur-Fascist transfers his will to power to sexual matters)</li>
<li><input disabled="" type="checkbox"/>
based upon a selective populism, a qualitative populism</li>
<li><input disabled="" type="checkbox"/>
Ur-Fascism speaks Newspeak (impoverished vocabulary and an elementary syntax)</li>
</ol>
<h2><a class="header" href="#text-1" id="text-1">Text</a></h2>
<p>In 1942, at the age of ten, I received the First Provincial Award of Ludi Juveniles (a voluntary, compulsory competition for young Italian Fascists—that is, for every young Italian). I elaborated with rhetorical skill on the subject “Should we die for the glory of Mussolini and the immortal destiny of Italy?” My answer was positive. I was a smart boy.</p>
<p>I spent two of my early years among the SS, Fascists, Republicans, and partisans shooting at one another, and I learned how to dodge bullets. It was good exercise.</p>
<p>In April 1945, the partisans took over in Milan. Two days later they arrived in the small town where I was living at the time. It was a moment of joy. The main square was crowded with people singing and waving flags, calling in loud voices for Mimo, the partisan leader of that area. A former maresciallo of the Carabinieri, Mimo joined the supporters of General Badoglio, Mussolini’s successor, and lost a leg during one of the first clashes with Mussolini’s remaining forces. Mimo showed up on the balcony of the city hall, pale, leaning on his crutch, and with one hand tried to calm the crowd. I was waiting for his speech because my whole childhood had been marked by the great historic speeches of Mussolini, whose most significant passages we memorized in school. Silence. Mimo spoke in a hoarse voice, barely audible. He said: “Citizens, friends. After so many painful sacrifices … here we are. Glory to those who have fallen for freedom.” And that was it. He went back inside. The crowd yelled, the partisans raised their guns and fired festive volleys. We kids hurried to pick up the shells, precious items, but I had also learned that freedom of speech means freedom from rhetoric.</p>
<p>A few days later I saw the first American soldiers. They were African Americans. The first Yankee I met was a black man, Joseph, who introduced me to the marvels of Dick Tracy and Li’l Abner. His comic books were brightly colored and smelled good.</p>
<p>One of the officers (Major or Captain Muddy) was a guest in the villa of a family whose two daughters were my schoolmates. I met him in their garden where some ladies, surrounding Captain Muddy, talked in tentative French. Captain Muddy knew some French, too. My first image of American liberators was thus—after so many palefaces in black shirts—that of a cultivated black man in a yellow-green uniform saying: “Oui, merci beaucoup, Madame, moi aussi j’aime le champagne…” Unfortunately there was no champagne, but Captain Muddy gave me my first piece of Wrigley’s Spearmint and I started chewing all day long. At night I put my wad in a water glass, so it would be fresh for the next day.</p>
<p>In May we heard that the war was over. Peace gave me a curious sensation. I had been told that permanent warfare was the normal condition for a young Italian. In the following months I discovered that the Resistance was not only a local phenomenon but a European one. I learned new, exciting words like réseau, maquis, armée secrète, Rote Kapelle, Warsaw ghetto. I saw the first photographs of the Holocaust, thus understanding the meaning before knowing the word. I realized what we were liberated from.</p>
<p>In my country today there are people who are wondering if the Resistance had a real military impact on the course of the war. For my generation this question is irrelevant: we immediately understood the moral and psychological meaning of the Resistance. For us it was a point of pride to know that we Europeans did not wait passively for liberation. And for the young Americans who were paying with their blood for our restored freedom it meant something to know that behind the firing lines there were Europeans paying their own debt in advance.</p>
<p>In my country today there are those who are saying that the myth of the Resistance was a Communist lie. It is true that the Communists exploited the Resistance as if it were their personal property, since they played a prime role in it; but I remember partisans with kerchiefs of different colors. Sticking close to the radio, I spent my nights—the windows closed, the blackout making the small space around the set a lone luminous halo—listening to the messages sent by the Voice of London to the partisans. They were cryptic and poetic at the same time (The sun also rises, The roses will bloom) and most of them were “messaggi per la Franchi.” Somebody whispered to me that Franchi was the leader of the most powerful clandestine network in northwestern Italy, a man of legendary courage. Franchi became my hero. Franchi (whose real name was Edgardo Sogno) was a monarchist, so strongly anti-Communist that after the war he joined very right-wing groups, and was charged with collaborating in a project for a reactionary coup d’état. Who cares? Sogno still remains the dream hero of my childhood. Liberation was a common deed for people of different colors.</p>
<p>In my country today there are some who say that the War of Liberation was a tragic period of division, and that all we need is national reconciliation. The memory of those terrible years should be repressed, refoulée, verdrängt. But Verdrängung causes neurosis. If reconciliation means compassion and respect for all those who fought their own war in good faith, to forgive does not mean to forget. I can even admit that Eichmann sincerely believed in his mission, but I cannot say, “OK, come back and do it again.” We are here to remember what happened and solemnly say that “They” must not do it again.</p>
<p>But who are They?</p>
<p>If we still think of the totalitarian governments that ruled Europe before the Second World War we can easily say that it would be difficult for them to reappear in the same form in different historical circumstances. If Mussolini’s fascism was based upon the idea of a charismatic ruler, on corporatism, on the utopia of the Imperial Fate of Rome, on an imperialistic will to conquer new territories, on an exacerbated nationalism, on the ideal of an entire nation regimented in black shirts, on the rejection of parliamentary democracy, on anti-Semitism, then I have no difficulty in acknowledging that today the Italian Alleanza Nazionale, born from the postwar Fascist Party, MSI, and certainly a right-wing party, has by now very little to do with the old fascism. In the same vein, even though I am much concerned about the various Nazi-like movements that have arisen here and there in Europe, including Russia, I do not think that Nazism, in its original form, is about to reappear as a nationwide movement.</p>
<p>Nevertheless, even though political regimes can be overthrown, and ideologies can be criticized and disowned, behind a regime and its ideology there is always a way of thinking and feeling, a group of cultural habits, of obscure instincts and unfathomable drives. Is there still another ghost stalking Europe (not to speak of other parts of the world)?</p>
<p>Ionesco once said that “only words count and the rest is mere chattering.” Linguistic habits are frequently important symptoms of underlying feelings. Thus it is worth asking why not only the Resistance but the Second World War was generally defined throughout the world as a struggle against fascism. If you reread Hemingway’s For Whom the Bell Tolls you will discover that Robert Jordan identifies his enemies with Fascists, even when he thinks of the Spanish Falangists. And for FDR, “The victory of the American people and their allies will be a victory against fascism and the dead hand of despotism it represents.”</p>
<p>During World War II, the Americans who took part in the Spanish war were called “premature anti-fascists”—meaning that fighting against Hitler in the Forties was a moral duty for every good American, but fighting against Franco too early, in the Thirties, smelled sour because it was mainly done by Communists and other leftists. … Why was an expression like fascist pig used by American radicals thirty years later to refer to a cop who did not approve of their smoking habits? Why didn’t they say: Cagoulard pig, Falangist pig, Ustashe pig, Quisling pig, Nazi pig?</p>
<p>Mein Kampf is a manifesto of a complete political program. Nazism had a theory of racism and of the Aryan chosen people, a precise notion of degenerate art, entartete Kunst, a philosophy of the will to power and of the Ubermensch. Nazism was decidedly anti-Christian and neo-pagan, while Stalin’s Diamat (the official version of Soviet Marxism) was blatantly materialistic and atheistic. If by totalitarianism one means a regime that subordinates every act of the individual to the state and to its ideology, then both Nazism and Stalinism were true totalitarian regimes.</p>
<p>Italian fascism was certainly a dictatorship, but it was not totally totalitarian, not because of its mildness but rather because of the philosophical weakness of its ideology. Contrary to common opinion, fascism in Italy had no special philosophy. The article on fascism signed by Mussolini in the Treccani Encyclopedia was written or basically inspired by Giovanni Gentile, but it reflected a late-Hegelian notion of the Absolute and Ethical State which was never fully realized by Mussolini. Mussolini did not have any philosophy: he had only rhetoric. He was a militant atheist at the beginning and later signed the Convention with the Church and welcomed the bishops who blessed the Fascist pennants. In his early anticlerical years, according to a likely legend, he once asked God, in order to prove His existence, to strike him down on the spot. Later, Mussolini always cited the name of God in his speeches, and did not mind being called the Man of Providence.</p>
<p>Italian fascism was the first right-wing dictatorship that took over a European country, and all similar movements later found a sort of archetype in Mussolini’s regime. Italian fascism was the first to establish a military liturgy, a folklore, even a way of dressing—far more influential, with its black shirts, than Armani, Benetton, or Versace would ever be. It was only in the Thirties that fascist movements appeared, with Mosley, in Great Britain, and in Latvia, Estonia, Lithuania, Poland, Hungary, Romania, Bulgaria, Greece, Yugoslavia, Spain, Portugal, Norway, and even in South America. It was Italian fascism that convinced many European liberal leaders that the new regime was carrying out interesting social reform, and that it was providing a mildly revolutionary alternative to the Communist threat.</p>
<p>Nevertheless, historical priority does not seem to me a sufficient reason to explain why the word fascism became a synecdoche, that is, a word that could be used for different totalitarian movements. This is not because fascism contained in itself, so to speak in their quintessential state, all the elements of any later form of totalitarianism. On the contrary, fascism had no quintessence. Fascism was a fuzzy totalitarianism, a collage of different philosophical and political ideas, a beehive of contradictions. Can one conceive of a truly totalitarian movement that was able to combine monarchy with revolution, the Royal Army with Mussolini’s personal milizia, the grant of privileges to the Church with state education extolling violence, absolute state control with a free market? The Fascist Party was born boasting that it brought a revolutionary new order; but it was financed by the most conservative among the landowners who expected from it a counter-revolution. At its beginning fascism was republican. Yet it survived for twenty years proclaiming its loyalty to the royal family, while the Duce (the unchallenged Maximal Leader) was arm-in-arm with the King, to whom he also offered the title of Emperor. But when the King fired Mussolini in 1943, the party reappeared two months later, with German support, under the standard of a “social” republic, recycling its old revolutionary script, now enriched with almost Jacobin overtones.</p>
<p>There was only a single Nazi architecture and a single Nazi art. If the Nazi architect was Albert Speer, there was no more room for Mies van der Rohe. Similarly, under Stalin’s rule, if Lamarck was right there was no room for Darwin. In Italy there were certainly fascist architects but close to their pseudo-Coliseums were many new buildings inspired by the modern rationalism of Gropius.</p>
<p>There was no fascist Zhdanov setting a strictly cultural line. In Italy there were two important art awards. The Premio Cremona was controlled by a fanatical and uncultivated Fascist, Roberto Farinacci, who encouraged art as propaganda. (I can remember paintings with such titles as Listening by Radio to the Duce’s Speech or States of Mind Created by Fascism.) The Premio Bergamo was sponsored by the cultivated and reasonably tolerant Fascist Giuseppe Bottai, who protected both the concept of art for art’s sake and the many kinds of avant-garde art that had been banned as corrupt and crypto-Communist in Germany.</p>
<p>The national poet was D’Annunzio, a dandy who in Germany or in Russia would have been sent to the firing squad. He was appointed as the bard of the regime because of his nationalism and his cult of heroism—which were in fact abundantly mixed up with influences of French fin de siècle decadence.</p>
<p>Take Futurism. One might think it would have been considered an instance of entartete Kunst, along with Expressionism, Cubism, and Surrealism. But the early Italian Futurists were nationalist; they favored Italian participation in the First World War for aesthetic reasons; they celebrated speed, violence, and risk, all of which somehow seemed to connect with the fascist cult of youth. While fascism identified itself with the Roman Empire and rediscovered rural traditions, Marinetti (who proclaimed that a car was more beautiful than the Victory of Samothrace, and wanted to kill even the moonlight) was nevertheless appointed as a member of the Italian Academy, which treated moonlight with great respect.</p>
<p>Many of the future partisans and of the future intellectuals of the Communist Party were educated by the GUF, the fascist university students’ association, which was supposed to be the cradle of the new fascist culture. These clubs became a sort of intellectual melting pot where new ideas circulated without any real ideological control. It was not that the men of the party were tolerant of radical thinking, but few of them had the intellectual equipment to control it.</p>
<p>During those twenty years, the poetry of Montale and other writers associated with the group called the Ermetici was a reaction to the bombastic style of the regime, and these poets were allowed to develop their literary protest from within what was seen as their ivory tower. The mood of the Ermetici poets was exactly the reverse of the fascist cult of optimism and heroism. The regime tolerated their blatant, even though socially imperceptible, dissent because the Fascists simply did not pay attention to such arcane language.</p>
<p>All this does not mean that Italian fascism was tolerant. Gramsci was put in prison until his death; the opposition leaders Giacomo Matteotti and the brothers Rosselli were assassinated; the free press was abolished, the labor unions were dismantled, and political dissenters were confined on remote islands. Legislative power became a mere fiction and the executive power (which controlled the judiciary as well as the mass media) directly issued new laws, among them laws calling for preservation of the race (the formal Italian gesture of support for what became the Holocaust).</p>
<p>The contradictory picture I describe was not the result of tolerance but of political and ideological discombobulation. But it was a rigid discombobulation, a structured confusion. Fascism was philosophically out of joint, but emotionally it was firmly fastened to some archetypal foundations.</p>
<p>So we come to my second point. There was only one Nazism. We cannot label Franco’s hyper-Catholic Falangism as Nazism, since Nazism is fundamentally pagan, polytheistic, and anti-Christian. But the fascist game can be played in many forms, and the name of the game does not change. The notion of fascism is not unlike Wittgenstein’s notion of a game. A game can be either competitive or not, it can require some special skill or none, it can or cannot involve money. Games are different activities that display only some “family resemblance,” as Wittgenstein put it. Consider the following sequence:
1 2 3 4
abc bcd cde def</p>
<p>Suppose there is a series of political groups in which group one is characterized by the features abc, group two by the features bcd, and so on. Group two is similar to group one since they have two features in common; for the same reasons three is similar to two and four is similar to three. Notice that three is also similar to one (they have in common the feature c). The most curious case is presented by four, obviously similar to three and two, but with no feature in common with one. However, owing to the uninterrupted series of decreasing similarities between one and four, there remains, by a sort of illusory transitivity, a family resemblance between four and one.</p>
<p>Fascism became an all-purpose term because one can eliminate from a fascist regime one or more features, and it will still be recognizable as fascist. Take away imperialism from fascism and you still have Franco and Salazar. Take away colonialism and you still have the Balkan fascism of the Ustashes. Add to the Italian fascism a radical anti-capitalism (which never much fascinated Mussolini) and you have Ezra Pound. Add a cult of Celtic mythology and the Grail mysticism (completely alien to official fascism) and you have one of the most respected fascist gurus, Julius Evola.</p>
<p>But in spite of this fuzziness, I think it is possible to outline a list of features that are typical of what I would like to call Ur-Fascism, or Eternal Fascism. These features cannot be organized into a system; many of them contradict each other, and are also typical of other kinds of despotism or fanaticism. But it is enough that one of them be present to allow fascism to coagulate around it.</p>
<ol>
<li>The first feature of Ur-Fascism is the cult of tradition. Traditionalism is of course much older than fascism. Not only was it typical of counter-revolutionary Catholic thought after the French revolution, but it was born in the late Hellenistic era, as a reaction to classical Greek rationalism. In the Mediterranean basin, people of different religions (most of them indulgently accepted by the Roman Pantheon) started dreaming of a revelation received at the dawn of human history. This revelation, according to the traditionalist mystique, had remained for a long time concealed under the veil of forgotten languages—in Egyptian hieroglyphs, in the Celtic runes, in the scrolls of the little known religions of Asia.</li>
</ol>
<p>This new culture had to be syncretistic. Syncretism is not only, as the dictionary says, “the combination of different forms of belief or practice”; such a combination must tolerate contradictions. Each of the original messages contains a sliver of wisdom, and whenever they seem to say different or incompatible things it is only because all are alluding, allegorically, to the same primeval truth.</p>
<p>As a consequence, there can be no advancement of learning. Truth has been already spelled out once and for all, and we can only keep interpreting its obscure message.</p>
<p>One has only to look at the syllabus of every fascist movement to find the major traditionalist thinkers. The Nazi gnosis was nourished by traditionalist, syncretistic, occult elements. The most influential theoretical source of the theories of the new Italian right, Julius Evola, merged the Holy Grail with The Protocols of the Elders of Zion, alchemy with the Holy Roman and Germanic Empire. The very fact that the Italian right, in order to show its open-mindedness, recently broadened its syllabus to include works by De Maistre, Guenon, and Gramsci, is a blatant proof of syncretism.</p>
<p>If you browse in the shelves that, in American bookstores, are labeled as New Age, you can find there even Saint Augustine who, as far as I know, was not a fascist. But combining Saint Augustine and Stonehenge—that is a symptom of Ur-Fascism.</p>
<ol start="2">
<li>
<p>Traditionalism implies the rejection of modernism. Both Fascists and Nazis worshiped technology, while traditionalist thinkers usually reject it as a negation of traditional spiritual values. However, even though Nazism was proud of its industrial achievements, its praise of modernism was only the surface of an ideology based upon Blood and Earth (Blut und Boden). The rejection of the modern world was disguised as a rebuttal of the capitalistic way of life, but it mainly concerned the rejection of the Spirit of 1789 (and of 1776, of course). The Enlightenment, the Age of Reason, is seen as the beginning of modern depravity. In this sense Ur-Fascism can be defined as irrationalism.</p>
</li>
<li>
<p>Irrationalism also depends on the cult of action for action’s sake. Action being beautiful in itself, it must be taken before, or without, any previous reflection. Thinking is a form of emasculation. Therefore culture is suspect insofar as it is identified with critical attitudes. Distrust of the intellectual world has always been a symptom of Ur-Fascism, from Goering’s alleged statement (“When I hear talk of culture I reach for my gun”) to the frequent use of such expressions as “degenerate intellectuals,” “eggheads,” “effete snobs,” “universities are a nest of reds.” The official Fascist intellectuals were mainly engaged in attacking modern culture and the liberal intelligentsia for having betrayed traditional values.</p>
</li>
<li>
<p>No syncretistic faith can withstand analytical criticism. The critical spirit makes distinctions, and to distinguish is a sign of modernism. In modern culture the scientific community praises disagreement as a way to improve knowledge. For Ur-Fascism, disagreement is treason.</p>
</li>
<li>
<p>Besides, disagreement is a sign of diversity. Ur-Fascism grows up and seeks for consensus by exploiting and exacerbating the natural fear of difference. The first appeal of a fascist or prematurely fascist movement is an appeal against the intruders. Thus Ur-Fascism is racist by definition.</p>
</li>
<li>
<p>Ur-Fascism derives from individual or social frustration. That is why one of the most typical features of the historical fascism was the appeal to a frustrated middle class, a class suffering from an economic crisis or feelings of political humiliation, and frightened by the pressure of lower social groups. In our time, when the old “proletarians” are becoming petty bourgeois (and the lumpen are largely excluded from the political scene), the fascism of tomorrow will find its audience in this new majority.</p>
</li>
<li>
<p>To people who feel deprived of a clear social identity, Ur-Fascism says that their only privilege is the most common one, to be born in the same country. This is the origin of nationalism. Besides, the only ones who can provide an identity to the nation are its enemies. Thus at the root of the Ur-Fascist psychology there is the obsession with a plot, possibly an international one. The followers must feel besieged. The easiest way to solve the plot is the appeal to xenophobia. But the plot must also come from the inside: Jews are usually the best target because they have the advantage of being at the same time inside and outside. In the US, a prominent instance of the plot obsession is to be found in Pat Robertson’s The New World Order, but, as we have recently seen, there are many others.</p>
</li>
<li>
<p>The followers must feel humiliated by the ostentatious wealth and force of their enemies. When I was a boy I was taught to think of Englishmen as the five-meal people. They ate more frequently than the poor but sober Italians. Jews are rich and help each other through a secret web of mutual assistance. However, the followers must be convinced that they can overwhelm the enemies. Thus, by a continuous shifting of rhetorical focus, the enemies are at the same time too strong and too weak. Fascist governments are condemned to lose wars because they are constitutionally incapable of objectively evaluating the force of the enemy.</p>
</li>
<li>
<p>For Ur-Fascism there is no struggle for life but, rather, life is lived for struggle. Thus pacifism is trafficking with the enemy. It is bad because life is permanent warfare. This, however, brings about an Armageddon complex. Since enemies have to be defeated, there must be a final battle, after which the movement will have control of the world. But such a “final solution” implies a further era of peace, a Golden Age, which contradicts the principle of permanent war. No fascist leader has ever succeeded in solving this predicament.</p>
</li>
<li>
<p>Elitism is a typical aspect of any reactionary ideology, insofar as it is fundamentally aristocratic, and aristocratic and militaristic elitism cruelly implies contempt for the weak. Ur-Fascism can only advocate a popular elitism. Every citizen belongs to the best people of the world, the members of the party are the best among the citizens, every citizen can (or ought to) become a member of the party. But there cannot be patricians without plebeians. In fact, the Leader, knowing that his power was not delegated to him democratically but was conquered by force, also knows that his force is based upon the weakness of the masses; they are so weak as to need and deserve a ruler. Since the group is hierarchically organized (according to a military model), every subordinate leader despises his own underlings, and each of them despises his inferiors. This reinforces the sense of mass elitism.</p>
</li>
<li>
<p>In such a perspective everybody is educated to become a hero. In every mythology the hero is an exceptional being, but in Ur-Fascist ideology, heroism is the norm. This cult of heroism is strictly linked with the cult of death. It is not by chance that a motto of the Falangists was Viva la Muerte (in English it should be translated as “Long Live Death!”). In non-fascist societies, the lay public is told that death is unpleasant but must be faced with dignity; believers are told that it is the painful way to reach a supernatural happiness. By contrast, the Ur-Fascist hero craves heroic death, advertised as the best reward for a heroic life. The Ur-Fascist hero is impatient to die. In his impatience, he more frequently sends other people to death.</p>
</li>
<li>
<p>Since both permanent war and heroism are difficult games to play, the Ur-Fascist transfers his will to power to sexual matters. This is the origin of machismo (which implies both disdain for women and intolerance and condemnation of nonstandard sexual habits, from chastity to homosexuality). Since even sex is a difficult game to play, the Ur-Fascist hero tends to play with weapons—doing so becomes an ersatz phallic exercise.</p>
</li>
<li>
<p>Ur-Fascism is based upon a selective populism, a qualitative populism, one might say. In a democracy, the citizens have individual rights, but the citizens in their entirety have a political impact only from a quantitative point of view—one follows the decisions of the majority. For Ur-Fascism, however, individuals as individuals have no rights, and the People is conceived as a quality, a monolithic entity expressing the Common Will. Since no large quantity of human beings can have a common will, the Leader pretends to be their interpreter. Having lost their power of delegation, citizens do not act; they are only called on to play the role of the People. Thus the People is only a theatrical fiction. To have a good instance of qualitative populism we no longer need the Piazza Venezia in Rome or the Nuremberg Stadium. There is in our future a TV or Internet populism, in which the emotional response of a selected group of citizens can be presented and accepted as the Voice of the People.</p>
</li>
</ol>
<p>Because of its qualitative populism Ur-Fascism must be against “rotten” parliamentary governments. One of the first sentences uttered by Mussolini in the Italian parliament was “I could have transformed this deaf and gloomy place into a bivouac for my maniples”—“maniples” being a subdivision of the traditional Roman legion. As a matter of fact, he immediately found better housing for his maniples, but a little later he liquidated the parliament. Wherever a politician casts doubt on the legitimacy of a parliament because it no longer represents the Voice of the People, we can smell Ur-Fascism.</p>
<ol start="14">
<li>Ur-Fascism speaks Newspeak. Newspeak was invented by Orwell, in 1984, as the official language of Ingsoc, English Socialism. But elements of Ur-Fascism are common to different forms of dictatorship. All the Nazi or Fascist schoolbooks made use of an impoverished vocabulary, and an elementary syntax, in order to limit the instruments for complex and critical reasoning. But we must be ready to identify other kinds of Newspeak, even if they take the apparently innocent form of a popular talk show.</li>
</ol>
<p>On the morning of July 27, 1943, I was told that, according to radio reports, fascism had collapsed and Mussolini was under arrest. When my mother sent me out to buy the newspaper, I saw that the papers at the nearest newsstand had different titles. Moreover, after seeing the headlines, I realized that each newspaper said different things. I bought one of them, blindly, and read a message on the first page signed by five or six political parties—among them the Democrazia Cristiana, the Communist Party, the Socialist Party, the Partito d’Azione, and the Liberal Party.</p>
<p>Until then, I had believed that there was a single party in every country and that in Italy it was the Partito Nazionale Fascista. Now I was discovering that in my country several parties could exist at the same time. Since I was a clever boy, I immediately realized that so many parties could not have been born overnight, and they must have existed for some time as clandestine organizations.</p>
<p>The message on the front celebrated the end of the dictatorship and the return of freedom: freedom of speech, of press, of political association. These words, “freedom,” “dictatorship,” “liberty,”—I now read them for the first time in my life. I was reborn as a free Western man by virtue of these new words.</p>
<p>We must keep alert, so that the sense of these words will not be forgotten again. Ur-Fascism is still around us, sometimes in plainclothes. It would be so much easier, for us, if there appeared on the world scene somebody saying, “I want to reopen Auschwitz, I want the Black Shirts to parade again in the Italian squares.” Life is not that simple. Ur-Fascism can come back under the most innocent of disguises. Our duty is to uncover it and to point our finger at any of its new instances—every day, in every part of the world. Franklin Roosevelt’s words of November 4, 1938, are worth recalling: “I venture the challenging statement that if American democracy ceases to move forward as a living force, seeking day and night by peaceful means to better the lot of our citizens, fascism will grow in strength in our land.” Freedom and liberation are an unending task.</p>
<p>Let me finish with a poem by Franco Fortini:</p>
<pre><code>Sulla spalletta del ponte
Le teste degli impiccati
Nell’acqua della fonte
La bava degli impiccati.

Sul lastrico del mercato
Le unghie dei fucilati
Sull’erba secca del prato
I denti dei fucilati.

Mordere l’aria mordere i sassi
La nostra carne non è più d’uomini
Mordere l’aria mordere i sassi
Il nostro cuore non è più d’uomini.

Ma noi s’è letto negli occhi dei morti
E sulla terra faremo libertà
Ma l’hanno stretta i pugni dei morti
La giustizia che si farà.

* * *

(On the bridge’s parapet
The heads of the hanged
In the flowing rivulet
The spittle of the hanged.

On the cobbles in the market- places
The fingernails of those lined up and shot
On the dry grass in the open spaces
The broken teeth of those lined up and shot.

Biting the air, biting the stones
Our flesh is no longer human
Biting the air, biting the stones
Our hearts are no longer human.

But we have read into the eyes of the dead
And shall bring freedom on the earth
But clenched tight in the fists of the dead
Lies the justice to be served.)
—poem translated by Stephen Sartarelli
</code></pre>
<p>Copyright © by Umberto Eco</p>
<h1><a class="header" href="#music-1" id="music-1">Music</a></h1>
<ul>
<li><a href="music/./music/lyrics/index.html">Lyrics</a>
<ul>
<li><a href="music/./music/lyrics/berri_txarrak/index.html">Berri Txarrak</a>
<ul>
<li><a href="music/./music/lyrics/berri_txarrak/1999_ikasten/index.html">1999 Ikasten</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2001_eskuak_ekubilak/index.html">2001 Eskuak-Ekubilak</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2003_libre/index.html">2003 Libre</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2003_jaoi_musika_hil/index.html">2005 Jaoi.Musika.Hil</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2009_payola/index.html">2009 Payola</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2011_haria/index.html">2011 Haria</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2014_denbora_da_poligrafo_bakarra/index.html">2014 Denbora da poligrafo bakarra</a></li>
<li><a href="music/./music/lyrics/berri_txarrak/2017_infrasoinuak/index.html">2017 Infrasoinuak</a></li>
</ul>
</li>
<li><a href="music/./music/lyrics/deftones/index.html">Deftones</a>
<ul>
<li><a href="music/./music/lyrics/deftones/1995_adrenaline/index.html">1995 Adrenaline</a></li>
<li><a href="music/./music/lyrics/deftones/1997_around_the_fur/index.html">1997 Around the Fur</a></li>
<li><a href="music/./music/lyrics/deftones/2000_white_pony/index.html">2000 White Pony</a></li>
<li><a href="music/./music/lyrics/deftones/2003_deftones/index.html">2003 Deftones</a></li>
<li><a href="music/./music/lyrics/deftones/2006_saturday_night_wrist/index.html">2006 Saturday Night Wrist</a></li>
<li><a href="music/./music/lyrics/deftones/2010_diamond_eyes/index.html">2010 Diamond Eyes</a></li>
<li><a href="music/./music/lyrics/deftones/2012_koi_no_yokan/index.html">2012 Koi No Yokan</a></li>
<li><a href="music/./music/lyrics/deftones/2016_gore/index.html">2016 Gore</a></li>
</ul>
</li>
<li><a href="music/./music/lyrics/tool/index.html">Tool</a>
<ul>
<li><a href="music/./music/lyrics/tool/1993_undertow/index.html">1993 Undertow</a></li>
<li><a href="music/./music/lyrics/tool/1996_aenima/index.html">1996 Aenima</a></li>
<li><a href="music/./music/lyrics/tool/2001_lateralus/index.html">2001 Lateralus</a></li>
<li><a href="music/./music/lyrics/tool/2006_10000_days/index.html">2006 10000 Days</a></li>
<li><a href="music/./music/lyrics/tool/2019_fear_inoculum/index.html">2019 Fear Inoculum</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#lyrics" id="lyrics">Lyrics</a></h1>
<h1><a class="header" href="#berri-txarrak" id="berri-txarrak">Berri Txarrak</a></h1>
<h1><a class="header" href="#1999-ikasten" id="1999-ikasten">1999 Ikasten</a></h1>
<h1><a class="header" href="#2001-eskuak-ekubilak" id="2001-eskuak-ekubilak">2001 Eskuak-Ekubilak</a></h1>
<h1><a class="header" href="#2003-libre" id="2003-libre">2003 Libre</a></h1>
<h1><a class="header" href="#2005-jaoimusikahil" id="2005-jaoimusikahil">2005 Jaoi.Musika.Hil</a></h1>
<h1><a class="header" href="#2009-payola" id="2009-payola">2009 Payola</a></h1>
<h1><a class="header" href="#2011-haria" id="2011-haria">2011 Haria</a></h1>
<h1><a class="header" href="#2014-denbora-da-poligrafo-bakarra" id="2014-denbora-da-poligrafo-bakarra">2014 Denbora da poligrafo bakarra</a></h1>
<h1><a class="header" href="#2017-infrasoinuak" id="2017-infrasoinuak">2017 Infrasoinuak</a></h1>
<h1><a class="header" href="#deftones" id="deftones">Deftones</a></h1>
<h1><a class="header" href="#1995-adrenaline" id="1995-adrenaline">1995 Adrenaline</a></h1>
<h1><a class="header" href="#1997-around-the-fur" id="1997-around-the-fur">1997 Around the Fur</a></h1>
<h1><a class="header" href="#2000-white-pony" id="2000-white-pony">2000 White Pony</a></h1>
<h1><a class="header" href="#2003-deftones" id="2003-deftones">2003 Deftones</a></h1>
<h1><a class="header" href="#2006-saturday-night-wrist" id="2006-saturday-night-wrist">2006 Saturday Night Wrist</a></h1>
<h1><a class="header" href="#2010-diamond-eyes" id="2010-diamond-eyes">2010 Diamond Eyes</a></h1>
<h1><a class="header" href="#2012-koi-no-yokan" id="2012-koi-no-yokan">2012 Koi No Yokan</a></h1>
<h1><a class="header" href="#2016-gore" id="2016-gore">2016 Gore</a></h1>
<h1><a class="header" href="#tool" id="tool">Tool</a></h1>
<h1><a class="header" href="#1993-undertow" id="1993-undertow">1993 Undertow</a></h1>
<h1><a class="header" href="#1996-aenima" id="1996-aenima">1996 Aenima</a></h1>
<h1><a class="header" href="#2001-lateralus" id="2001-lateralus">2001 Lateralus</a></h1>
<h1><a class="header" href="#2006-10000-days" id="2006-10000-days">2006 10000 Days</a></h1>
<h1><a class="header" href="#2019-fear-inoculum" id="2019-fear-inoculum">2019 Fear Inoculum</a></h1>
<h1><a class="header" href="#miscellaneous-1" id="miscellaneous-1">Miscellaneous</a></h1>
<ul>
<li><a href="misc/./misc/cooking/index.html">Cooking</a>
<ul>
<li><a href="misc/./misc/cooking/arroz_con_hongos.html">Arroz con Hongos</a></li>
<li><a href="misc/./misc/cooking/croquetas_de_acelga_o_espinaca.html">Croquetas de Acelga/Espinaca</a></li>
<li><a href="misc/./misc/cooking/mayonesa.html">Mayonesa</a></li>
<li><a href="misc/./misc/cooking/sopa_de_arvejas.html">Sopa de Arvejas</a></li>
</ul>
</li>
<li><a href="misc/./misc/library.html">My library</a></li>
<li><a href="misc/./misc/technical_and_scientific_writing.html">Technical and Scientific Writing</a></li>
</ul>
<h1><a class="header" href="#cooking" id="cooking">Cooking</a></h1>
<h1><a class="header" href="#arroz-von-hongos" id="arroz-von-hongos">Arroz von Hongos</a></h1>
<h2><a class="header" href="#ingredientes" id="ingredientes">Ingredientes</a></h2>
<ul>
<li>400g Arroz carnaroli</li>
<li>1 Cebolla</li>
<li>300g Hongos frescos (champiñones, gírgolas, portobellos, etc.)</li>
<li>100g Hongos de pino secos</li>
<li>150g Queso reggianito rallado</li>
<li>200g Crema de leche</li>
<li>½ vaso Vino blanco</li>
<li>1l Caldo de verduras</li>
<li>50g Manteca</li>
<li>Aceite de oliva</li>
<li>1 hoja Laurel,</li>
<li>Sal y pimienta a gusto</li>
</ul>
<h2><a class="header" href="#preparación" id="preparación">Preparación</a></h2>
<p>– Picar muy finamente la cebolla.
– Poner a remojar en agua los hongos secos.
– Cortar en láminas los hongos frescos y saltearlos en manteca con aceite de oliva.
– Rehogar la cebolla picada en aceite hasta que transparente.
– Incorporar el arroz y cocinar revolviendo hasta que el arroz transparente.
– Agregar el vino y cocinar unos minutos hasta que se evapore el alcohol.
– Incorporar al arroz los hongos frescos y la hoja de laurel.
– Escurrir los hongos secos y cortarlos.
– Añadir los hongos secos al arroz.
– Incorporar el caldo en la medida que se vaya cocinando el arroz, revolviendo de vez en cuando.
– Cuando el arroz esté casi listo (unos 15 minutos de cocción) incorporar la crema de leche, calentar mezclando, salpimentar a gusto, tapar la olla y retirar del fuego.
– Dejar reposar durante 5 minutos.
– Servir el arroz cubierto con queso rallado</p>
<h1><a class="header" href="#croquetas-de-acelga-o-espinaca" id="croquetas-de-acelga-o-espinaca">Croquetas de Acelga o Espinaca</a></h1>
<h2><a class="header" href="#preparacion" id="preparacion">Preparacion</a></h2>
<ul>
<li>Se hierve la verdura
<ul>
<li>Si es acelga, primero el tallo y despues la hoja</li>
<li>Si es espinaca, todo junto</li>
</ul>
</li>
<li>Se rehoga y cocina la cebolla hasta que este glaceada rubia pero no tostada y se pica</li>
<li>Por cada paquete de acelga, tres huevos y medio paquete de queso rallado</li>
<li>Sal, pimienta y paprika a ojo</li>
<li>Se pica todo con la mini primer</li>
<li>Se le agrega harina leudante hasta que la mezcla se pone espesa</li>
<li>A ultimo momento, antes de ponerlo en la essen, se le pone quaker para que no se ponga chicloso</li>
<li>Cuando las das vuelta le pones mozzarella</li>
</ul>
<h1><a class="header" href="#mayonesa" id="mayonesa">Mayonesa</a></h1>
<ul>
<li>Huevo a la misma temperatura que el aceita, a temperatura de ambiente, no debe estar frio</li>
<li>Nada de agua en el recipiente, ni una gota</li>
<li>Tirar aceite en hilo fino hasta que espese</li>
<li>Sal, pimienta blanca, ajo, fresco, picado, juego de un limon, vinagre</li>
</ul>
<h1><a class="header" href="#sopa-de-arvejas" id="sopa-de-arvejas">Sopa de Arvejas</a></h1>
<h2><a class="header" href="#ingredientes-1" id="ingredientes-1">Ingredientes</a></h2>
<ul>
<li>Tomillo</li>
<li>Perejil</li>
<li>Oregano</li>
<li>Laurel</li>
<li>Albahaca</li>
<li>Nuez moscada</li>
<li>1/2 kg arvejas partidas</li>
<li>1 cuchadrada copera de ajo disecado picado</li>
<li>Pizca de sal</li>
</ul>
<h2><a class="header" href="#preparacion-1" id="preparacion-1">Preparacion</a></h2>
<ul>
<li>Hervir hasta que las arvejas estan blandas</li>
<li>Agregar los condimentos</li>
</ul>
<h1><a class="header" href="#library" id="library">Library</a></h1>
<h2><a class="header" href="#literature" id="literature">Literature</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Anne Morrow Lindbergh - Gift From the Sea EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Arabien Nights EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Arthur Conan Doyle - The Case Book of Sherlock Holmes EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Carl Djerassi - Cantor's Dilemma EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Carson McCullers - The Heart is a Lonely Hunter EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Charles Dickens - A Tale of Two Cities EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Daniel Defoe - Robinson Crusoe EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Edgar Allen Poe - Selected Tales EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Erich Maria Remarque - All Quiet on the Western Front EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Evelyn Waugh - Scoop EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Frederick Forsyth - The Day of the Jackal EN</li>
<li><input disabled="" type="checkbox" checked=""/>
George Eliot - Middlemarch EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Graham Greene - The Honorary Consul EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Gulliver's Travels EN</li>
<li><input disabled="" type="checkbox" checked=""/>
H G Wells - The Invisible Man EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Harriet Beech Stowe - Uncle Tom's Cabin EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - 1Q84 Vol 1 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - 1Q84 Vol 2 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - 1Q84 Vol 3 ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - A Wild Sheep Chase ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - After Dark ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - Colorless Tsukuru Tazaki and His Years of Pilgrimage ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - Dance Dance Dance ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - Hard-boiled Wonderland and the End of the World ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - Hear the Wind Sing ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - Kafka on the Shore ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - Men Without Women ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - Norwegian Wood ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - Pinball, 1973 ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - South of the Border, West of the Sun ES</li>
<li><input disabled="" type="checkbox"/>
Haruki Murakami - Sputnik Sweetheart ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Haruki Murakami - The Wind-Up Bird Chronicle ES</li>
<li><input disabled="" type="checkbox" checked=""/>
J D Salinger - The Catcher in the Rye EN</li>
<li><input disabled="" type="checkbox" checked=""/>
James Baldwin - Nobody Knows My Name EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Jane Austen - Pride and Prejudice EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Jeff Goodell - The Cyberthief and the Samurai EN</li>
<li><input disabled="" type="checkbox" checked=""/>
John Irving - A Son of the Circus EN</li>
<li><input disabled="" type="checkbox" checked=""/>
John Milton - The Complete English Poetry of John Milton EN</li>
<li><input disabled="" type="checkbox" checked=""/>
John Steinbeck - The Moon is Down EN</li>
<li><input disabled="" type="checkbox" checked=""/>
John Updike - Couples EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Jules Verne - Twenty Thousand Leagues Under the Sea EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Kingsley Amis - Lucky Jim EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Kurt Vonnegut - Bluebeard EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Kurt Vonnegut - Player Piano EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Kurt Vonnegut - Welcome to the Monkey House EN</li>
<li><input disabled="" type="checkbox" checked=""/>
L P Hartley - The Shrimp and the Anemone EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Lu Hsun - Diario de un loco ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Mark Twain - The Complete Short Stories of Mark Twain EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Marlowe - The Tragedy of Doctor Faustus EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - A Case of Need EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - Airframe EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - Congo EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - Disclosure EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - Eaters of the Dead EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - Rising Sun EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - Sphere EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - The Andromeda Strain EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - The Great Train Robbery EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Michael Crichton - The Terminal Man EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Oscar Wilde - Lord Arthur Savile's Crime EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Peter Blauner - Man of the Hour EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Phil Rickman - December EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Rhine Sagas EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Richard Adams - Watership Down EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Rudyard Kipling - Captains Courageous EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Rudyard Kipling - The Jungle Book EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Soviet Short Stories EN</li>
<li><input disabled="" type="checkbox" checked=""/>
The Adventures of Huckleberry Finn EN</li>
<li><input disabled="" type="checkbox" checked=""/>
The Adventures of Ulysses EN</li>
<li><input disabled="" type="checkbox" checked=""/>
The Earliest English Poems EN</li>
<li><input disabled="" type="checkbox" checked=""/>
The Trojan War EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Thomas Hardy - Tess of the d'Urbervilles EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Thomas Harris - The Silence of the Lambs EN</li>
<li><input disabled="" type="checkbox"/>
Marcel Proust - En busqueda del tiempo perdido</li>
</ul>
<h3><a class="header" href="#english-literature" id="english-literature">English Literature</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Spencer Holst - The Language of Cats and Other Stories</li>
<li><input disabled="" type="checkbox" checked=""/>
Agatha Christie - Hercule Poirot, Miss Marple and 3 Whodunnits EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Agatha Christie - Murder on the Orient Express EN</li>
</ul>
<h3><a class="header" href="#latin-american-literature" id="latin-american-literature">Latin American Literature</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Adolfo Bioy Casares - El Sueño de los Heroes</li>
<li><input disabled="" type="checkbox"/>
Alan Pauls - El Pasado</li>
<li><input disabled="" type="checkbox"/>
Alberto Laiseca - El Jardin de las Maquinas Parlantes</li>
<li><input disabled="" type="checkbox"/>
Alberto Laiseca - La Hija de Kheops</li>
<li><input disabled="" type="checkbox"/>
Alberto Laiseca - La Mujer en la Muralla</li>
<li><input disabled="" type="checkbox"/>
Alberto Laiseca - Las Cuatro Torres de Babel</li>
<li><input disabled="" type="checkbox"/>
Alberto Laiseca - Los Sorias</li>
<li><input disabled="" type="checkbox"/>
Alejo Carpentier - El recurso del metodo ES</li>
<li><input disabled="" type="checkbox"/>
Alejo Carpentier - El Reino de este Mundo ES</li>
<li><input disabled="" type="checkbox"/>
Alejo Carpentier - El Siglo de las Luces ES</li>
<li><input disabled="" type="checkbox"/>
Alejo Carpentier - La consagracion de la primavera ES</li>
<li><input disabled="" type="checkbox"/>
Alejo Carpentier - Los Pasos Perdidos ES</li>
<li><input disabled="" type="checkbox"/>
Camila Sosa Villada - Las Malas</li>
<li><input disabled="" type="checkbox"/>
Carla Maliandi - La Habitacion Alemana</li>
<li><input disabled="" type="checkbox"/>
Cesar Aira - El Marmol</li>
<li><input disabled="" type="checkbox"/>
Daniel Guebel - El Absoluto</li>
<li><input disabled="" type="checkbox"/>
Enrique Vila-Matas - Exploradores del Abismo</li>
<li><input disabled="" type="checkbox"/>
Ernesto Sabato - Hombres y Engranajes</li>
<li><input disabled="" type="checkbox"/>
Ernesto Sabato - Uno y el Universo</li>
<li><input disabled="" type="checkbox" checked=""/>
Ernesto Sabato - Ensayo sobre la ceguera</li>
<li><input disabled="" type="checkbox"/>
Ernestp Sabato - Sobre Heroes y Tumbas</li>
<li><input disabled="" type="checkbox"/>
Ernesto Sabato - El Tunel</li>
<li><input disabled="" type="checkbox" checked=""/>
Ernesto Sabato - Abaddon, el exterminador</li>
<li><input disabled="" type="checkbox" checked=""/>
Gabriel Garcia Marquez - One Hundred Years of Solitude EN</li>
<li><input disabled="" type="checkbox"/>
Gabriel Garcia Marquez - Cien Años de Soledad ES</li>
<li><input disabled="" type="checkbox"/>
Gabriel Garcia Marquez - Del Amor y Otros Demonios ES</li>
<li><input disabled="" type="checkbox"/>
Gabriel Garcia Marquez - El Amor en Tiempos de Colera ES</li>
<li><input disabled="" type="checkbox"/>
Gabriel Garcia Marquez - El Coronel no tiene quien le escriba ES</li>
<li><input disabled="" type="checkbox"/>
Gabriel Garcia Marquez - Memoria de mis putas tristes ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Guillermo Martinez - Acerca de Roderer ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Guillermo Martinez - Borges y la Matematica ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Guillermo Martinez - Crimenes imperceptibles ES</li>
<li><input disabled="" type="checkbox"/>
Jorge Baron Biza - El Desierto y Su Semilla</li>
<li><input disabled="" type="checkbox" checked=""/>
Jorge Luis Borges - Obras Completas 1 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jorge Luis Borges - Obras Completas 2 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jorge Luis Borges - Obras Completas 3 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jorge Luis Borges - Obras Completas 4 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Julio Cortazar - Bestiario ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Julio Cortazar - Cuentos Completos 1 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Julio Cortazar - Cuentos Completos 2 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Julio Cortazar - Cuentos Completos 3 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Julio Cortazar - El Diario de Andres Fava ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Julio Cortazar - Rayuela ES</li>
<li><input disabled="" type="checkbox"/>
Juan Forn - Los Viernes</li>
<li><input disabled="" type="checkbox"/>
Julian Lopez - Una Muchacha Muy Bella</li>
<li><input disabled="" type="checkbox"/>
Leila Guerriero - Los suicidas del fin del mundo. Cronica de un pueblo patagonico</li>
<li><input disabled="" type="checkbox"/>
Maria Sonia Cristoff - Bajo Influencia</li>
<li><input disabled="" type="checkbox"/>
Maria Sonia Cristoff - Falsa Calma</li>
<li><input disabled="" type="checkbox"/>
Maria Sonia Cristoff - Incluyanme Afuera</li>
<li><input disabled="" type="checkbox"/>
Roa Bastos - Yo El Supremo ES</li>
<li><input disabled="" type="checkbox"/>
Roberto Arlt - El Amor Brujo</li>
<li><input disabled="" type="checkbox"/>
Roberto Arlt - El Juguete Rabioso</li>
<li><input disabled="" type="checkbox"/>
Roberto Arlt - Los Lanzallamas</li>
<li><input disabled="" type="checkbox"/>
Roberto Arlt - Los Siete Locos</li>
<li><input disabled="" type="checkbox"/>
Roberto Bolaño - Los detectives salvajes</li>
<li><input disabled="" type="checkbox"/>
Rodolfo Fogwill - Los Pichiciegos</li>
<li><input disabled="" type="checkbox"/>
Samantha Schwebling - Distancia de Rescate</li>
<li><input disabled="" type="checkbox"/>
Samantha Schwebling - Kentukis</li>
<li><input disabled="" type="checkbox"/>
Valeria Luiselli - Desierto Sonoro</li>
</ul>
<h3><a class="header" href="#fantasymythology" id="fantasymythology">Fantasy/Mythology</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Bernard Cowell - The Winter King EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Bullfinch's Mythology EN</li>
<li><input disabled="" type="checkbox" checked=""/>
C S Lewis - Prince Caspian EN</li>
<li><input disabled="" type="checkbox" checked=""/>
C S Lewis - The Lion, the Witch and the Wardrobe EN</li>
<li><input disabled="" type="checkbox" checked=""/>
C S Lewis - The Silver Chair EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Dioses Vikingos ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Dioses y Mitos Chinos ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Dioses y Mitos Japoneses ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Edith Hamilton - Mythology EN</li>
<li><input disabled="" type="checkbox" checked=""/>
El Libro Magico de las Runas ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Esteban Ierardo - El Druida ES</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - Sauron Defeated EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Book of Lost Tales 1 EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Book of Lost Tales 2 EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Hobbit EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Lays of Beleriand EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Legend of Sigurd and Gudrun EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Lord of the Rings EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Lost Road and Other Writings EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Shaping of Middle Earth EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - The Silmarillion EN</li>
<li><input disabled="" type="checkbox" checked=""/>
J R R Tolkien - Unfinished Tales EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Liliana Bodoc - Los Dias de la Sombra ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Liliana Bodoc - Los Dias del Fuego ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Liliana Bodoc - Los Dias del Venado ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Marion Zimmer Bradley - The Mists of Avalon EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Mitos y Leyendas de los Vikingos ES</li>
<li><input disabled="" type="checkbox" checked=""/>
R Rosaspini Reynolds - Historia y Leyenda del Rey Arturo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
R Rosaspini Reynolds - Mitos y Leyendas Celtas ES</li>
</ul>
<h3><a class="header" href="#science-fiction" id="science-fiction">Science Fiction</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Arthur C Clarke - Rama II EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Arthur C Clarke - Rendezvous with Rama EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Diane Carey - Star Trek The Next Generation Descent EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Douglas Adamas - The Hitchiker's Guide to the Galaxy EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Frank Herbert - Dune EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Gene DeWeese - Die Kolonie Der Abtrünnigen DE</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - The Caves of Steel EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - The Naked Sun EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - The Robots of Dawn EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - Robots and Empire EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - The Currents of Space EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - The Stars, Like Dust EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - Pebble in the Sky EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - Foundation EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Isaac Asimov - Foundation and Empire EN</li>
<li><input disabled="" type="checkbox"/>
Isaac Asimov - Second Foundation EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Isaac Asimov - Foundation's Edge EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Isaac Asimov - Foundation and Earth EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Isaac Asimov - The Winds of Change EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Isaac Asimov - Words from the Myths EN</li>
<li><input disabled="" type="checkbox"/>
Neal Stephenson - Anathem EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Neal Stephenson - Cryptonomicon EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Neal Stephenson - REAMDE EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Neal Stephenson - Snow Crash EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Neal Stephenson - The Diamond Age EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Orson Scott Card - Ender's Game EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Peter Haining - The Flying Sorcerers EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Timothy Zahn - Star Wars Dark Force Rising EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Timothy Zahn - Star Wars The Last Command EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Sprawl 1: Neuromancer (1984) EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Sprawl 2: Count Zero (1986) EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Sprawl 3: Mona Lisa Overdrive (1988) EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Bridge 1: Virtual Light (1993) EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Bridge 2: Idoru (1996) EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Bridge 3: All Tomorrow's Parties (1999) EN</li>
<li><input disabled="" type="checkbox" checked=""/>
William Gibson - Blue Ant 1: Pattern Recognition (2003) EN</li>
<li><input disabled="" type="checkbox"/>
William Gibson - Blue Ant 2: Spook Country (2007) EN</li>
<li><input disabled="" type="checkbox"/>
William Gibson - Blue Ant 3: Zero History (2010) EN</li>
<li><input disabled="" type="checkbox"/>
William Gibson - Burning Chrome (1986) EN</li>
<li><input disabled="" type="checkbox"/>
William Gibson - The Difference Engine (1990) EN</li>
<li><input disabled="" type="checkbox"/>
William Gibson - The Peripheral (2014)</li>
<li><input disabled="" type="checkbox"/>
William Gibson - Agency (2020)</li>
<li><input disabled="" type="checkbox" checked=""/>
William Shatner - Startrek: The Return EN</li>
</ul>
<h2><a class="header" href="#art" id="art">Art</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
50 Cosas Que Hay Que Saber Sobre - Philip Wilkinson - Arquitectura</li>
<li><input disabled="" type="checkbox" checked=""/>
1001 Discos de Musica Clasica que hay que escuchar antes de morir</li>
<li><input disabled="" type="checkbox" checked=""/>
1001 Libros que hay que leer antes de morir</li>
<li><input disabled="" type="checkbox" checked=""/>
1001 Peliculas que hay que ver antes de morir</li>
<li><input disabled="" type="checkbox" checked=""/>
Williams - Jazz Panorama</li>
</ul>
<h3><a class="header" href="#drawing" id="drawing">Drawing</a></h3>
<h2><a class="header" href="#science" id="science">Science</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Ciencia Que Ladra - Gonzalo Zabala - Robots</li>
<li><input disabled="" type="checkbox" checked=""/>
Ciencia Que Ladra - Pablo Kreimer - El Cientifico Tambien es un Ser Humano</li>
<li><input disabled="" type="checkbox" checked=""/>
Douglas Hofstadter - Gödel, Escher, Bach</li>
<li><input disabled="" type="checkbox" checked=""/>
Douglas Hofstadter - Gödel, Escher, Bach</li>
<li><input disabled="" type="checkbox" checked=""/>
Francisco Martin Casalderrey - La Burla de los Sentidos</li>
<li><input disabled="" type="checkbox" checked=""/>
Javier Fresan - El Sueño de la Razon</li>
<li><input disabled="" type="checkbox" checked=""/>
Malba Tahan - El Hombre Que Calculaba</li>
<li><input disabled="" type="checkbox" checked=""/>
Serway Vuille - Fundamentos de Fisica</li>
<li><input disabled="" type="checkbox" checked=""/>
50 Cosas Que Hay Que Saber Sobre - Martin Redfern - La Tierra</li>
</ul>
<h3><a class="header" href="#mathematics" id="mathematics">Mathematics</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Ciencia Que Ladra - Pablo Amster - La Matematica como una de las Bellas Artes</li>
<li><input disabled="" type="checkbox" checked=""/>
50 Cosas Que Hay Que Saber Sobre - Tony Crilly - Matematica</li>
<li><input disabled="" type="checkbox" checked=""/>
Oscar Reula - Metodos Matematicos de la Fisica</li>
</ul>
<h3><a class="header" href="#computer-science" id="computer-science">Computer Science</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
A Little Riak Book 2.0 EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Artificial Social Systems EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Intelligent Agents. Theories, Architectures and Languages EN</li>
<li><input disabled="" type="checkbox" checked=""/>
JavaScript: The Good Parts EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Korsch, Garrett - Data Structures, Algorithms and Program Style Using C EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Linux Ed4 ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Linux Maxima Seguridad ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Lippman, Lajoie, Moo - C++ Primer EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Multiagent Systems: Intentions, Know-How and Communications EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Redes GNU/Linux ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Sedgewick Algorithms in C Parts 1-4 EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Sedgewick Algorithms in C Part 5 EN</li>
<li><input disabled="" type="checkbox" checked=""/>
SuSE Linux 6.4 EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Van Wyk - Data Structures and C Programs EN</li>
</ul>
<h3><a class="header" href="#cognitive-science" id="cognitive-science">Cognitive Science</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Csikszentmihalyi - Aprender a Fluir ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Csikszentmihalyi - Fluir (Flow) ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Daniel Goleman - Focus ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Diego Golombek - Las Neuronas de Dios ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Facundo Manes - Usar el Cerebro ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Marcelo Rodriguez - Historia de la Inteligencia ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Marvin Minsky - La Maquina de las Emociones ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Ramirez - Cognotecnicas ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Skidelsky, Scotto - Cuestiones Mentales ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Stanislas Dehaene - La Conciencia en el Cerebro ES</li>
</ul>
<h2><a class="header" href="#philosophypsychologysociology" id="philosophypsychologysociology">Philosophy/Psychology/Sociology</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Arthur Schopenhauer - Historia de la Filosofia ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Bertrand Russel - Misticismo y Logica ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Carl Jung - El Hombre y Sus Simbolos ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Edgar Morin - Introduccion al Pensamiento Complejo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Frost - Basic Teachings: Philosophers EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Herbert Read - The Meaning of Art EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Hodgson - Wittgenstein y el Zen ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jostein Gaarder - El Mundo de Sofia ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Martin Heidegger - Que Significa Pensar? ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Milan Kundera - La Identidad ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Milan Kundera - La Insoportable Levedad del Ser ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Mircea Eliade - Mefistoles y el Androgino ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Monica Cavalle - La Sabiduria de la No-Dualidad ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Noam Chomsky - El Conocimiento del Lenguaje ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Para Principiantes - Baudrillard ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Para Principiantes - Heidegger ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Paul Feyerabend - Tratado Contra el Metodo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Georges Bataille - El erotismo</li>
<li><input disabled="" type="checkbox" checked=""/>
Rene Descartes - Discurso del Metodo / Meditaciones Metafisicas ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Sigmund Freud - The Future of an Illusion EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - Apocalipticos e Integrados ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - Baudolino ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - Decir casi lo mismo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - El cementerio de Praga ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - El nombre del a rosa ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - El pendulo de Foucault ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - La busqueda de la lengua perfecta ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - La misteriosa llama de la Reina Loana ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - La estructura ausente ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - Signo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Umberto Eco - Numero Zero</li>
<li><input disabled="" type="checkbox" checked=""/>
Willard Quine - Los Metodos de la Logica ES</li>
</ul>
<h2><a class="header" href="#western-existentialism" id="western-existentialism">Western Existentialism</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Ramiro Calle - Ante la ansiedad ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Sade - Filosofia en el tocador ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Max Stirner - El Unico y su propiedad ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Nietzsche - La Voluntad de poder ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Nietzsche - Mas alla del bien y del mal ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jean-Paul Sartre - La nausea ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jean-Paul Sartre - El ser y la nada ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Martin Heidegger - El ser y el tiempo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Albert Camus - El mito de sisifo ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Albert Camus - El extranjero ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Soren Kierkegaard - El Concepto de la Angustia ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Soren Kierkegaard - Tratado de la desesperacion ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Soren Kierkegaard - Temor y temblor ES</li>
</ul>
<h2><a class="header" href="#eastern-philosophy--mysticism" id="eastern-philosophy--mysticism">Eastern Philosophy &amp; Mysticism</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Alan Watts - El Camino del Zen ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Carmelo Rios - El Espiritu de las Artes Marciales ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Daisetz Suzuki - Budismo Zen ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Daisetz Suzuki - Introduccion al Budismo Zen ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Eugen Herrigel - Zen el Tiro del Arco ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Fritjof Capra - El Tao de la Fisica ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Gaku Homma - La Estructura del Aikido ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Gozo Shioda - Aikido Total ES</li>
<li><input disabled="" type="checkbox" checked=""/>
I Ching ES</li>
<li><input disabled="" type="checkbox" checked=""/>
J van de Wetering - El Espejo Vacio ES</li>
<li><input disabled="" type="checkbox" checked=""/>
La Mente del Samurai ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Lao Tse - Tao Te Ching ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Mitsugi Saotome - Aikido ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Indra Devi - Respirar bien para vivir mejor</li>
<li><input disabled="" type="checkbox" checked=""/>
Luciano Jolly - Do-In Hara</li>
<li><input disabled="" type="checkbox" checked=""/>
Mantak Chia - Automasaje Chi: Sistema Taoista de Rejuvenecimiento</li>
<li><input disabled="" type="checkbox" checked=""/>
Mantak Chia - Taoist Secrets of Love: Cultivating Female Sexual Energy</li>
<li><input disabled="" type="checkbox" checked=""/>
Mantak Chia - Taoist Secrets of Love: Cultivating Male Sexual Energy</li>
<li><input disabled="" type="checkbox" checked=""/>
Shigeru Onoda - Libro completo de shiatsu</li>
<li><input disabled="" type="checkbox" checked=""/>
Stephen Chang - El libro de los ejercicios internos</li>
<li><input disabled="" type="checkbox" checked=""/>
Taisen Deshimaru - La Practica del Zen ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Taisen Deshimaru - Zen Verdadero ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Taisen Deshimaru - Zen y Autocontrol ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Taisen Deshimaru - Zen y Cerebro ES</li>
</ul>
<h2><a class="header" href="#politics" id="politics">Politics</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1985 Rodolfo Walsh y la prensa clandestina (1976-1978).</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1985 La posguerra sucia.</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1985 Ezeiza</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1987 Civiles y militares: memoria secreta de la transición .</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1987 Medio siglo de proclamas militares</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1990 La educación presidencial. De la derrota del '70 al desguace del Estado</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1991 Robo para la corona</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1993 Hacer la Corte: La construcción de un poder absoluto sin justicia ni control</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1995 El vuelo</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1997 Un mundo sin periodistas</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 1998 Hemisferio derecho</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2002 Malvinas: La última batalla de la Tercera Guerra Mundial (versión ampliada)</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2005 El silencio. De Paulo VI a Bergoglio: Las relaciones secretas de la Iglesia con la ESMA</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2006 Doble juego: la Argentina católica y militar</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2007 Cristo vence: la Iglesia en la Argentina: un siglo de historia política (1884-1983)</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2008 La violencia evangélica. Historia política de la Iglesia católica</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2009 Vigilia de armas. Del Cordobazo de 1969 al 23 de marzo de 1976</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2010 La mano izquierda de Dios. La última dictadura (1976- 1983)</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2013 Cuentas pendientes. Los cómplices económicos de la dictadura</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2017 La libertad no es un milagro</li>
<li><input disabled="" type="checkbox"/>
Horacio Verbitsky - 2018 Vida de Perro</li>
<li><input disabled="" type="checkbox" checked=""/>
Noam Chomsky - Anarquismo ES</li>
</ul>
<h3><a class="header" href="#anarchism" id="anarchism">Anarchism</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Mijail Bakunin - Dios y el Estado</li>
<li><input disabled="" type="checkbox"/>
Mijail Bakunin - Estatismo y Anarquia</li>
<li><input disabled="" type="checkbox" checked=""/>
Daniel Guerin - El Anarquismo</li>
<li><input disabled="" type="checkbox"/>
Daniel Guerin - Rosa Luxemburg</li>
<li><input disabled="" type="checkbox"/>
Murray Bookchin - La utopia es posible</li>
<li><input disabled="" type="checkbox"/>
Arthur Lehning - Marxismo y Anarquismo en la Revolucion Rusa</li>
<li><input disabled="" type="checkbox"/>
Paul Avrich - Kronstadt 1921</li>
<li><input disabled="" type="checkbox"/>
Christian Ferrer - Cabezas de tormenta</li>
<li><input disabled="" type="checkbox"/>
Christian Ferrer - El lenguaje libertario</li>
<li><input disabled="" type="checkbox"/>
Piotr Kropotkin - La conquista del pan</li>
<li><input disabled="" type="checkbox"/>
Piotr Kropotkin - La moral anarquista</li>
<li><input disabled="" type="checkbox"/>
Piotr Kropotkin - Campos, fabricas y talleres</li>
<li><input disabled="" type="checkbox"/>
D. Abad de Santillan - La FORA</li>
<li><input disabled="" type="checkbox"/>
Javier Benyo - La Alianza Obrero Spartacus</li>
<li><input disabled="" type="checkbox" checked=""/>
Pierre Proudhon - Que es la propiedad?</li>
<li><input disabled="" type="checkbox"/>
Pierre Proudhon - El principio federativo</li>
<li><input disabled="" type="checkbox"/>
Plinio A. Coelho - Surrealismo y Anarquismo</li>
<li><input disabled="" type="checkbox"/>
Eduardo Colombo - La voluntad del pueblo</li>
<li><input disabled="" type="checkbox"/>
Osvaldo Baigorria - El amor libre</li>
<li><input disabled="" type="checkbox"/>
Osvaldo Baigorria - El anarquismo trashumante</li>
<li><input disabled="" type="checkbox"/>
Frank Mintz - A cien años de la Revolución Rusa. De los sóviets libres a la restauración del privilegio</li>
<li><input disabled="" type="checkbox" checked=""/>
Frank Mintz - Bakunin, critica y accion</li>
<li><input disabled="" type="checkbox"/>
Frank Mintz - Anatol Gorelik. El anarquismo y la Revolución Rusa</li>
<li><input disabled="" type="checkbox"/>
Frank Mintz - Autogestion y Anarcosindicalismo</li>
<li><input disabled="" type="checkbox" checked=""/>
Jose Peirats - Los anarquistas en la crisis politica española (1869 - 1939)</li>
<li><input disabled="" type="checkbox"/>
Vernon Richards - Malatesta. Pensamiento y accion revolucionarios</li>
<li><input disabled="" type="checkbox"/>
Tomas Ibanez - Actualidad del anarquismo</li>
<li><input disabled="" type="checkbox"/>
Tomas Ibanez - Agitando los anarquismos. De Mayo del 68 a las revueltas del siglo XXI</li>
<li><input disabled="" type="checkbox"/>
Emile Armand - El anarquismo individualista</li>
<li><input disabled="" type="checkbox" checked=""/>
Max Stirner - El Unico y su Propiedad</li>
<li><input disabled="" type="checkbox"/>
Grupo de Estudios Sobre El Anarquismo - El Anarquismo Frente al Derecho</li>
<li><input disabled="" type="checkbox"/>
Piotr Archinov - Historia del Movimiento Makhnovista</li>
</ul>
<h3><a class="header" href="#economics" id="economics">Economics</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Alfredo Zaiat - Economia a contramano ES</li>
</ul>
<h2><a class="header" href="#other" id="other">Other</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Harper and Row - A College Book of Modern Verse EN</li>
<li><input disabled="" type="checkbox" checked=""/>
German Literature Since Goethe DE</li>
<li><input disabled="" type="checkbox" checked=""/>
The Illustrated Encyclopedia of Minerals EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Mein Lesebuch DE</li>
<li><input disabled="" type="checkbox" checked=""/>
Krüss - Der Korngeist DE</li>
<li><input disabled="" type="checkbox" checked=""/>
Finnland, Geschichte und Gegenwart DE</li>
<li><input disabled="" type="checkbox" checked=""/>
Dante - La Divina Comedia ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Paolo Bacigalupi - La chica mecanica ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Deepak Chopra - The way of the wizard EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Italo Calvino - De fabula ES</li>
<li><input disabled="" type="checkbox"/>
Italo Calvino - Ciudades Invisibles ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Fyodor Dostoievski - Los demonios ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Fyodor Dostoievski - Noches blancas ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Rudolph Koch - El Libro de los simbolos ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Paulo Coelho - Manual del guerrero de la luz ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Jean Marigny - Los vampiros ES</li>
<li><input disabled="" type="checkbox" checked=""/>
Robert Kiyosaki - Rich dad, poor dad EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Luis Alberto Romero - Breve historia contemporanea Argentina ES</li>
<li><input disabled="" type="checkbox" checked=""/>
John Updike - Rabbit is Rich, Rabbit Redux, Rabbit, Run EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Harry Thompson - This thing of darkness EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Roald Dahl - The Twits EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Roald Dahl - The collected short stories EN</li>
<li><input disabled="" type="checkbox" checked=""/>
Roald Dahl - The wonderful story of Henry Sugar and six more</li>
<li><input disabled="" type="checkbox" checked=""/>
Canciones Celtas</li>
<li><input disabled="" type="checkbox" checked=""/>
No Longer at Ease</li>
<li><input disabled="" type="checkbox" checked=""/>
The Vicar of Wakefield</li>
<li><input disabled="" type="checkbox" checked=""/>
Three Men in a Boat</li>
<li><input disabled="" type="checkbox" checked=""/>
Maria Angelica Canel - Asi aprendi a cocinar sano, rico y natural</li>
<li><input disabled="" type="checkbox" checked=""/>
Jan Sardi - Guion Original de Claroscuro</li>
<li><input disabled="" type="checkbox" checked=""/>
S R Ranganathan - Colon Classification</li>
</ul>
<h1><a class="header" href="#technical-and-scientific-writing" id="technical-and-scientific-writing">Technical and Scientific Writing</a></h1>
<h2><a class="header" href="#persist-and-publish" id="persist-and-publish">Persist and Publish</a></h2>
<ul>
<li>1 I wanted to be a teacher, not a writer</li>
<li>2 Publish or perish is the name of the game</li>
<li>3 The basics of getting started</li>
<li>4 Writing can be fun, but seldom is it easy</li>
<li>5 In the beginning there was the local copy</li>
<li>6 Creating foothills from mole hills: writing journal articles</li>
<li>7 Expanding the horizons: monographs and technical reports</li>
<li>8 Scaling the summits: your first book</li>
<li>9 Seeking new challenges in the publishing game</li>
<li>10 What happens when the stargazers see you</li>
</ul>
<h2><a class="header" href="#effective-writing-improving-scientific-technical-and-business-communication" id="effective-writing-improving-scientific-technical-and-business-communication">Effective writing. Improving scientific, technical and business communication</a></h2>
<ul>
<li>1 Writing is communicating. Revising basic assumptions.</li>
<li>2 Writing about aim and audience.</li>
<li>3 Starting to write. A practical approach.</li>
<li>4 Organization and layout of information.</li>
<li>5 The use of headings and numbering.</li>
<li>6 Algorithms for complex possibilities and procedures.</li>
<li>7 Style for readability.</li>
<li>8 Writing with a computer.</li>
<li>9 Informative summaries.</li>
<li>10 Choosing and using tables, illustrations and graphics presentation techniques.</li>
<li>11 Writing instructions.</li>
<li>12 Writing descriptions and explanations.</li>
<li>13 Writing letters and memoranda.</li>
<li>14 Writing minutes and reports of proceedings.</li>
<li>15 Writing in examinations.</li>
</ul>
<h2><a class="header" href="#english-for-writing-research-papers" id="english-for-writing-research-papers">English for writing research papers</a></h2>
<ul>
<li>I Writing skills
<ul>
<li>1 Planning and perception</li>
<li>2 Structuring a sentence: word order</li>
<li>3 Structuring paragraphs</li>
<li>4 Breaking up long sentences</li>
<li>5 Being concise and removing redundancy</li>
<li>6 Avoiding ambiguity, repetition and vague language</li>
<li>7 Clarifying who did what</li>
<li>8 Highlighting your findings</li>
<li>9 Discussing your limitations</li>
<li>10 Hedging and criticizing</li>
<li>11 Plagiarism and paraphrasing</li>
</ul>
</li>
<li>II Sections of a paper
<ul>
<li>12 Titles</li>
<li>13 Abstracts</li>
<li>14 Introductions</li>
<li>15 Review of the literature</li>
<li>16 Methods</li>
<li>17 Results</li>
<li>18 Discussion</li>
<li>19 Conclusions</li>
<li>20 The final check</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#academic-writing-an-introduction" id="academic-writing-an-introduction">Academic Writing. An Introduction</a></h2>
<ul>
<li>1 Introducing genre</li>
<li>2 Readers reading I</li>
<li>3 Citation and summary</li>
<li>4 Summary</li>
<li>5 Challenging situations for summarizers</li>
<li>6 Orchestrating voices</li>
<li>7 Definition</li>
<li>8 Readers reading II</li>
<li>9 Scholarly styles I</li>
<li>10 Scholarly styles II</li>
<li>11 Making and maintaining knowledge I</li>
<li>12 Making and maintaining knowledge II</li>
<li>13 Introductions</li>
<li>14 Conclusions and the moral compass of the disciplines</li>
</ul>
<h2><a class="header" href="#science-and-technical-writing-a-manual-of-style" id="science-and-technical-writing-a-manual-of-style">Science and technical writing. A manual of style</a></h2>
<ul>
<li>1 Audience analysis and document planning</li>
<li>2 Writing for non-native audiences</li>
<li>3 Grammar, usage and revising for publication</li>
<li>4 Puncuating and scientific and technical prose</li>
<li>5 Using acceptable spelling</li>
<li>6 Incorporating specialized terminology</li>
<li>7 Using numbers and symbols</li>
<li>8 Using quotations, citations and references</li>
<li>9 Creating indexes</li>
<li>10 Creating nontextual information</li>
<li>11 Creating usable data displays</li>
<li>12 Designing useful documents</li>
</ul>
<h2><a class="header" href="#scientific-writing-easy-when-you-know-how" id="scientific-writing-easy-when-you-know-how">Scientific writing. Easy when you know how</a></h2>
<ul>
<li>1 Scientific writing</li>
<li>2 Getting started</li>
<li>3 Writing your paper</li>
<li>4 Finishing your paper</li>
<li>5 Review and editorial process</li>
<li>6 Publishing</li>
<li>7 Other types of documents</li>
<li>8 Writing style</li>
</ul>
<h2><a class="header" href="#technical-writing-for-dummies" id="technical-writing-for-dummies">Technical Writing for Dummies</a></h2>
<h2><a class="header" href="#technical-writing-101" id="technical-writing-101">Technical writing 101</a></h2>
<h2><a class="header" href="#technical-writing-for-success" id="technical-writing-for-success">Technical writing for success</a></h2>
<h2><a class="header" href="#handbook-for-technical-writing" id="handbook-for-technical-writing">Handbook for technical writing</a></h2>
<h2><a class="header" href="#a-guide-to-writing-mathematics" id="a-guide-to-writing-mathematics">A guide to writing mathematics</a></h2>
<h2><a class="header" href="#engineers-guide-to-technical-writing" id="engineers-guide-to-technical-writing">Engineer's guide to technical writing</a></h2>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
